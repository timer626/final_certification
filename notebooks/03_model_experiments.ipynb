{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf765872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier,Pool\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(r'.env')\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASS = os.getenv(\"DB_PASS\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "engine = create_engine(f'postgresql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "df = pd.read_sql('select * from ecommerce_features',engine )\n",
    "df = df.set_index('CustomerID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82bb209",
   "metadata": {},
   "source": [
    "Я выбрал catboost, потому что она лучше всех, рассмотренных моделей, по показателям precision,recall,f1,roc-auc, и время инференса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b936cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Churn'],axis=1)\n",
    "y = df['Churn']\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(X,y,test_size=0.1,random_state=42)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "511a0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CatBoost\n",
    "cat_columns = X_train.select_dtypes(exclude='number').columns.to_list()\n",
    "eval_pool = Pool(X_val,y_val,cat_features=cat_columns)\n",
    "train_pool = Pool(X_train,y_train,cat_features=cat_columns)\n",
    "model_cb = CatBoostClassifier(iterations=5000,eval_metric='Logloss')\n",
    "\n",
    "#RandomForest\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=5000,criterion='log_loss')\n",
    "num_columns = X_train.select_dtypes(include='number').columns\n",
    "cat_columns = X_train.select_dtypes(exclude='number').columns\n",
    "ct_rf = ColumnTransformer(\n",
    "    [\n",
    "        ('num',StandardScaler(),num_columns),\n",
    "        ('cat',OneHotEncoder(),cat_columns)\n",
    "    ]\n",
    "    \n",
    ")\n",
    "pl_rf = Pipeline([\n",
    "    ('preprocess',ct_rf),\n",
    "    ('classifier',model_rf)\n",
    "])\n",
    "#MLP\n",
    "model_mlp = MLPClassifier()\n",
    "\n",
    "num_columns = X_train.select_dtypes(include='number').columns\n",
    "cat_columns = X_train.select_dtypes(exclude='number').columns\n",
    "ct_mlp = ColumnTransformer(\n",
    "    [\n",
    "        ('num',StandardScaler(),num_columns),\n",
    "        ('cat',OneHotEncoder(),cat_columns)\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "pl_mlp = Pipeline([\n",
    "    ('preprocess',ct_mlp),\n",
    "    ('classifier',model_mlp)\n",
    "])\n",
    "\n",
    "#LogReg\n",
    "model_logreg = LogisticRegression()\n",
    "\n",
    "num_columns = X_train.select_dtypes(include='number').columns\n",
    "cat_columns = X_train.select_dtypes(exclude='number').columns\n",
    "ct_logreg = ColumnTransformer(\n",
    "    [\n",
    "        ('num',StandardScaler(),num_columns),\n",
    "        ('cat',OneHotEncoder(),cat_columns)\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "pl_logreg = Pipeline([\n",
    "    ('preprocess',ct_logreg),\n",
    "    ('classifier',model_logreg)\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6951786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  Index([&#x27;Tenure&#x27;, &#x27;CityTier&#x27;, &#x27;WarehouseToHome&#x27;, &#x27;HourSpendOnApp&#x27;,\n",
       "       &#x27;NumberOfDeviceRegistered&#x27;, &#x27;SatisfactionScore&#x27;, &#x27;NumberOfAddress&#x27;,\n",
       "       &#x27;Complain&#x27;, &#x27;OrderAmountHikeFromlastYear&#x27;, &#x27;CouponUsed&#x27;, &#x27;OrderCount&#x27;,\n",
       "       &#x27;DaySinceLastOrder&#x27;, &#x27;CashbackAmount&#x27;, &#x27;cashbk_per_order&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                                 (&#x27;cat&#x27;, OneHotEncoder(),\n",
       "                                                  Index([&#x27;PreferredLoginDevice&#x27;, &#x27;PreferredPaymentMode&#x27;, &#x27;Gender&#x27;,\n",
       "       &#x27;PreferedOrderCat&#x27;, &#x27;MaritalStatus&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples\">\n",
       "            steps\n",
       "            <span class=\"param-doc-description\">steps: list of tuples<br><br>List of (name of step, estimator) tuples that are to be chained in<br>sequential order. To be compatible with the scikit-learn API, all steps<br>must define `fit`. All non-last steps must also define `transform`. See<br>:ref:`Combining Estimators <combining_estimators>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;preprocess&#x27;, ...), (&#x27;classifier&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone\">\n",
       "            transform_input\n",
       "            <span class=\"param-doc-description\">transform_input: list of str, default=None<br><br>The names of the :term:`metadata` parameters that should be transformed by the<br>pipeline before passing it to the step consuming it.<br><br>This enables transforming some input arguments to ``fit`` (other than ``X``)<br>to be transformed by the steps of the pipeline up to the step which requires<br>them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>For instance, this can be used to pass a validation set through the pipeline.<br><br>You can only set this if metadata routing is enabled, which you<br>can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br><br>.. versionadded:: 1.6</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone\">\n",
       "            memory\n",
       "            <span class=\"param-doc-description\">memory: str or object with the joblib.Memory interface, default=None<br><br>Used to cache the fitted transformers of the pipeline. The last step<br>will never be cached, even if it is a transformer. By default, no<br>caching is performed. If a string is given, it is the path to the<br>caching directory. Enabling caching triggers a clone of the transformers<br>before fitting. Therefore, the transformer instance given to the<br>pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>or ``steps`` to inspect estimators within the pipeline. Caching the<br>transformers is advantageous when fitting is time consuming. See<br>:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>for an example on how to enable caching.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each step will be printed as it<br>is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocess: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocess: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"preprocess__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transformers',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformers,-list%20of%20tuples\">\n",
       "            transformers\n",
       "            <span class=\"param-doc-description\">transformers: list of tuples<br><br>List of (name, transformer, columns) tuples specifying the<br>transformer objects to be applied to subsets of the data.<br><br>name : str<br>    Like in Pipeline and FeatureUnion, this allows the transformer and<br>    its parameters to be set using ``set_params`` and searched in grid<br>    search.<br>transformer : {'drop', 'passthrough'} or estimator<br>    Estimator must support :term:`fit` and :term:`transform`.<br>    Special-cased strings 'drop' and 'passthrough' are accepted as<br>    well, to indicate to drop the columns or to pass them through<br>    untransformed, respectively.<br>columns :  str, array-like of str, int, array-like of int,                 array-like of bool, slice or callable<br>    Indexes the data on its second axis. Integers are interpreted as<br>    positional columns, while strings can reference DataFrame columns<br>    by name.  A scalar string or int should be used where<br>    ``transformer`` expects X to be a 1d array-like (vector),<br>    otherwise a 2d array will be passed to the transformer.<br>    A callable is passed the input data `X` and can return any of the<br>    above. To select multiple columns by name or dtype, you can use<br>    :obj:`make_column_selector`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">[(&#x27;num&#x27;, ...), (&#x27;cat&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('remainder',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=remainder,-%7B%27drop%27%2C%20%27passthrough%27%7D%20or%20estimator%2C%20default%3D%27drop%27\">\n",
       "            remainder\n",
       "            <span class=\"param-doc-description\">remainder: {'drop', 'passthrough'} or estimator, default='drop'<br><br>By default, only the specified columns in `transformers` are<br>transformed and combined in the output, and the non-specified<br>columns are dropped. (default of ``'drop'``).<br>By specifying ``remainder='passthrough'``, all remaining columns that<br>were not specified in `transformers`, but present in the data passed<br>to `fit` will be automatically passed through. This subset of columns<br>is concatenated with the output of the transformers. For dataframes,<br>extra columns not seen during `fit` will be excluded from the output<br>of `transform`.<br>By setting ``remainder`` to be an estimator, the remaining<br>non-specified columns will use the ``remainder`` estimator. The<br>estimator must support :term:`fit` and :term:`transform`.<br>Note that using this feature requires that the DataFrame columns<br>input at :term:`fit` and :term:`transform` have identical order.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;drop&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sparse_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=sparse_threshold,-float%2C%20default%3D0.3\">\n",
       "            sparse_threshold\n",
       "            <span class=\"param-doc-description\">sparse_threshold: float, default=0.3<br><br>If the output of the different transformers contains sparse matrices,<br>these will be stacked as a sparse matrix if the overall density is<br>lower than this value. Use ``sparse_threshold=0`` to always return<br>dense.  When the transformed output consists of all dense data, the<br>stacked result will be dense, and this keyword will be ignored.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transformer_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformer_weights,-dict%2C%20default%3DNone\">\n",
       "            transformer_weights\n",
       "            <span class=\"param-doc-description\">transformer_weights: dict, default=None<br><br>Multiplicative weights for features per transformer. The output of the<br>transformer is multiplied by these weights. Keys are transformer names,<br>values the weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose,-bool%2C%20default%3DFalse\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: bool, default=False<br><br>If True, the time elapsed while fitting each transformer will be<br>printed as it is completed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose_feature_names_out',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose_feature_names_out,-bool%2C%20str%20or%20Callable%5B%5Bstr%2C%20str%5D%2C%20str%5D%2C%20default%3DTrue\">\n",
       "            verbose_feature_names_out\n",
       "            <span class=\"param-doc-description\">verbose_feature_names_out: bool, str or Callable[[str, str], str], default=True<br><br>- If True, :meth:`ColumnTransformer.get_feature_names_out` will prefix<br>  all feature names with the name of the transformer that generated that<br>  feature. It is equivalent to setting<br>  `verbose_feature_names_out=\"{transformer_name}__{feature_name}\"`.<br>- If False, :meth:`ColumnTransformer.get_feature_names_out` will not<br>  prefix any feature names and will error if feature names are not<br>  unique.<br>- If ``Callable[[str, str], str]``,<br>  :meth:`ColumnTransformer.get_feature_names_out` will rename all the features<br>  using the name of the transformer. The first argument of the callable is the<br>  transformer name and the second argument is the feature name. The returned<br>  string will be the new feature name.<br>- If ``str``, it must be a string ready for formatting. The given string will<br>  be formatted using two field names: ``transformer_name`` and ``feature_name``.<br>  e.g. ``\"{feature_name}__{transformer_name}\"``. See :meth:`str.format` method<br>  from the standard library for more info.<br><br>.. versionadded:: 1.0<br><br>.. versionchanged:: 1.6<br>    `verbose_feature_names_out` can be a callable or a string to be formatted.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('force_int_remainder_cols',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=force_int_remainder_cols,-bool%2C%20default%3DFalse\">\n",
       "            force_int_remainder_cols\n",
       "            <span class=\"param-doc-description\">force_int_remainder_cols: bool, default=False<br><br>This parameter has no effect.<br><br>.. note::<br>    If you do not access the list of columns for the remainder columns<br>    in the `transformers_` fitted attribute, you do not need to set<br>    this parameter.<br><br>.. versionadded:: 1.5<br><br>.. versionchanged:: 1.7<br>   The default value for `force_int_remainder_cols` will change from<br>   `True` to `False` in version 1.7.<br><br>.. deprecated:: 1.7<br>   `force_int_remainder_cols` is deprecated and will be removed in 1.9.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"preprocess__num__\"><pre>Index([&#x27;Tenure&#x27;, &#x27;CityTier&#x27;, &#x27;WarehouseToHome&#x27;, &#x27;HourSpendOnApp&#x27;,\n",
       "       &#x27;NumberOfDeviceRegistered&#x27;, &#x27;SatisfactionScore&#x27;, &#x27;NumberOfAddress&#x27;,\n",
       "       &#x27;Complain&#x27;, &#x27;OrderAmountHikeFromlastYear&#x27;, &#x27;CouponUsed&#x27;, &#x27;OrderCount&#x27;,\n",
       "       &#x27;DaySinceLastOrder&#x27;, &#x27;CashbackAmount&#x27;, &#x27;cashbk_per_order&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"preprocess__num__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=copy,-bool%2C%20default%3DTrue\">\n",
       "            copy\n",
       "            <span class=\"param-doc-description\">copy: bool, default=True<br><br>If False, try to avoid a copy and do inplace scaling instead.<br>This is not guaranteed to always work inplace; e.g. if the data is<br>not a NumPy array or scipy.sparse CSR matrix, a copy may still be<br>returned.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_mean',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_mean,-bool%2C%20default%3DTrue\">\n",
       "            with_mean\n",
       "            <span class=\"param-doc-description\">with_mean: bool, default=True<br><br>If True, center the data before scaling.<br>This does not work (and will raise an exception) when attempted on<br>sparse matrices, because centering them entails building a dense<br>matrix which in common use cases is likely to be too large to fit in<br>memory.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('with_std',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.StandardScaler.html#:~:text=with_std,-bool%2C%20default%3DTrue\">\n",
       "            with_std\n",
       "            <span class=\"param-doc-description\">with_std: bool, default=True<br><br>If True, scale the data to unit variance (or equivalently,<br>unit standard deviation).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"preprocess__cat__\"><pre>Index([&#x27;PreferredLoginDevice&#x27;, &#x27;PreferredPaymentMode&#x27;, &#x27;Gender&#x27;,\n",
       "       &#x27;PreferedOrderCat&#x27;, &#x27;MaritalStatus&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"preprocess__cat__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('categories',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=categories,-%27auto%27%20or%20a%20list%20of%20array-like%2C%20default%3D%27auto%27\">\n",
       "            categories\n",
       "            <span class=\"param-doc-description\">categories: 'auto' or a list of array-like, default='auto'<br><br>Categories (unique values) per feature:<br><br>- 'auto' : Determine categories automatically from the training data.<br>- list : ``categories[i]`` holds the categories expected in the ith<br>  column. The passed categories should not mix strings and numeric<br>  values within a single feature, and should be sorted in case of<br>  numeric values.<br><br>The used categories can be found in the ``categories_`` attribute.<br><br>.. versionadded:: 0.20</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('drop',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=drop,-%7B%27first%27%2C%20%27if_binary%27%7D%20or%20an%20array-like%20of%20shape%20%28n_features%2C%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            drop\n",
       "            <span class=\"param-doc-description\">drop: {'first', 'if_binary'} or an array-like of shape (n_features,),             default=None<br><br>Specifies a methodology to use to drop one of the categories per<br>feature. This is useful in situations where perfectly collinear<br>features cause problems, such as when feeding the resulting data<br>into an unregularized linear regression model.<br><br>However, dropping one category breaks the symmetry of the original<br>representation and can therefore induce a bias in downstream models,<br>for instance for penalized linear classification or regression models.<br><br>- None : retain all features (the default).<br>- 'first' : drop the first category in each feature. If only one<br>  category is present, the feature will be dropped entirely.<br>- 'if_binary' : drop the first category in each feature with two<br>  categories. Features with 1 or more than 2 categories are<br>  left intact.<br>- array : ``drop[i]`` is the category in feature ``X[:, i]`` that<br>  should be dropped.<br><br>When `max_categories` or `min_frequency` is configured to group<br>infrequent categories, the dropping behavior is handled after the<br>grouping.<br><br>.. versionadded:: 0.21<br>   The parameter `drop` was added in 0.21.<br><br>.. versionchanged:: 0.23<br>   The option `drop='if_binary'` was added in 0.23.<br><br>.. versionchanged:: 1.1<br>    Support for dropping infrequent categories.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sparse_output',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=sparse_output,-bool%2C%20default%3DTrue\">\n",
       "            sparse_output\n",
       "            <span class=\"param-doc-description\">sparse_output: bool, default=True<br><br>When ``True``, it returns a :class:`scipy.sparse.csr_matrix`,<br>i.e. a sparse matrix in \"Compressed Sparse Row\" (CSR) format.<br><br>.. versionadded:: 1.2<br>   `sparse` was renamed to `sparse_output`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=dtype,-number%20type%2C%20default%3Dnp.float64\">\n",
       "            dtype\n",
       "            <span class=\"param-doc-description\">dtype: number type, default=np.float64<br><br>Desired dtype of output.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('handle_unknown',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=handle_unknown,-%7B%27error%27%2C%20%27ignore%27%2C%20%27infrequent_if_exist%27%2C%20%27warn%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27error%27\">\n",
       "            handle_unknown\n",
       "            <span class=\"param-doc-description\">handle_unknown: {'error', 'ignore', 'infrequent_if_exist', 'warn'},                      default='error'<br><br>Specifies the way unknown categories are handled during :meth:`transform`.<br><br>- 'error' : Raise an error if an unknown category is present during transform.<br>- 'ignore' : When an unknown category is encountered during<br>  transform, the resulting one-hot encoded columns for this feature<br>  will be all zeros. In the inverse transform, an unknown category<br>  will be denoted as None.<br>- 'infrequent_if_exist' : When an unknown category is encountered<br>  during transform, the resulting one-hot encoded columns for this<br>  feature will map to the infrequent category if it exists. The<br>  infrequent category will be mapped to the last position in the<br>  encoding. During inverse transform, an unknown category will be<br>  mapped to the category denoted `'infrequent'` if it exists. If the<br>  `'infrequent'` category does not exist, then :meth:`transform` and<br>  :meth:`inverse_transform` will handle an unknown category as with<br>  `handle_unknown='ignore'`. Infrequent categories exist based on<br>  `min_frequency` and `max_categories`. Read more in the<br>  :ref:`User Guide <encoder_infrequent_categories>`.<br>- 'warn' : When an unknown category is encountered during transform<br>  a warning is issued, and the encoding then proceeds as described for<br>  `handle_unknown=\"infrequent_if_exist\"`.<br><br>.. versionchanged:: 1.1<br>    `'infrequent_if_exist'` was added to automatically handle unknown<br>    categories and infrequent categories.<br><br>.. versionadded:: 1.6<br>   The option `\"warn\"` was added in 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_frequency',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=min_frequency,-int%20or%20float%2C%20default%3DNone\">\n",
       "            min_frequency\n",
       "            <span class=\"param-doc-description\">min_frequency: int or float, default=None<br><br>Specifies the minimum frequency below which a category will be<br>considered infrequent.<br><br>- If `int`, categories with a smaller cardinality will be considered<br>  infrequent.<br><br>- If `float`, categories with a smaller cardinality than<br>  `min_frequency * n_samples`  will be considered infrequent.<br><br>.. versionadded:: 1.1<br>    Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_categories',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=max_categories,-int%2C%20default%3DNone\">\n",
       "            max_categories\n",
       "            <span class=\"param-doc-description\">max_categories: int, default=None<br><br>Specifies an upper limit to the number of output features for each input<br>feature when considering infrequent categories. If there are infrequent<br>categories, `max_categories` includes the category representing the<br>infrequent categories along with the frequent categories. If `None`,<br>there is no limit to the number of output features.<br><br>.. versionadded:: 1.1<br>    Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_name_combiner',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=feature_name_combiner,-%22concat%22%20or%20callable%2C%20default%3D%22concat%22\">\n",
       "            feature_name_combiner\n",
       "            <span class=\"param-doc-description\">feature_name_combiner: \"concat\" or callable, default=\"concat\"<br><br>Callable with signature `def callable(input_feature, category)` that returns a<br>string. This is used to create feature names to be returned by<br>:meth:`get_feature_names_out`.<br><br>`\"concat\"` concatenates encoded feature name and category with<br>`feature + \"_\" + str(category)`.E.g. feature X with values 1, 6, 7 create<br>feature names `X_1, X_6, X_7`.<br><br>.. versionadded:: 1.3</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;concat&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"classifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  Index(['Tenure', 'CityTier', 'WarehouseToHome', 'HourSpendOnApp',\n",
       "       'NumberOfDeviceRegistered', 'SatisfactionScore', 'NumberOfAddress',\n",
       "       'Complain', 'OrderAmountHikeFromlastYear', 'CouponUsed', 'OrderCount',\n",
       "       'DaySinceLastOrder', 'CashbackAmount', 'cashbk_per_order'],\n",
       "      dtype='object')),\n",
       "                                                 ('cat', OneHotEncoder(),\n",
       "                                                  Index(['PreferredLoginDevice', 'PreferredPaymentMode', 'Gender',\n",
       "       'PreferedOrderCat', 'MaritalStatus'],\n",
       "      dtype='object'))])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cb.fit(train_pool,eval_set=eval_pool,early_stopping_rounds=30,use_best_model=True,verbose=False)\n",
    "pl_rf.fit(X_train,y_train)\n",
    "pl_mlp.fit(X_train,y_train)\n",
    "pl_logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b95949",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics catboost\n",
    "start_cb = time.perf_counter()\n",
    "pred_cb = model_cb.predict(X_test)\n",
    "end_cb = time.perf_counter()\n",
    "pred_proba_cb=model_cb.predict_proba(X_test)\n",
    "precision_cb = np.round(precision_score(y_test,pred_cb),4)\n",
    "recall_cb = np.round(recall_score(y_test,pred_cb),4)\n",
    "f1_cb = np.round(f1_score(y_test,pred_cb),4)\n",
    "roc_auc_cb = np.round(roc_auc_score(y_test,pred_proba_cb[:,1]),4)\n",
    "time_inference_ms_cb = round((end_cb-start_cb)/X_test.shape[0] * 1000,4)\n",
    "\n",
    "#Metrics RandomForest\n",
    "start_rf = time.perf_counter()\n",
    "pred_rf = pl_rf.predict(X_test)\n",
    "end_rf = time.perf_counter()\n",
    "pred_proba_rf=pl_rf.predict_proba(X_test)\n",
    "precision_rf = np.round(precision_score(y_test,pred_rf),4)\n",
    "recall_rf = np.round(recall_score(y_test,pred_rf),4)\n",
    "f1_rf = np.round(f1_score(y_test,pred_rf),4)\n",
    "roc_auc_rf = np.round(roc_auc_score(y_test,pred_proba_rf[:,1]),4)\n",
    "time_inference_ms_rf = round((end_rf-start_rf)/X_test.shape[0] * 1000,4)\n",
    "\n",
    "#Metrics MLP\n",
    "start_mpl = time.perf_counter()\n",
    "pred_mlp = pl_mlp.predict(X_test)\n",
    "end_mlp = time.perf_counter()\n",
    "pred_proba_mlp=pl_mlp.predict_proba(X_test)\n",
    "precision_mlp = np.round(precision_score(y_test,pred_mlp),4)\n",
    "recall_mlp = np.round(recall_score(y_test,pred_mlp),4)\n",
    "f1_mlp = np.round(f1_score(y_test,pred_mlp),4)\n",
    "roc_auc_mlp = np.round(roc_auc_score(y_test,pred_proba_mlp[:,1]),4)\n",
    "time_inference_ms_mlp = np.round((end_mlp-start_mpl)/X_test.shape[0] * 1000,4)\n",
    "\n",
    "#Metrics Logreg\n",
    "start_logreg = time.perf_counter()\n",
    "pred_logreg = pl_logreg.predict(X_test)\n",
    "end_logreg = time.perf_counter()\n",
    "pred_proba_logreg=pl_logreg.predict_proba(X_test)\n",
    "precision_logreg = np.round(precision_score(y_test,pred_logreg),4)\n",
    "recall_logreg = np.round(recall_score(y_test,pred_logreg),4)\n",
    "f1_logreg = np.round(f1_score(y_test,pred_logreg),4)\n",
    "roc_auc_logreg = np.round(roc_auc_score(y_test,pred_proba_logreg[:,1]),4)\n",
    "time_inference_ms_logreg = np.round((end_logreg-start_logreg)/X_test.shape[0] * 1000,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1e7d7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>time_inferense(ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>0.9155</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>1.2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.7037</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>0.5984</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.0105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  Precision  Recall      F1  ROC_AUC  time_inferense(ms)\n",
       "0      Catboost     0.9420  0.8904  0.9155   0.9933              0.0107\n",
       "1  RandomForest     0.9667  0.7945  0.8722   0.9923              1.2502\n",
       "2           MLP     0.8030  0.7260  0.7626   0.9747              0.0096\n",
       "3        LogReg     0.7037  0.5205  0.5984   0.8851              0.0105"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summarize results\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model':['Catboost','RandomForest','MLP','LogReg'],\n",
    "    'Precision':[precision_cb,precision_rf,precision_mlp,precision_logreg],\n",
    "    'Recall':[recall_cb,recall_rf,recall_mlp,recall_logreg],\n",
    "    'F1':[f1_cb,f1_rf,f1_mlp,f1_logreg],\n",
    "    'ROC_AUC':[roc_auc_cb,roc_auc_rf,roc_auc_mlp,roc_auc_logreg],\n",
    "    'time_inferense(ms)':[time_inference_ms_cb,time_inference_ms_rf,time_inference_ms_mlp,time_inference_ms_logreg]\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab58c13",
   "metadata": {},
   "source": [
    "По всем показателям победил Catboost. Стоит выбрать его для использования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f1490",
   "metadata": {},
   "source": [
    "Такие результаты получены с параметрами по умолчанию\n",
    "\n",
    "Проведу подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2291e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 100, 3000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "        \"early_stopping_rounds\": 50,\n",
    "        \"verbose\": False,\n",
    "        \"random_seed\": 42,\n",
    "        \"eval_metric\": \"Logloss\"\n",
    "    }\n",
    "\n",
    "    cat_columns = X_train.select_dtypes(exclude='number').columns.to_list()\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_columns)\n",
    "    eval_pool = Pool(X_val, y_val, cat_features=cat_columns)\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(train_pool, eval_set=eval_pool, use_best_model=True)\n",
    "\n",
    "    y_pred = model.predict(X_val)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "def objective_rf(trial):\n",
    "\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 2000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    num_columns = X_train.select_dtypes(include='number').columns\n",
    "    cat_columns = X_train.select_dtypes(exclude='number').columns\n",
    "\n",
    "    ct = ColumnTransformer([\n",
    "        ('num', StandardScaler(), num_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', ct),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "def objective_mlp(trial):\n",
    "\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "    for i in range(n_layers):\n",
    "        layers.append(trial.suggest_int(f\"n_units_l{i}\", 16, 256))\n",
    "\n",
    "    alpha = trial.suggest_float(\"alpha\", 1e-6, 1e-1, log=True)\n",
    "    learning_rate_init = trial.suggest_float(\"learning_rate_init\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=tuple(layers),\n",
    "        alpha=alpha,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        max_iter=500,\n",
    "        random_state=42,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1\n",
    "    )\n",
    "\n",
    "    num_columns = X_train.select_dtypes(include='number').columns\n",
    "    cat_columns = X_train.select_dtypes(exclude='number').columns\n",
    "\n",
    "    ct = ColumnTransformer([\n",
    "        ('num', StandardScaler(), num_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', ct),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "def objective_logreg(trial):\n",
    "    C = trial.suggest_float(\"C\", 1e-4, 1e2, log=True)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"])\n",
    "    \n",
    "    if penalty == \"elasticnet\":\n",
    "        l1_ratio = trial.suggest_float(\"l1_ratio\", 0.1, 0.9)\n",
    "        solver = \"saga\"\n",
    "    else:\n",
    "        l1_ratio = None\n",
    "        solver = \"liblinear\" if penalty == \"l1\" else \"lbfgs\"\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        l1_ratio=l1_ratio,\n",
    "        solver=solver,\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    num_columns = X_train.select_dtypes(include='number').columns\n",
    "    cat_columns = X_train.select_dtypes(exclude='number').columns\n",
    "\n",
    "    ct = ColumnTransformer([\n",
    "        ('num', StandardScaler(), num_columns),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_columns)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', ct),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_val)\n",
    "    return f1_score(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33718cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-16 16:07:35,735] A new study created in memory with name: no-name-7eb45ad6-e815-41f4-ac53-5a788e631f24\n",
      "[I 2025-12-16 16:07:45,500] Trial 0 finished with value: 0.8991596638655462 and parameters: {'iterations': 1095, 'learning_rate': 0.20603471383931798, 'depth': 9}. Best is trial 0 with value: 0.8991596638655462.\n",
      "[I 2025-12-16 16:07:52,706] Trial 1 finished with value: 0.751131221719457 and parameters: {'iterations': 456, 'learning_rate': 0.06752619918558418, 'depth': 4}. Best is trial 0 with value: 0.8991596638655462.\n",
      "[I 2025-12-16 16:08:23,802] Trial 2 finished with value: 0.8983050847457628 and parameters: {'iterations': 1325, 'learning_rate': 0.05198404013557428, 'depth': 8}. Best is trial 0 with value: 0.8991596638655462.\n",
      "[I 2025-12-16 16:09:21,302] Trial 3 finished with value: 0.8776371308016878 and parameters: {'iterations': 2243, 'learning_rate': 0.022026261133812636, 'depth': 10}. Best is trial 0 with value: 0.8991596638655462.\n",
      "[I 2025-12-16 16:09:44,104] Trial 4 finished with value: 0.9029535864978903 and parameters: {'iterations': 1060, 'learning_rate': 0.07875783666214999, 'depth': 9}. Best is trial 4 with value: 0.9029535864978903.\n",
      "[I 2025-12-16 16:09:51,495] Trial 5 finished with value: 0.8898305084745762 and parameters: {'iterations': 2670, 'learning_rate': 0.23188833051484736, 'depth': 5}. Best is trial 4 with value: 0.9029535864978903.\n",
      "[I 2025-12-16 16:09:53,867] Trial 6 finished with value: 0.7129629629629629 and parameters: {'iterations': 135, 'learning_rate': 0.10135411985290252, 'depth': 6}. Best is trial 4 with value: 0.9029535864978903.\n",
      "[I 2025-12-16 16:10:41,385] Trial 7 finished with value: 0.7963800904977375 and parameters: {'iterations': 2399, 'learning_rate': 0.007948240156180368, 'depth': 6}. Best is trial 4 with value: 0.9029535864978903.\n",
      "[I 2025-12-16 16:11:51,058] Trial 8 finished with value: 0.8936170212765957 and parameters: {'iterations': 2971, 'learning_rate': 0.016981323755329215, 'depth': 7}. Best is trial 4 with value: 0.9029535864978903.\n",
      "[I 2025-12-16 16:12:27,550] Trial 9 finished with value: 0.8823529411764706 and parameters: {'iterations': 1184, 'learning_rate': 0.03420326339958061, 'depth': 10}. Best is trial 4 with value: 0.9029535864978903.\n",
      "[I 2025-12-16 16:12:51,225] Trial 10 finished with value: 0.9083333333333333 and parameters: {'iterations': 1907, 'learning_rate': 0.1202977482669015, 'depth': 8}. Best is trial 10 with value: 0.9083333333333333.\n",
      "[I 2025-12-16 16:13:04,831] Trial 11 finished with value: 0.919831223628692 and parameters: {'iterations': 1875, 'learning_rate': 0.10851878131004626, 'depth': 8}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:13:18,687] Trial 12 finished with value: 0.8916666666666667 and parameters: {'iterations': 1846, 'learning_rate': 0.13812254776264685, 'depth': 8}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:13:31,490] Trial 13 finished with value: 0.8813559322033898 and parameters: {'iterations': 1741, 'learning_rate': 0.1488620805078225, 'depth': 7}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:13:39,708] Trial 14 finished with value: 0.8851063829787233 and parameters: {'iterations': 2038, 'learning_rate': 0.28948455458122235, 'depth': 8}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:13:57,766] Trial 15 finished with value: 0.730593607305936 and parameters: {'iterations': 1555, 'learning_rate': 0.03783183397076642, 'depth': 3}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:14:13,597] Trial 16 finished with value: 0.902127659574468 and parameters: {'iterations': 2476, 'learning_rate': 0.10865541688989283, 'depth': 9}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:14:32,461] Trial 17 finished with value: 0.6766169154228856 and parameters: {'iterations': 753, 'learning_rate': 0.0050166437030870975, 'depth': 7}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:14:43,337] Trial 18 finished with value: 0.895397489539749 and parameters: {'iterations': 2024, 'learning_rate': 0.1706945843079695, 'depth': 5}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:15:10,409] Trial 19 finished with value: 0.895397489539749 and parameters: {'iterations': 1506, 'learning_rate': 0.05120765667588254, 'depth': 8}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:15:27,904] Trial 20 finished with value: 0.902127659574468 and parameters: {'iterations': 2762, 'learning_rate': 0.09112129248615133, 'depth': 9}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:15:50,716] Trial 21 finished with value: 0.8907563025210085 and parameters: {'iterations': 958, 'learning_rate': 0.07400648347708945, 'depth': 9}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:16:13,432] Trial 22 finished with value: 0.8983050847457628 and parameters: {'iterations': 815, 'learning_rate': 0.1306079665829521, 'depth': 10}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:16:44,582] Trial 23 finished with value: 0.8974358974358975 and parameters: {'iterations': 1585, 'learning_rate': 0.061123022516308766, 'depth': 8}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:17:06,021] Trial 24 finished with value: 0.8860759493670886 and parameters: {'iterations': 1966, 'learning_rate': 0.0828037897012657, 'depth': 9}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:17:43,538] Trial 25 finished with value: 0.8860759493670886 and parameters: {'iterations': 1414, 'learning_rate': 0.030235813271265996, 'depth': 7}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:17:53,741] Trial 26 finished with value: 0.8907563025210085 and parameters: {'iterations': 2175, 'learning_rate': 0.19368734849608732, 'depth': 8}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:18:06,708] Trial 27 finished with value: 0.9113924050632911 and parameters: {'iterations': 1746, 'learning_rate': 0.11551477446580208, 'depth': 10}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:18:24,354] Trial 28 finished with value: 0.8962655601659751 and parameters: {'iterations': 1830, 'learning_rate': 0.1152447383610589, 'depth': 10}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:18:32,125] Trial 29 finished with value: 0.8793103448275862 and parameters: {'iterations': 1672, 'learning_rate': 0.2505654212116278, 'depth': 6}. Best is trial 11 with value: 0.919831223628692.\n",
      "[I 2025-12-16 16:18:32,126] A new study created in memory with name: no-name-c01a59ad-623d-4611-a4e5-e24290acb8d5\n",
      "[I 2025-12-16 16:18:32,418] Trial 0 finished with value: 0.6461538461538462 and parameters: {'n_estimators': 156, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.6461538461538462.\n",
      "[I 2025-12-16 16:18:33,781] Trial 1 finished with value: 0.5384615384615384 and parameters: {'n_estimators': 868, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.6461538461538462.\n",
      "[I 2025-12-16 16:18:36,495] Trial 2 finished with value: 0.49122807017543857 and parameters: {'n_estimators': 1735, 'max_depth': 7, 'min_samples_split': 2, 'min_samples_leaf': 8, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6461538461538462.\n",
      "[I 2025-12-16 16:18:38,350] Trial 3 finished with value: 0.6283185840707964 and parameters: {'n_estimators': 895, 'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 8, 'max_features': None}. Best is trial 0 with value: 0.6461538461538462.\n",
      "[I 2025-12-16 16:18:40,452] Trial 4 finished with value: 0.6288659793814433 and parameters: {'n_estimators': 1332, 'max_depth': 16, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 0 with value: 0.6461538461538462.\n",
      "[I 2025-12-16 16:18:40,868] Trial 5 finished with value: 0.6082474226804123 and parameters: {'n_estimators': 213, 'max_depth': 16, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6461538461538462.\n",
      "[I 2025-12-16 16:18:42,398] Trial 6 finished with value: 0.5925925925925926 and parameters: {'n_estimators': 808, 'max_depth': 17, 'min_samples_split': 16, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 0 with value: 0.6461538461538462.\n",
      "[I 2025-12-16 16:18:45,013] Trial 7 finished with value: 0.6597938144329897 and parameters: {'n_estimators': 1606, 'max_depth': 11, 'min_samples_split': 19, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 7 with value: 0.6597938144329897.\n",
      "[I 2025-12-16 16:18:48,737] Trial 8 finished with value: 0.7117117117117117 and parameters: {'n_estimators': 1347, 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 8 with value: 0.7117117117117117.\n",
      "[I 2025-12-16 16:18:49,378] Trial 9 finished with value: 0.5333333333333333 and parameters: {'n_estimators': 383, 'max_depth': 16, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 8 with value: 0.7117117117117117.\n",
      "[I 2025-12-16 16:18:54,572] Trial 10 finished with value: 0.7914893617021277 and parameters: {'n_estimators': 1971, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 10 with value: 0.7914893617021277.\n",
      "[I 2025-12-16 16:18:59,825] Trial 11 finished with value: 0.7914893617021277 and parameters: {'n_estimators': 1980, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 10 with value: 0.7914893617021277.\n",
      "[I 2025-12-16 16:19:05,795] Trial 12 finished with value: 0.7932489451476793 and parameters: {'n_estimators': 1952, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 12 with value: 0.7932489451476793.\n",
      "[I 2025-12-16 16:19:11,504] Trial 13 finished with value: 0.8067226890756303 and parameters: {'n_estimators': 1978, 'max_depth': 13, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 13 with value: 0.8067226890756303.\n",
      "[I 2025-12-16 16:19:17,089] Trial 14 finished with value: 0.8117154811715481 and parameters: {'n_estimators': 1643, 'max_depth': 14, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 14 with value: 0.8117154811715481.\n",
      "[I 2025-12-16 16:19:21,244] Trial 15 finished with value: 0.8200836820083682 and parameters: {'n_estimators': 1535, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:24,693] Trial 16 finished with value: 0.7312775330396476 and parameters: {'n_estimators': 1338, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:27,228] Trial 17 finished with value: 0.7428571428571429 and parameters: {'n_estimators': 1572, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:29,287] Trial 18 finished with value: 0.5381165919282511 and parameters: {'n_estimators': 1154, 'max_depth': 3, 'min_samples_split': 12, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:33,986] Trial 19 finished with value: 0.8200836820083682 and parameters: {'n_estimators': 1727, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:38,669] Trial 20 finished with value: 0.7652173913043478 and parameters: {'n_estimators': 1783, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:42,857] Trial 21 finished with value: 0.8200836820083682 and parameters: {'n_estimators': 1526, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:46,866] Trial 22 finished with value: 0.8 and parameters: {'n_estimators': 1507, 'max_depth': 14, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 15 with value: 0.8200836820083682.\n",
      "[I 2025-12-16 16:19:50,170] Trial 23 finished with value: 0.8347107438016529 and parameters: {'n_estimators': 1214, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 23 with value: 0.8347107438016529.\n",
      "[I 2025-12-16 16:19:53,153] Trial 24 finished with value: 0.7815126050420168 and parameters: {'n_estimators': 1124, 'max_depth': 18, 'min_samples_split': 8, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 23 with value: 0.8347107438016529.\n",
      "[I 2025-12-16 16:19:54,221] Trial 25 finished with value: 0.6868686868686869 and parameters: {'n_estimators': 655, 'max_depth': 18, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 23 with value: 0.8347107438016529.\n",
      "[I 2025-12-16 16:19:57,428] Trial 26 finished with value: 0.8699186991869918 and parameters: {'n_estimators': 1195, 'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 26 with value: 0.8699186991869918.\n",
      "[I 2025-12-16 16:20:00,643] Trial 27 finished with value: 0.8 and parameters: {'n_estimators': 1257, 'max_depth': 17, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 26 with value: 0.8699186991869918.\n",
      "[I 2025-12-16 16:20:03,432] Trial 28 finished with value: 0.825 and parameters: {'n_estimators': 1026, 'max_depth': 15, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 26 with value: 0.8699186991869918.\n",
      "[I 2025-12-16 16:20:05,065] Trial 29 finished with value: 0.7254901960784313 and parameters: {'n_estimators': 1008, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 26 with value: 0.8699186991869918.\n",
      "[I 2025-12-16 16:20:05,066] A new study created in memory with name: no-name-fa823b4a-f4b3-4376-b3ac-905e0f329f19\n",
      "[I 2025-12-16 16:20:06,296] Trial 0 finished with value: 0.8153846153846154 and parameters: {'n_layers': 2, 'n_units_l0': 178, 'n_units_l1': 143, 'alpha': 3.6104487435856874e-06, 'learning_rate_init': 0.004251337308388556}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:06,602] Trial 1 finished with value: 0.043795620437956206 and parameters: {'n_layers': 3, 'n_units_l0': 56, 'n_units_l1': 27, 'n_units_l2': 133, 'alpha': 4.794459812713429e-06, 'learning_rate_init': 1.7836434476940953e-05}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:07,031] Trial 2 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 22, 'n_units_l1': 130, 'n_units_l2': 89, 'alpha': 3.329413891888769e-06, 'learning_rate_init': 2.823614133243045e-05}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:07,743] Trial 3 finished with value: 0.7400881057268722 and parameters: {'n_layers': 3, 'n_units_l0': 38, 'n_units_l1': 89, 'n_units_l2': 254, 'alpha': 3.693280758542389e-06, 'learning_rate_init': 0.008473283744745803}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:09,048] Trial 4 finished with value: 0.7085201793721974 and parameters: {'n_layers': 1, 'n_units_l0': 256, 'alpha': 7.914489848486619e-06, 'learning_rate_init': 0.0009139731157339081}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:12,657] Trial 5 finished with value: 0.6814159292035398 and parameters: {'n_layers': 3, 'n_units_l0': 226, 'n_units_l1': 183, 'n_units_l2': 108, 'alpha': 0.0029682725283504425, 'learning_rate_init': 0.00012126697355191397}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:13,067] Trial 6 finished with value: 0.8103448275862069 and parameters: {'n_layers': 1, 'n_units_l0': 114, 'alpha': 4.586696413257707e-05, 'learning_rate_init': 0.04300669361098147}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:13,437] Trial 7 finished with value: 0.6637168141592921 and parameters: {'n_layers': 2, 'n_units_l0': 27, 'n_units_l1': 67, 'alpha': 0.04997361854678933, 'learning_rate_init': 0.0018423643611076704}. Best is trial 0 with value: 0.8153846153846154.\n",
      "[I 2025-12-16 16:20:13,802] Trial 8 finished with value: 0.8326530612244898 and parameters: {'n_layers': 1, 'n_units_l0': 82, 'alpha': 0.0008448321465933152, 'learning_rate_init': 0.05244367929368665}. Best is trial 8 with value: 0.8326530612244898.\n",
      "[I 2025-12-16 16:20:14,523] Trial 9 finished with value: 0.8677685950413223 and parameters: {'n_layers': 1, 'n_units_l0': 255, 'alpha': 0.0381340629804387, 'learning_rate_init': 0.03012696177776058}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:15,840] Trial 10 finished with value: 0.6534653465346535 and parameters: {'n_layers': 2, 'n_units_l0': 161, 'n_units_l1': 254, 'alpha': 0.06113218948991953, 'learning_rate_init': 0.09440973049133473}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:16,249] Trial 11 finished with value: 0.8130081300813008 and parameters: {'n_layers': 1, 'n_units_l0': 101, 'alpha': 0.0016022661037980912, 'learning_rate_init': 0.016558888095465702}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:16,638] Trial 12 finished with value: 0.8253968253968254 and parameters: {'n_layers': 1, 'n_units_l0': 98, 'alpha': 0.005493635295225324, 'learning_rate_init': 0.026631429975269662}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:17,029] Trial 13 finished with value: 0.8535564853556485 and parameters: {'n_layers': 1, 'n_units_l0': 195, 'alpha': 0.0002025802997035063, 'learning_rate_init': 0.09416852088138965}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:18,142] Trial 14 finished with value: 0.6467661691542289 and parameters: {'n_layers': 1, 'n_units_l0': 203, 'alpha': 0.00010568331482478892, 'learning_rate_init': 0.00033023120266818947}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:20,228] Trial 15 finished with value: 0.7692307692307693 and parameters: {'n_layers': 2, 'n_units_l0': 251, 'n_units_l1': 253, 'alpha': 0.009561074805081542, 'learning_rate_init': 0.09981348778040357}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:20,892] Trial 16 finished with value: 0.7966101694915254 and parameters: {'n_layers': 1, 'n_units_l0': 208, 'alpha': 0.00017519660295949228, 'learning_rate_init': 0.007849956649266509}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:21,631] Trial 17 finished with value: 0.7631578947368421 and parameters: {'n_layers': 2, 'n_units_l0': 155, 'n_units_l1': 197, 'alpha': 3.969820746532039e-05, 'learning_rate_init': 0.015297785491999435}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:22,545] Trial 18 finished with value: 0.7477477477477478 and parameters: {'n_layers': 1, 'n_units_l0': 225, 'alpha': 0.0004209441378598353, 'learning_rate_init': 0.0027370064385908344}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:23,673] Trial 19 finished with value: 0.7531380753138075 and parameters: {'n_layers': 2, 'n_units_l0': 192, 'n_units_l1': 30, 'alpha': 0.020992837199316886, 'learning_rate_init': 0.0009459606895248109}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:24,486] Trial 20 finished with value: 0.8368200836820083 and parameters: {'n_layers': 1, 'n_units_l0': 229, 'alpha': 1.5344677160129613e-05, 'learning_rate_init': 0.033867465209384925}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:25,048] Trial 21 finished with value: 0.8425531914893617 and parameters: {'n_layers': 1, 'n_units_l0': 233, 'alpha': 1.8568937242321377e-05, 'learning_rate_init': 0.024739819149816527}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:25,826] Trial 22 finished with value: 0.8163265306122449 and parameters: {'n_layers': 1, 'n_units_l0': 239, 'alpha': 4.5835298173290384e-05, 'learning_rate_init': 0.00959790287422293}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:26,259] Trial 23 finished with value: 0.8451882845188284 and parameters: {'n_layers': 1, 'n_units_l0': 138, 'alpha': 1.0070842356739097e-06, 'learning_rate_init': 0.05948244835975531}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:26,739] Trial 24 finished with value: 0.8650793650793651 and parameters: {'n_layers': 1, 'n_units_l0': 134, 'alpha': 0.000499851197838236, 'learning_rate_init': 0.06459393559676656}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:26,937] Trial 25 finished with value: 0.703862660944206 and parameters: {'n_layers': 1, 'n_units_l0': 129, 'alpha': 0.00041550494700616497, 'learning_rate_init': 0.09490878722356903}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:28,073] Trial 26 finished with value: 0.8326530612244898 and parameters: {'n_layers': 2, 'n_units_l0': 168, 'n_units_l1': 193, 'alpha': 0.0008538865066135252, 'learning_rate_init': 0.005062715953319704}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:28,550] Trial 27 finished with value: 0.8244897959183674 and parameters: {'n_layers': 1, 'n_units_l0': 145, 'alpha': 0.017794645034478012, 'learning_rate_init': 0.021600222412693784}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:29,491] Trial 28 finished with value: 0.831858407079646 and parameters: {'n_layers': 2, 'n_units_l0': 186, 'n_units_l1': 99, 'alpha': 0.00012162529178523755, 'learning_rate_init': 0.04810928421893508}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:30,455] Trial 29 finished with value: 0.7456140350877193 and parameters: {'n_layers': 2, 'n_units_l0': 204, 'n_units_l1': 153, 'alpha': 0.0032649372048496267, 'learning_rate_init': 0.0034566506436779975}. Best is trial 9 with value: 0.8677685950413223.\n",
      "[I 2025-12-16 16:20:30,456] A new study created in memory with name: no-name-a2e53853-f587-4581-bad9-7846206a60c4\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l2 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:30,485] Trial 0 finished with value: 0.49411764705882355 and parameters: {'C': 0.019692486369819732, 'penalty': 'l2'}. Best is trial 0 with value: 0.49411764705882355.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:30,518] Trial 1 finished with value: 0.5918367346938775 and parameters: {'C': 0.17528243831617807, 'penalty': 'l1'}. Best is trial 1 with value: 0.5918367346938775.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:31,490] Trial 2 finished with value: 0.5970149253731343 and parameters: {'C': 1.712847924394454, 'penalty': 'elasticnet', 'l1_ratio': 0.6759589649095973}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:31,512] Trial 3 finished with value: 0.0 and parameters: {'C': 0.00023709422182704366, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:32,645] Trial 4 finished with value: 0.5865384615384616 and parameters: {'C': 4.86251645062126, 'penalty': 'elasticnet', 'l1_ratio': 0.3642149488565223}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:32,760] Trial 5 finished with value: 0.5340314136125655 and parameters: {'C': 0.06196327299464855, 'penalty': 'elasticnet', 'l1_ratio': 0.44870957501984055}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:32,840] Trial 6 finished with value: 0.5027932960893855 and parameters: {'C': 0.03533804359068681, 'penalty': 'elasticnet', 'l1_ratio': 0.2854162392475457}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:32,872] Trial 7 finished with value: 0.5922330097087378 and parameters: {'C': 86.11124545767248, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:33,136] Trial 8 finished with value: 0.5893719806763285 and parameters: {'C': 17.477637873289655, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:33,181] Trial 9 finished with value: 0.0 and parameters: {'C': 0.0013384773763070942, 'penalty': 'elasticnet', 'l1_ratio': 0.5040187352073898}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l2 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:33,221] Trial 10 finished with value: 0.5784313725490197 and parameters: {'C': 1.663292707644189, 'penalty': 'l2'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:33,629] Trial 11 finished with value: 0.5893719806763285 and parameters: {'C': 41.0144680614035, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:33,916] Trial 12 finished with value: 0.5922330097087378 and parameters: {'C': 88.37317583850817, 'penalty': 'elasticnet', 'l1_ratio': 0.8753134864422786}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:33,974] Trial 13 finished with value: 0.592964824120603 and parameters: {'C': 0.7032181382855018, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l2 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:34,017] Trial 14 finished with value: 0.5728643216080402 and parameters: {'C': 0.6495615687341073, 'penalty': 'l2'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:34,540] Trial 15 finished with value: 0.5829145728643216 and parameters: {'C': 0.4429021224287477, 'penalty': 'elasticnet', 'l1_ratio': 0.7503525916253659}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:34,683] Trial 16 finished with value: 0.5893719806763285 and parameters: {'C': 5.204483588277637, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:34,729] Trial 17 finished with value: 0.3821656050955414 and parameters: {'C': 0.01186413396164535, 'penalty': 'elasticnet', 'l1_ratio': 0.10331841878511444}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:34,809] Trial 18 finished with value: 0.594059405940594 and parameters: {'C': 2.169421630434709, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l2 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:34,848] Trial 19 finished with value: 0.5893719806763285 and parameters: {'C': 6.27064993934503, 'penalty': 'l2'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,069] Trial 20 finished with value: 0.5888324873096447 and parameters: {'C': 0.15332162185548046, 'penalty': 'elasticnet', 'l1_ratio': 0.623831549539353}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,132] Trial 21 finished with value: 0.59 and parameters: {'C': 1.2676626296608273, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,227] Trial 22 finished with value: 0.5951219512195122 and parameters: {'C': 2.9906326260333134, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,462] Trial 23 finished with value: 0.5865384615384616 and parameters: {'C': 9.601351808764276, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,542] Trial 24 finished with value: 0.5911330049261084 and parameters: {'C': 2.335891335751098, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,797] Trial 25 finished with value: 0.5893719806763285 and parameters: {'C': 21.718005075115684, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,823] Trial 26 finished with value: 0.0 and parameters: {'C': 0.005673086689952173, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l1 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,921] Trial 27 finished with value: 0.5951219512195122 and parameters: {'C': 3.0931029904909737, 'penalty': 'l1'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1160: UserWarning: Inconsistent values: penalty=l2 with l1_ratio=None. penalty is deprecated. Please use l1_ratio only.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:35,958] Trial 28 finished with value: 0.5757575757575758 and parameters: {'C': 0.3163588210798382, 'penalty': 'l2'}. Best is trial 2 with value: 0.5970149253731343.\n",
      "c:\\Users\\t.gumerov\\final_certification\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1135: FutureWarning: 'penalty' was deprecated in version 1.8 and will be removed in 1.10. To avoid this warning, leave 'penalty' set to its default value and use 'l1_ratio' or 'C' instead. Use l1_ratio=0 instead of penalty='l2', l1_ratio=1 instead of penalty='l1', and C=np.inf instead of penalty=None.\n",
      "  warnings.warn(\n",
      "[I 2025-12-16 16:20:36,798] Trial 29 finished with value: 0.5865384615384616 and parameters: {'C': 14.436747864036622, 'penalty': 'elasticnet', 'l1_ratio': 0.6577410381480613}. Best is trial 2 with value: 0.5970149253731343.\n"
     ]
    }
   ],
   "source": [
    "study_cb = optuna.create_study(direction=\"maximize\")\n",
    "study_cb.optimize(objective_catboost, n_trials=30)\n",
    "\n",
    "study_rf = optuna.create_study(direction=\"maximize\")\n",
    "study_rf.optimize(objective_rf, n_trials=30)\n",
    "\n",
    "study_mlp = optuna.create_study(direction=\"maximize\")\n",
    "study_mlp.optimize(objective_mlp, n_trials=30)\n",
    "\n",
    "study_logreg = optuna.create_study(direction=\"maximize\")\n",
    "study_logreg.optimize(objective_logreg, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "137f0a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.919831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.869919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.867769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model        F1\n",
       "0      CatBoost  0.919831\n",
       "1  RandomForest  0.869919\n",
       "2           MLP  0.867769\n",
       "3        LogReg  0.597015"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_opt = pd.DataFrame({\n",
    "    \"Model\":['CatBoost','RandomForest','MLP','LogReg'],\n",
    "    'F1':[study_cb.best_value,study_rf.best_value,study_mlp.best_value,study_logreg.best_value]\n",
    "})\n",
    "results_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c58ed4",
   "metadata": {},
   "source": [
    "После подбора гиперпараметров победил catboost по метрике f1. Буду использовать его его\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e598681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 1875, 'learning_rate': 0.10851878131004626, 'depth': 8}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_cb = study_cb.best_params\n",
    "best_params_cb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58195992",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = X_train_full.select_dtypes(exclude='number').columns.to_list()\n",
    "#eval_pool = Pool(X_val,y_val,cat_features=cat_columns)\n",
    "train_pool = Pool(X_train_full,y_train_full,cat_features=cat_columns)\n",
    "model_cb = CatBoostClassifier(**best_params_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29f0c41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5627634\ttotal: 26.6ms\tremaining: 49.9s\n",
      "1:\tlearn: 0.4836832\ttotal: 50.3ms\tremaining: 47.1s\n",
      "2:\tlearn: 0.4172228\ttotal: 80.6ms\tremaining: 50.3s\n",
      "3:\tlearn: 0.3702825\ttotal: 111ms\tremaining: 51.7s\n",
      "4:\tlearn: 0.3266664\ttotal: 141ms\tremaining: 52.6s\n",
      "5:\tlearn: 0.2970193\ttotal: 171ms\tremaining: 53.3s\n",
      "6:\tlearn: 0.2755856\ttotal: 201ms\tremaining: 53.5s\n",
      "7:\tlearn: 0.2540558\ttotal: 231ms\tremaining: 53.9s\n",
      "8:\tlearn: 0.2356725\ttotal: 261ms\tremaining: 54.1s\n",
      "9:\tlearn: 0.2213768\ttotal: 290ms\tremaining: 54.2s\n",
      "10:\tlearn: 0.2202210\ttotal: 297ms\tremaining: 50.4s\n",
      "11:\tlearn: 0.2127641\ttotal: 327ms\tremaining: 50.7s\n",
      "12:\tlearn: 0.2065083\ttotal: 357ms\tremaining: 51.1s\n",
      "13:\tlearn: 0.1966973\ttotal: 387ms\tremaining: 51.4s\n",
      "14:\tlearn: 0.1920180\ttotal: 417ms\tremaining: 51.7s\n",
      "15:\tlearn: 0.1860683\ttotal: 446ms\tremaining: 51.8s\n",
      "16:\tlearn: 0.1800141\ttotal: 476ms\tremaining: 52s\n",
      "17:\tlearn: 0.1757056\ttotal: 508ms\tremaining: 52.4s\n",
      "18:\tlearn: 0.1713530\ttotal: 539ms\tremaining: 52.6s\n",
      "19:\tlearn: 0.1668231\ttotal: 568ms\tremaining: 52.7s\n",
      "20:\tlearn: 0.1633107\ttotal: 598ms\tremaining: 52.8s\n",
      "21:\tlearn: 0.1627175\ttotal: 617ms\tremaining: 52s\n",
      "22:\tlearn: 0.1578715\ttotal: 645ms\tremaining: 52s\n",
      "23:\tlearn: 0.1563917\ttotal: 674ms\tremaining: 52s\n",
      "24:\tlearn: 0.1544913\ttotal: 705ms\tremaining: 52.1s\n",
      "25:\tlearn: 0.1526096\ttotal: 735ms\tremaining: 52.3s\n",
      "26:\tlearn: 0.1501314\ttotal: 766ms\tremaining: 52.4s\n",
      "27:\tlearn: 0.1483875\ttotal: 796ms\tremaining: 52.5s\n",
      "28:\tlearn: 0.1463662\ttotal: 827ms\tremaining: 52.6s\n",
      "29:\tlearn: 0.1440852\ttotal: 856ms\tremaining: 52.6s\n",
      "30:\tlearn: 0.1407882\ttotal: 886ms\tremaining: 52.7s\n",
      "31:\tlearn: 0.1354227\ttotal: 916ms\tremaining: 52.7s\n",
      "32:\tlearn: 0.1314075\ttotal: 946ms\tremaining: 52.8s\n",
      "33:\tlearn: 0.1283845\ttotal: 976ms\tremaining: 52.8s\n",
      "34:\tlearn: 0.1274855\ttotal: 1s\tremaining: 52.9s\n",
      "35:\tlearn: 0.1251654\ttotal: 1.03s\tremaining: 52.9s\n",
      "36:\tlearn: 0.1235621\ttotal: 1.06s\tremaining: 52.9s\n",
      "37:\tlearn: 0.1221128\ttotal: 1.09s\tremaining: 52.9s\n",
      "38:\tlearn: 0.1209924\ttotal: 1.12s\tremaining: 53s\n",
      "39:\tlearn: 0.1192509\ttotal: 1.15s\tremaining: 53s\n",
      "40:\tlearn: 0.1179806\ttotal: 1.19s\tremaining: 53s\n",
      "41:\tlearn: 0.1163664\ttotal: 1.21s\tremaining: 53s\n",
      "42:\tlearn: 0.1157808\ttotal: 1.25s\tremaining: 53.1s\n",
      "43:\tlearn: 0.1152567\ttotal: 1.29s\tremaining: 53.5s\n",
      "44:\tlearn: 0.1146746\ttotal: 1.32s\tremaining: 53.5s\n",
      "45:\tlearn: 0.1124693\ttotal: 1.35s\tremaining: 53.5s\n",
      "46:\tlearn: 0.1124674\ttotal: 1.35s\tremaining: 52.7s\n",
      "47:\tlearn: 0.1116566\ttotal: 1.38s\tremaining: 52.7s\n",
      "48:\tlearn: 0.1083112\ttotal: 1.41s\tremaining: 52.7s\n",
      "49:\tlearn: 0.1056230\ttotal: 1.44s\tremaining: 52.7s\n",
      "50:\tlearn: 0.1043173\ttotal: 1.49s\tremaining: 53.2s\n",
      "51:\tlearn: 0.1024218\ttotal: 1.52s\tremaining: 53.2s\n",
      "52:\tlearn: 0.0990179\ttotal: 1.55s\tremaining: 53.2s\n",
      "53:\tlearn: 0.0968805\ttotal: 1.58s\tremaining: 53.2s\n",
      "54:\tlearn: 0.0946946\ttotal: 1.61s\tremaining: 53.4s\n",
      "55:\tlearn: 0.0940852\ttotal: 1.64s\tremaining: 53.4s\n",
      "56:\tlearn: 0.0918552\ttotal: 1.67s\tremaining: 53.4s\n",
      "57:\tlearn: 0.0898049\ttotal: 1.7s\tremaining: 53.3s\n",
      "58:\tlearn: 0.0889965\ttotal: 1.73s\tremaining: 53.3s\n",
      "59:\tlearn: 0.0874399\ttotal: 1.76s\tremaining: 53.3s\n",
      "60:\tlearn: 0.0858036\ttotal: 1.79s\tremaining: 53.3s\n",
      "61:\tlearn: 0.0845704\ttotal: 1.82s\tremaining: 53.3s\n",
      "62:\tlearn: 0.0833452\ttotal: 1.85s\tremaining: 53.3s\n",
      "63:\tlearn: 0.0819860\ttotal: 1.88s\tremaining: 53.3s\n",
      "64:\tlearn: 0.0815063\ttotal: 1.92s\tremaining: 53.4s\n",
      "65:\tlearn: 0.0805720\ttotal: 1.95s\tremaining: 53.3s\n",
      "66:\tlearn: 0.0793068\ttotal: 1.98s\tremaining: 53.3s\n",
      "67:\tlearn: 0.0782416\ttotal: 2.01s\tremaining: 53.4s\n",
      "68:\tlearn: 0.0771788\ttotal: 2.04s\tremaining: 53.4s\n",
      "69:\tlearn: 0.0758421\ttotal: 2.07s\tremaining: 53.4s\n",
      "70:\tlearn: 0.0751156\ttotal: 2.1s\tremaining: 53.3s\n",
      "71:\tlearn: 0.0742618\ttotal: 2.13s\tremaining: 53.3s\n",
      "72:\tlearn: 0.0733026\ttotal: 2.16s\tremaining: 53.3s\n",
      "73:\tlearn: 0.0725562\ttotal: 2.19s\tremaining: 53.3s\n",
      "74:\tlearn: 0.0716421\ttotal: 2.22s\tremaining: 53.2s\n",
      "75:\tlearn: 0.0708145\ttotal: 2.25s\tremaining: 53.2s\n",
      "76:\tlearn: 0.0705426\ttotal: 2.28s\tremaining: 53.2s\n",
      "77:\tlearn: 0.0701156\ttotal: 2.31s\tremaining: 53.2s\n",
      "78:\tlearn: 0.0701136\ttotal: 2.32s\tremaining: 52.8s\n",
      "79:\tlearn: 0.0693656\ttotal: 2.35s\tremaining: 52.7s\n",
      "80:\tlearn: 0.0687567\ttotal: 2.38s\tremaining: 52.7s\n",
      "81:\tlearn: 0.0679011\ttotal: 2.41s\tremaining: 52.7s\n",
      "82:\tlearn: 0.0676087\ttotal: 2.44s\tremaining: 52.6s\n",
      "83:\tlearn: 0.0664339\ttotal: 2.47s\tremaining: 52.6s\n",
      "84:\tlearn: 0.0657138\ttotal: 2.5s\tremaining: 52.6s\n",
      "85:\tlearn: 0.0644681\ttotal: 2.53s\tremaining: 52.6s\n",
      "86:\tlearn: 0.0633195\ttotal: 2.56s\tremaining: 52.6s\n",
      "87:\tlearn: 0.0625157\ttotal: 2.59s\tremaining: 52.5s\n",
      "88:\tlearn: 0.0622577\ttotal: 2.62s\tremaining: 52.5s\n",
      "89:\tlearn: 0.0601946\ttotal: 2.65s\tremaining: 52.5s\n",
      "90:\tlearn: 0.0597653\ttotal: 2.67s\tremaining: 52.5s\n",
      "91:\tlearn: 0.0594649\ttotal: 2.71s\tremaining: 52.5s\n",
      "92:\tlearn: 0.0585745\ttotal: 2.74s\tremaining: 52.5s\n",
      "93:\tlearn: 0.0573599\ttotal: 2.77s\tremaining: 52.4s\n",
      "94:\tlearn: 0.0556005\ttotal: 2.79s\tremaining: 52.4s\n",
      "95:\tlearn: 0.0555999\ttotal: 2.81s\tremaining: 52s\n",
      "96:\tlearn: 0.0547445\ttotal: 2.84s\tremaining: 52s\n",
      "97:\tlearn: 0.0535161\ttotal: 2.87s\tremaining: 52s\n",
      "98:\tlearn: 0.0530853\ttotal: 2.9s\tremaining: 52s\n",
      "99:\tlearn: 0.0517720\ttotal: 2.92s\tremaining: 51.9s\n",
      "100:\tlearn: 0.0515940\ttotal: 2.96s\tremaining: 51.9s\n",
      "101:\tlearn: 0.0508549\ttotal: 2.98s\tremaining: 51.9s\n",
      "102:\tlearn: 0.0505451\ttotal: 3.01s\tremaining: 51.9s\n",
      "103:\tlearn: 0.0496445\ttotal: 3.04s\tremaining: 51.8s\n",
      "104:\tlearn: 0.0494471\ttotal: 3.07s\tremaining: 51.8s\n",
      "105:\tlearn: 0.0491705\ttotal: 3.1s\tremaining: 51.8s\n",
      "106:\tlearn: 0.0490165\ttotal: 3.13s\tremaining: 51.8s\n",
      "107:\tlearn: 0.0483459\ttotal: 3.16s\tremaining: 51.8s\n",
      "108:\tlearn: 0.0474357\ttotal: 3.19s\tremaining: 51.7s\n",
      "109:\tlearn: 0.0471123\ttotal: 3.22s\tremaining: 51.7s\n",
      "110:\tlearn: 0.0470458\ttotal: 3.25s\tremaining: 51.7s\n",
      "111:\tlearn: 0.0469834\ttotal: 3.28s\tremaining: 51.7s\n",
      "112:\tlearn: 0.0464362\ttotal: 3.31s\tremaining: 51.7s\n",
      "113:\tlearn: 0.0459157\ttotal: 3.34s\tremaining: 51.6s\n",
      "114:\tlearn: 0.0458473\ttotal: 3.37s\tremaining: 51.6s\n",
      "115:\tlearn: 0.0453414\ttotal: 3.4s\tremaining: 51.6s\n",
      "116:\tlearn: 0.0448120\ttotal: 3.43s\tremaining: 51.6s\n",
      "117:\tlearn: 0.0445159\ttotal: 3.46s\tremaining: 51.5s\n",
      "118:\tlearn: 0.0443582\ttotal: 3.49s\tremaining: 51.6s\n",
      "119:\tlearn: 0.0440409\ttotal: 3.52s\tremaining: 51.5s\n",
      "120:\tlearn: 0.0437863\ttotal: 3.55s\tremaining: 51.5s\n",
      "121:\tlearn: 0.0436883\ttotal: 3.58s\tremaining: 51.5s\n",
      "122:\tlearn: 0.0429898\ttotal: 3.61s\tremaining: 51.5s\n",
      "123:\tlearn: 0.0427491\ttotal: 3.64s\tremaining: 51.4s\n",
      "124:\tlearn: 0.0425964\ttotal: 3.67s\tremaining: 51.4s\n",
      "125:\tlearn: 0.0416866\ttotal: 3.7s\tremaining: 51.4s\n",
      "126:\tlearn: 0.0411821\ttotal: 3.73s\tremaining: 51.4s\n",
      "127:\tlearn: 0.0404750\ttotal: 3.76s\tremaining: 51.4s\n",
      "128:\tlearn: 0.0403622\ttotal: 3.79s\tremaining: 51.4s\n",
      "129:\tlearn: 0.0397819\ttotal: 3.82s\tremaining: 51.3s\n",
      "130:\tlearn: 0.0396819\ttotal: 3.85s\tremaining: 51.3s\n",
      "131:\tlearn: 0.0391924\ttotal: 3.89s\tremaining: 51.3s\n",
      "132:\tlearn: 0.0380039\ttotal: 3.92s\tremaining: 51.3s\n",
      "133:\tlearn: 0.0377329\ttotal: 3.96s\tremaining: 51.4s\n",
      "134:\tlearn: 0.0372305\ttotal: 3.99s\tremaining: 51.4s\n",
      "135:\tlearn: 0.0371311\ttotal: 4.02s\tremaining: 51.4s\n",
      "136:\tlearn: 0.0364673\ttotal: 4.05s\tremaining: 51.4s\n",
      "137:\tlearn: 0.0361291\ttotal: 4.08s\tremaining: 51.3s\n",
      "138:\tlearn: 0.0355968\ttotal: 4.11s\tremaining: 51.3s\n",
      "139:\tlearn: 0.0352569\ttotal: 4.14s\tremaining: 51.3s\n",
      "140:\tlearn: 0.0351582\ttotal: 4.17s\tremaining: 51.3s\n",
      "141:\tlearn: 0.0348131\ttotal: 4.2s\tremaining: 51.3s\n",
      "142:\tlearn: 0.0341930\ttotal: 4.23s\tremaining: 51.2s\n",
      "143:\tlearn: 0.0339057\ttotal: 4.26s\tremaining: 51.2s\n",
      "144:\tlearn: 0.0335683\ttotal: 4.29s\tremaining: 51.2s\n",
      "145:\tlearn: 0.0333396\ttotal: 4.32s\tremaining: 51.1s\n",
      "146:\tlearn: 0.0328871\ttotal: 4.35s\tremaining: 51.1s\n",
      "147:\tlearn: 0.0325326\ttotal: 4.38s\tremaining: 51.1s\n",
      "148:\tlearn: 0.0321390\ttotal: 4.41s\tremaining: 51.1s\n",
      "149:\tlearn: 0.0319801\ttotal: 4.44s\tremaining: 51.1s\n",
      "150:\tlearn: 0.0314959\ttotal: 4.47s\tremaining: 51s\n",
      "151:\tlearn: 0.0311207\ttotal: 4.5s\tremaining: 51s\n",
      "152:\tlearn: 0.0308755\ttotal: 4.53s\tremaining: 51s\n",
      "153:\tlearn: 0.0305918\ttotal: 4.56s\tremaining: 50.9s\n",
      "154:\tlearn: 0.0301517\ttotal: 4.58s\tremaining: 50.9s\n",
      "155:\tlearn: 0.0295728\ttotal: 4.62s\tremaining: 50.9s\n",
      "156:\tlearn: 0.0290999\ttotal: 4.64s\tremaining: 50.8s\n",
      "157:\tlearn: 0.0287115\ttotal: 4.68s\tremaining: 50.8s\n",
      "158:\tlearn: 0.0282942\ttotal: 4.71s\tremaining: 50.8s\n",
      "159:\tlearn: 0.0279705\ttotal: 4.73s\tremaining: 50.8s\n",
      "160:\tlearn: 0.0274471\ttotal: 4.76s\tremaining: 50.7s\n",
      "161:\tlearn: 0.0269434\ttotal: 4.79s\tremaining: 50.7s\n",
      "162:\tlearn: 0.0266662\ttotal: 4.82s\tremaining: 50.7s\n",
      "163:\tlearn: 0.0261851\ttotal: 4.85s\tremaining: 50.6s\n",
      "164:\tlearn: 0.0256039\ttotal: 4.88s\tremaining: 50.6s\n",
      "165:\tlearn: 0.0254387\ttotal: 4.91s\tremaining: 50.6s\n",
      "166:\tlearn: 0.0250121\ttotal: 4.94s\tremaining: 50.6s\n",
      "167:\tlearn: 0.0249075\ttotal: 4.97s\tremaining: 50.5s\n",
      "168:\tlearn: 0.0247584\ttotal: 5s\tremaining: 50.5s\n",
      "169:\tlearn: 0.0245881\ttotal: 5.03s\tremaining: 50.5s\n",
      "170:\tlearn: 0.0243144\ttotal: 5.06s\tremaining: 50.5s\n",
      "171:\tlearn: 0.0239929\ttotal: 5.09s\tremaining: 50.4s\n",
      "172:\tlearn: 0.0236668\ttotal: 5.12s\tremaining: 50.4s\n",
      "173:\tlearn: 0.0233455\ttotal: 5.15s\tremaining: 50.4s\n",
      "174:\tlearn: 0.0232322\ttotal: 5.18s\tremaining: 50.3s\n",
      "175:\tlearn: 0.0230319\ttotal: 5.21s\tremaining: 50.3s\n",
      "176:\tlearn: 0.0227860\ttotal: 5.24s\tremaining: 50.3s\n",
      "177:\tlearn: 0.0225405\ttotal: 5.27s\tremaining: 50.3s\n",
      "178:\tlearn: 0.0222044\ttotal: 5.3s\tremaining: 50.2s\n",
      "179:\tlearn: 0.0220052\ttotal: 5.33s\tremaining: 50.2s\n",
      "180:\tlearn: 0.0218438\ttotal: 5.36s\tremaining: 50.2s\n",
      "181:\tlearn: 0.0218111\ttotal: 5.39s\tremaining: 50.2s\n",
      "182:\tlearn: 0.0216750\ttotal: 5.42s\tremaining: 50.1s\n",
      "183:\tlearn: 0.0215291\ttotal: 5.45s\tremaining: 50.1s\n",
      "184:\tlearn: 0.0213355\ttotal: 5.48s\tremaining: 50.1s\n",
      "185:\tlearn: 0.0211109\ttotal: 5.51s\tremaining: 50s\n",
      "186:\tlearn: 0.0209104\ttotal: 5.55s\tremaining: 50.1s\n",
      "187:\tlearn: 0.0206043\ttotal: 5.58s\tremaining: 50.1s\n",
      "188:\tlearn: 0.0205199\ttotal: 5.61s\tremaining: 50.1s\n",
      "189:\tlearn: 0.0203152\ttotal: 5.64s\tremaining: 50.1s\n",
      "190:\tlearn: 0.0202957\ttotal: 5.67s\tremaining: 50s\n",
      "191:\tlearn: 0.0200965\ttotal: 5.7s\tremaining: 50s\n",
      "192:\tlearn: 0.0198536\ttotal: 5.73s\tremaining: 50s\n",
      "193:\tlearn: 0.0197397\ttotal: 5.76s\tremaining: 49.9s\n",
      "194:\tlearn: 0.0195094\ttotal: 5.79s\tremaining: 49.9s\n",
      "195:\tlearn: 0.0193137\ttotal: 5.82s\tremaining: 49.9s\n",
      "196:\tlearn: 0.0191950\ttotal: 5.85s\tremaining: 49.8s\n",
      "197:\tlearn: 0.0191117\ttotal: 5.88s\tremaining: 49.8s\n",
      "198:\tlearn: 0.0190112\ttotal: 5.91s\tremaining: 49.8s\n",
      "199:\tlearn: 0.0188823\ttotal: 5.94s\tremaining: 49.8s\n",
      "200:\tlearn: 0.0187901\ttotal: 5.97s\tremaining: 49.7s\n",
      "201:\tlearn: 0.0187771\ttotal: 6s\tremaining: 49.7s\n",
      "202:\tlearn: 0.0187506\ttotal: 6.03s\tremaining: 49.7s\n",
      "203:\tlearn: 0.0186457\ttotal: 6.06s\tremaining: 49.6s\n",
      "204:\tlearn: 0.0184099\ttotal: 6.09s\tremaining: 49.6s\n",
      "205:\tlearn: 0.0183996\ttotal: 6.12s\tremaining: 49.6s\n",
      "206:\tlearn: 0.0183856\ttotal: 6.15s\tremaining: 49.5s\n",
      "207:\tlearn: 0.0182760\ttotal: 6.18s\tremaining: 49.5s\n",
      "208:\tlearn: 0.0182138\ttotal: 6.21s\tremaining: 49.5s\n",
      "209:\tlearn: 0.0180327\ttotal: 6.24s\tremaining: 49.5s\n",
      "210:\tlearn: 0.0178869\ttotal: 6.27s\tremaining: 49.4s\n",
      "211:\tlearn: 0.0178697\ttotal: 6.3s\tremaining: 49.4s\n",
      "212:\tlearn: 0.0177511\ttotal: 6.33s\tremaining: 49.4s\n",
      "213:\tlearn: 0.0177036\ttotal: 6.36s\tremaining: 49.3s\n",
      "214:\tlearn: 0.0176463\ttotal: 6.39s\tremaining: 49.3s\n",
      "215:\tlearn: 0.0176128\ttotal: 6.42s\tremaining: 49.3s\n",
      "216:\tlearn: 0.0175549\ttotal: 6.45s\tremaining: 49.3s\n",
      "217:\tlearn: 0.0173912\ttotal: 6.47s\tremaining: 49.2s\n",
      "218:\tlearn: 0.0172304\ttotal: 6.5s\tremaining: 49.2s\n",
      "219:\tlearn: 0.0171774\ttotal: 6.54s\tremaining: 49.2s\n",
      "220:\tlearn: 0.0169631\ttotal: 6.57s\tremaining: 49.1s\n",
      "221:\tlearn: 0.0167847\ttotal: 6.59s\tremaining: 49.1s\n",
      "222:\tlearn: 0.0167121\ttotal: 6.62s\tremaining: 49.1s\n",
      "223:\tlearn: 0.0163860\ttotal: 6.65s\tremaining: 49s\n",
      "224:\tlearn: 0.0163566\ttotal: 6.68s\tremaining: 49s\n",
      "225:\tlearn: 0.0162477\ttotal: 6.71s\tremaining: 49s\n",
      "226:\tlearn: 0.0161378\ttotal: 6.74s\tremaining: 49s\n",
      "227:\tlearn: 0.0159851\ttotal: 6.77s\tremaining: 48.9s\n",
      "228:\tlearn: 0.0159412\ttotal: 6.8s\tremaining: 48.9s\n",
      "229:\tlearn: 0.0157686\ttotal: 6.83s\tremaining: 48.9s\n",
      "230:\tlearn: 0.0156706\ttotal: 6.86s\tremaining: 48.8s\n",
      "231:\tlearn: 0.0155438\ttotal: 6.89s\tremaining: 48.8s\n",
      "232:\tlearn: 0.0154874\ttotal: 6.92s\tremaining: 48.8s\n",
      "233:\tlearn: 0.0153604\ttotal: 6.95s\tremaining: 48.7s\n",
      "234:\tlearn: 0.0152533\ttotal: 6.98s\tremaining: 48.7s\n",
      "235:\tlearn: 0.0151497\ttotal: 7.01s\tremaining: 48.7s\n",
      "236:\tlearn: 0.0150248\ttotal: 7.04s\tremaining: 48.6s\n",
      "237:\tlearn: 0.0149002\ttotal: 7.07s\tremaining: 48.6s\n",
      "238:\tlearn: 0.0146762\ttotal: 7.1s\tremaining: 48.6s\n",
      "239:\tlearn: 0.0146393\ttotal: 7.13s\tremaining: 48.6s\n",
      "240:\tlearn: 0.0145376\ttotal: 7.16s\tremaining: 48.5s\n",
      "241:\tlearn: 0.0144905\ttotal: 7.2s\tremaining: 48.6s\n",
      "242:\tlearn: 0.0144808\ttotal: 7.25s\tremaining: 48.7s\n",
      "243:\tlearn: 0.0144561\ttotal: 7.29s\tremaining: 48.7s\n",
      "244:\tlearn: 0.0142651\ttotal: 7.32s\tremaining: 48.7s\n",
      "245:\tlearn: 0.0141726\ttotal: 7.34s\tremaining: 48.6s\n",
      "246:\tlearn: 0.0141365\ttotal: 7.38s\tremaining: 48.6s\n",
      "247:\tlearn: 0.0139896\ttotal: 7.4s\tremaining: 48.6s\n",
      "248:\tlearn: 0.0138928\ttotal: 7.43s\tremaining: 48.5s\n",
      "249:\tlearn: 0.0138735\ttotal: 7.46s\tremaining: 48.5s\n",
      "250:\tlearn: 0.0137165\ttotal: 7.49s\tremaining: 48.5s\n",
      "251:\tlearn: 0.0135767\ttotal: 7.52s\tremaining: 48.5s\n",
      "252:\tlearn: 0.0135015\ttotal: 7.55s\tremaining: 48.4s\n",
      "253:\tlearn: 0.0133999\ttotal: 7.58s\tremaining: 48.4s\n",
      "254:\tlearn: 0.0133053\ttotal: 7.61s\tremaining: 48.4s\n",
      "255:\tlearn: 0.0131897\ttotal: 7.64s\tremaining: 48.3s\n",
      "256:\tlearn: 0.0131297\ttotal: 7.67s\tremaining: 48.3s\n",
      "257:\tlearn: 0.0130374\ttotal: 7.7s\tremaining: 48.3s\n",
      "258:\tlearn: 0.0129054\ttotal: 7.74s\tremaining: 48.3s\n",
      "259:\tlearn: 0.0127910\ttotal: 7.77s\tremaining: 48.3s\n",
      "260:\tlearn: 0.0127151\ttotal: 7.8s\tremaining: 48.2s\n",
      "261:\tlearn: 0.0126345\ttotal: 7.83s\tremaining: 48.2s\n",
      "262:\tlearn: 0.0125202\ttotal: 7.86s\tremaining: 48.2s\n",
      "263:\tlearn: 0.0124268\ttotal: 7.89s\tremaining: 48.2s\n",
      "264:\tlearn: 0.0123439\ttotal: 7.92s\tremaining: 48.1s\n",
      "265:\tlearn: 0.0122718\ttotal: 7.95s\tremaining: 48.1s\n",
      "266:\tlearn: 0.0122125\ttotal: 7.98s\tremaining: 48.1s\n",
      "267:\tlearn: 0.0121365\ttotal: 8.01s\tremaining: 48s\n",
      "268:\tlearn: 0.0120451\ttotal: 8.04s\tremaining: 48s\n",
      "269:\tlearn: 0.0120282\ttotal: 8.07s\tremaining: 48s\n",
      "270:\tlearn: 0.0119717\ttotal: 8.1s\tremaining: 47.9s\n",
      "271:\tlearn: 0.0119498\ttotal: 8.13s\tremaining: 47.9s\n",
      "272:\tlearn: 0.0118199\ttotal: 8.16s\tremaining: 47.9s\n",
      "273:\tlearn: 0.0117929\ttotal: 8.19s\tremaining: 47.9s\n",
      "274:\tlearn: 0.0116894\ttotal: 8.22s\tremaining: 47.8s\n",
      "275:\tlearn: 0.0116200\ttotal: 8.26s\tremaining: 47.8s\n",
      "276:\tlearn: 0.0115858\ttotal: 8.29s\tremaining: 47.8s\n",
      "277:\tlearn: 0.0115376\ttotal: 8.31s\tremaining: 47.8s\n",
      "278:\tlearn: 0.0114021\ttotal: 8.35s\tremaining: 47.7s\n",
      "279:\tlearn: 0.0113576\ttotal: 8.38s\tremaining: 47.7s\n",
      "280:\tlearn: 0.0112978\ttotal: 8.4s\tremaining: 47.7s\n",
      "281:\tlearn: 0.0112139\ttotal: 8.43s\tremaining: 47.6s\n",
      "282:\tlearn: 0.0111337\ttotal: 8.46s\tremaining: 47.6s\n",
      "283:\tlearn: 0.0110541\ttotal: 8.49s\tremaining: 47.6s\n",
      "284:\tlearn: 0.0109858\ttotal: 8.52s\tremaining: 47.5s\n",
      "285:\tlearn: 0.0108873\ttotal: 8.55s\tremaining: 47.5s\n",
      "286:\tlearn: 0.0108362\ttotal: 8.58s\tremaining: 47.5s\n",
      "287:\tlearn: 0.0108198\ttotal: 8.61s\tremaining: 47.5s\n",
      "288:\tlearn: 0.0107282\ttotal: 8.64s\tremaining: 47.4s\n",
      "289:\tlearn: 0.0106521\ttotal: 8.67s\tremaining: 47.4s\n",
      "290:\tlearn: 0.0105603\ttotal: 8.7s\tremaining: 47.4s\n",
      "291:\tlearn: 0.0104693\ttotal: 8.73s\tremaining: 47.3s\n",
      "292:\tlearn: 0.0104047\ttotal: 8.76s\tremaining: 47.3s\n",
      "293:\tlearn: 0.0103362\ttotal: 8.79s\tremaining: 47.3s\n",
      "294:\tlearn: 0.0102365\ttotal: 8.82s\tremaining: 47.2s\n",
      "295:\tlearn: 0.0101633\ttotal: 8.85s\tremaining: 47.2s\n",
      "296:\tlearn: 0.0100393\ttotal: 8.88s\tremaining: 47.2s\n",
      "297:\tlearn: 0.0099120\ttotal: 8.91s\tremaining: 47.2s\n",
      "298:\tlearn: 0.0097630\ttotal: 8.94s\tremaining: 47.1s\n",
      "299:\tlearn: 0.0096590\ttotal: 8.97s\tremaining: 47.1s\n",
      "300:\tlearn: 0.0095954\ttotal: 9s\tremaining: 47.1s\n",
      "301:\tlearn: 0.0095433\ttotal: 9.03s\tremaining: 47s\n",
      "302:\tlearn: 0.0094992\ttotal: 9.06s\tremaining: 47s\n",
      "303:\tlearn: 0.0094619\ttotal: 9.09s\tremaining: 47s\n",
      "304:\tlearn: 0.0094234\ttotal: 9.12s\tremaining: 47s\n",
      "305:\tlearn: 0.0093465\ttotal: 9.15s\tremaining: 46.9s\n",
      "306:\tlearn: 0.0092583\ttotal: 9.18s\tremaining: 46.9s\n",
      "307:\tlearn: 0.0091631\ttotal: 9.21s\tremaining: 46.9s\n",
      "308:\tlearn: 0.0091213\ttotal: 9.24s\tremaining: 46.8s\n",
      "309:\tlearn: 0.0090836\ttotal: 9.27s\tremaining: 46.8s\n",
      "310:\tlearn: 0.0090310\ttotal: 9.3s\tremaining: 46.8s\n",
      "311:\tlearn: 0.0089557\ttotal: 9.33s\tremaining: 46.7s\n",
      "312:\tlearn: 0.0088832\ttotal: 9.36s\tremaining: 46.7s\n",
      "313:\tlearn: 0.0088443\ttotal: 9.39s\tremaining: 46.7s\n",
      "314:\tlearn: 0.0088327\ttotal: 9.42s\tremaining: 46.6s\n",
      "315:\tlearn: 0.0088228\ttotal: 9.45s\tremaining: 46.6s\n",
      "316:\tlearn: 0.0087707\ttotal: 9.48s\tremaining: 46.6s\n",
      "317:\tlearn: 0.0087265\ttotal: 9.51s\tremaining: 46.6s\n",
      "318:\tlearn: 0.0086439\ttotal: 9.54s\tremaining: 46.5s\n",
      "319:\tlearn: 0.0086074\ttotal: 9.57s\tremaining: 46.5s\n",
      "320:\tlearn: 0.0085533\ttotal: 9.6s\tremaining: 46.5s\n",
      "321:\tlearn: 0.0084851\ttotal: 9.63s\tremaining: 46.4s\n",
      "322:\tlearn: 0.0084322\ttotal: 9.65s\tremaining: 46.4s\n",
      "323:\tlearn: 0.0084116\ttotal: 9.68s\tremaining: 46.4s\n",
      "324:\tlearn: 0.0083391\ttotal: 9.71s\tremaining: 46.3s\n",
      "325:\tlearn: 0.0083357\ttotal: 9.74s\tremaining: 46.3s\n",
      "326:\tlearn: 0.0083294\ttotal: 9.78s\tremaining: 46.3s\n",
      "327:\tlearn: 0.0083069\ttotal: 9.81s\tremaining: 46.3s\n",
      "328:\tlearn: 0.0082811\ttotal: 9.84s\tremaining: 46.2s\n",
      "329:\tlearn: 0.0082218\ttotal: 9.87s\tremaining: 46.2s\n",
      "330:\tlearn: 0.0081684\ttotal: 9.89s\tremaining: 46.2s\n",
      "331:\tlearn: 0.0080921\ttotal: 9.93s\tremaining: 46.1s\n",
      "332:\tlearn: 0.0080689\ttotal: 9.96s\tremaining: 46.1s\n",
      "333:\tlearn: 0.0079579\ttotal: 9.99s\tremaining: 46.1s\n",
      "334:\tlearn: 0.0079240\ttotal: 10s\tremaining: 46s\n",
      "335:\tlearn: 0.0078812\ttotal: 10s\tremaining: 46s\n",
      "336:\tlearn: 0.0078541\ttotal: 10.1s\tremaining: 46s\n",
      "337:\tlearn: 0.0078253\ttotal: 10.1s\tremaining: 45.9s\n",
      "338:\tlearn: 0.0077556\ttotal: 10.1s\tremaining: 45.9s\n",
      "339:\tlearn: 0.0077067\ttotal: 10.2s\tremaining: 45.9s\n",
      "340:\tlearn: 0.0076644\ttotal: 10.2s\tremaining: 45.8s\n",
      "341:\tlearn: 0.0076485\ttotal: 10.2s\tremaining: 45.8s\n",
      "342:\tlearn: 0.0076209\ttotal: 10.3s\tremaining: 45.8s\n",
      "343:\tlearn: 0.0076036\ttotal: 10.3s\tremaining: 45.8s\n",
      "344:\tlearn: 0.0076016\ttotal: 10.3s\tremaining: 45.7s\n",
      "345:\tlearn: 0.0075689\ttotal: 10.3s\tremaining: 45.7s\n",
      "346:\tlearn: 0.0075220\ttotal: 10.4s\tremaining: 45.7s\n",
      "347:\tlearn: 0.0074813\ttotal: 10.4s\tremaining: 45.6s\n",
      "348:\tlearn: 0.0074572\ttotal: 10.4s\tremaining: 45.6s\n",
      "349:\tlearn: 0.0074053\ttotal: 10.5s\tremaining: 45.6s\n",
      "350:\tlearn: 0.0073621\ttotal: 10.5s\tremaining: 45.5s\n",
      "351:\tlearn: 0.0073061\ttotal: 10.5s\tremaining: 45.5s\n",
      "352:\tlearn: 0.0072649\ttotal: 10.5s\tremaining: 45.5s\n",
      "353:\tlearn: 0.0071852\ttotal: 10.6s\tremaining: 45.4s\n",
      "354:\tlearn: 0.0071119\ttotal: 10.6s\tremaining: 45.4s\n",
      "355:\tlearn: 0.0070551\ttotal: 10.6s\tremaining: 45.4s\n",
      "356:\tlearn: 0.0069989\ttotal: 10.7s\tremaining: 45.3s\n",
      "357:\tlearn: 0.0069667\ttotal: 10.7s\tremaining: 45.3s\n",
      "358:\tlearn: 0.0069120\ttotal: 10.7s\tremaining: 45.3s\n",
      "359:\tlearn: 0.0068458\ttotal: 10.8s\tremaining: 45.2s\n",
      "360:\tlearn: 0.0067741\ttotal: 10.8s\tremaining: 45.2s\n",
      "361:\tlearn: 0.0067297\ttotal: 10.8s\tremaining: 45.2s\n",
      "362:\tlearn: 0.0067074\ttotal: 10.8s\tremaining: 45.1s\n",
      "363:\tlearn: 0.0066415\ttotal: 10.9s\tremaining: 45.1s\n",
      "364:\tlearn: 0.0066286\ttotal: 10.9s\tremaining: 45.1s\n",
      "365:\tlearn: 0.0065541\ttotal: 10.9s\tremaining: 45.1s\n",
      "366:\tlearn: 0.0065039\ttotal: 11s\tremaining: 45s\n",
      "367:\tlearn: 0.0064899\ttotal: 11s\tremaining: 45s\n",
      "368:\tlearn: 0.0064538\ttotal: 11s\tremaining: 45s\n",
      "369:\tlearn: 0.0064347\ttotal: 11s\tremaining: 44.9s\n",
      "370:\tlearn: 0.0064104\ttotal: 11.1s\tremaining: 44.9s\n",
      "371:\tlearn: 0.0063992\ttotal: 11.1s\tremaining: 44.9s\n",
      "372:\tlearn: 0.0063569\ttotal: 11.1s\tremaining: 44.8s\n",
      "373:\tlearn: 0.0063548\ttotal: 11.2s\tremaining: 44.8s\n",
      "374:\tlearn: 0.0063238\ttotal: 11.2s\tremaining: 44.8s\n",
      "375:\tlearn: 0.0062914\ttotal: 11.2s\tremaining: 44.7s\n",
      "376:\tlearn: 0.0062386\ttotal: 11.3s\tremaining: 44.7s\n",
      "377:\tlearn: 0.0061903\ttotal: 11.3s\tremaining: 44.7s\n",
      "378:\tlearn: 0.0061623\ttotal: 11.3s\tremaining: 44.6s\n",
      "379:\tlearn: 0.0061112\ttotal: 11.3s\tremaining: 44.6s\n",
      "380:\tlearn: 0.0060666\ttotal: 11.4s\tremaining: 44.6s\n",
      "381:\tlearn: 0.0060157\ttotal: 11.4s\tremaining: 44.5s\n",
      "382:\tlearn: 0.0059837\ttotal: 11.4s\tremaining: 44.5s\n",
      "383:\tlearn: 0.0059211\ttotal: 11.5s\tremaining: 44.5s\n",
      "384:\tlearn: 0.0058562\ttotal: 11.5s\tremaining: 44.4s\n",
      "385:\tlearn: 0.0058394\ttotal: 11.5s\tremaining: 44.4s\n",
      "386:\tlearn: 0.0058113\ttotal: 11.5s\tremaining: 44.4s\n",
      "387:\tlearn: 0.0057842\ttotal: 11.6s\tremaining: 44.4s\n",
      "388:\tlearn: 0.0057625\ttotal: 11.6s\tremaining: 44.3s\n",
      "389:\tlearn: 0.0057288\ttotal: 11.6s\tremaining: 44.3s\n",
      "390:\tlearn: 0.0056792\ttotal: 11.7s\tremaining: 44.3s\n",
      "391:\tlearn: 0.0056366\ttotal: 11.7s\tremaining: 44.2s\n",
      "392:\tlearn: 0.0055965\ttotal: 11.7s\tremaining: 44.2s\n",
      "393:\tlearn: 0.0055881\ttotal: 11.7s\tremaining: 44.2s\n",
      "394:\tlearn: 0.0055737\ttotal: 11.8s\tremaining: 44.1s\n",
      "395:\tlearn: 0.0055421\ttotal: 11.8s\tremaining: 44.1s\n",
      "396:\tlearn: 0.0055358\ttotal: 11.8s\tremaining: 44.1s\n",
      "397:\tlearn: 0.0055199\ttotal: 11.9s\tremaining: 44s\n",
      "398:\tlearn: 0.0054857\ttotal: 11.9s\tremaining: 44s\n",
      "399:\tlearn: 0.0054425\ttotal: 11.9s\tremaining: 44s\n",
      "400:\tlearn: 0.0054119\ttotal: 12s\tremaining: 43.9s\n",
      "401:\tlearn: 0.0053845\ttotal: 12s\tremaining: 43.9s\n",
      "402:\tlearn: 0.0053516\ttotal: 12s\tremaining: 43.9s\n",
      "403:\tlearn: 0.0052946\ttotal: 12s\tremaining: 43.8s\n",
      "404:\tlearn: 0.0052620\ttotal: 12.1s\tremaining: 43.8s\n",
      "405:\tlearn: 0.0052498\ttotal: 12.1s\tremaining: 43.8s\n",
      "406:\tlearn: 0.0052258\ttotal: 12.1s\tremaining: 43.7s\n",
      "407:\tlearn: 0.0052184\ttotal: 12.2s\tremaining: 43.7s\n",
      "408:\tlearn: 0.0051862\ttotal: 12.2s\tremaining: 43.7s\n",
      "409:\tlearn: 0.0051742\ttotal: 12.2s\tremaining: 43.7s\n",
      "410:\tlearn: 0.0051524\ttotal: 12.2s\tremaining: 43.6s\n",
      "411:\tlearn: 0.0051280\ttotal: 12.3s\tremaining: 43.6s\n",
      "412:\tlearn: 0.0051163\ttotal: 12.3s\tremaining: 43.6s\n",
      "413:\tlearn: 0.0050843\ttotal: 12.3s\tremaining: 43.5s\n",
      "414:\tlearn: 0.0050617\ttotal: 12.4s\tremaining: 43.5s\n",
      "415:\tlearn: 0.0050474\ttotal: 12.4s\tremaining: 43.5s\n",
      "416:\tlearn: 0.0050363\ttotal: 12.4s\tremaining: 43.4s\n",
      "417:\tlearn: 0.0050099\ttotal: 12.5s\tremaining: 43.4s\n",
      "418:\tlearn: 0.0050022\ttotal: 12.5s\tremaining: 43.4s\n",
      "419:\tlearn: 0.0049850\ttotal: 12.5s\tremaining: 43.4s\n",
      "420:\tlearn: 0.0049741\ttotal: 12.5s\tremaining: 43.3s\n",
      "421:\tlearn: 0.0049668\ttotal: 12.6s\tremaining: 43.3s\n",
      "422:\tlearn: 0.0049439\ttotal: 12.6s\tremaining: 43.3s\n",
      "423:\tlearn: 0.0049362\ttotal: 12.6s\tremaining: 43.2s\n",
      "424:\tlearn: 0.0049248\ttotal: 12.7s\tremaining: 43.2s\n",
      "425:\tlearn: 0.0049006\ttotal: 12.7s\tremaining: 43.2s\n",
      "426:\tlearn: 0.0048781\ttotal: 12.7s\tremaining: 43.1s\n",
      "427:\tlearn: 0.0048678\ttotal: 12.8s\tremaining: 43.1s\n",
      "428:\tlearn: 0.0048487\ttotal: 12.8s\tremaining: 43.1s\n",
      "429:\tlearn: 0.0048350\ttotal: 12.8s\tremaining: 43.1s\n",
      "430:\tlearn: 0.0048193\ttotal: 12.8s\tremaining: 43s\n",
      "431:\tlearn: 0.0048157\ttotal: 12.9s\tremaining: 43s\n",
      "432:\tlearn: 0.0048042\ttotal: 12.9s\tremaining: 43s\n",
      "433:\tlearn: 0.0047660\ttotal: 12.9s\tremaining: 43s\n",
      "434:\tlearn: 0.0047455\ttotal: 13s\tremaining: 43s\n",
      "435:\tlearn: 0.0047420\ttotal: 13s\tremaining: 42.9s\n",
      "436:\tlearn: 0.0047135\ttotal: 13s\tremaining: 42.9s\n",
      "437:\tlearn: 0.0047004\ttotal: 13.1s\tremaining: 42.9s\n",
      "438:\tlearn: 0.0046816\ttotal: 13.1s\tremaining: 42.8s\n",
      "439:\tlearn: 0.0046549\ttotal: 13.1s\tremaining: 42.8s\n",
      "440:\tlearn: 0.0046424\ttotal: 13.2s\tremaining: 42.8s\n",
      "441:\tlearn: 0.0046289\ttotal: 13.2s\tremaining: 42.7s\n",
      "442:\tlearn: 0.0046129\ttotal: 13.2s\tremaining: 42.7s\n",
      "443:\tlearn: 0.0046091\ttotal: 13.2s\tremaining: 42.7s\n",
      "444:\tlearn: 0.0045854\ttotal: 13.3s\tremaining: 42.7s\n",
      "445:\tlearn: 0.0045699\ttotal: 13.3s\tremaining: 42.6s\n",
      "446:\tlearn: 0.0045503\ttotal: 13.3s\tremaining: 42.6s\n",
      "447:\tlearn: 0.0045268\ttotal: 13.4s\tremaining: 42.6s\n",
      "448:\tlearn: 0.0045149\ttotal: 13.4s\tremaining: 42.5s\n",
      "449:\tlearn: 0.0044964\ttotal: 13.4s\tremaining: 42.5s\n",
      "450:\tlearn: 0.0044943\ttotal: 13.4s\tremaining: 42.5s\n",
      "451:\tlearn: 0.0044796\ttotal: 13.5s\tremaining: 42.4s\n",
      "452:\tlearn: 0.0044586\ttotal: 13.5s\tremaining: 42.4s\n",
      "453:\tlearn: 0.0044198\ttotal: 13.5s\tremaining: 42.4s\n",
      "454:\tlearn: 0.0044118\ttotal: 13.6s\tremaining: 42.3s\n",
      "455:\tlearn: 0.0043879\ttotal: 13.6s\tremaining: 42.3s\n",
      "456:\tlearn: 0.0043787\ttotal: 13.6s\tremaining: 42.3s\n",
      "457:\tlearn: 0.0043664\ttotal: 13.7s\tremaining: 42.3s\n",
      "458:\tlearn: 0.0043588\ttotal: 13.7s\tremaining: 42.2s\n",
      "459:\tlearn: 0.0043463\ttotal: 13.7s\tremaining: 42.2s\n",
      "460:\tlearn: 0.0043322\ttotal: 13.7s\tremaining: 42.2s\n",
      "461:\tlearn: 0.0043265\ttotal: 13.8s\tremaining: 42.1s\n",
      "462:\tlearn: 0.0043095\ttotal: 13.8s\tremaining: 42.1s\n",
      "463:\tlearn: 0.0043018\ttotal: 13.8s\tremaining: 42.1s\n",
      "464:\tlearn: 0.0042876\ttotal: 13.9s\tremaining: 42s\n",
      "465:\tlearn: 0.0042875\ttotal: 13.9s\tremaining: 42s\n",
      "466:\tlearn: 0.0042769\ttotal: 13.9s\tremaining: 42s\n",
      "467:\tlearn: 0.0042703\ttotal: 14s\tremaining: 42s\n",
      "468:\tlearn: 0.0042611\ttotal: 14s\tremaining: 41.9s\n",
      "469:\tlearn: 0.0042490\ttotal: 14s\tremaining: 41.9s\n",
      "470:\tlearn: 0.0042365\ttotal: 14s\tremaining: 41.9s\n",
      "471:\tlearn: 0.0042289\ttotal: 14.1s\tremaining: 41.8s\n",
      "472:\tlearn: 0.0042198\ttotal: 14.1s\tremaining: 41.8s\n",
      "473:\tlearn: 0.0042124\ttotal: 14.1s\tremaining: 41.8s\n",
      "474:\tlearn: 0.0041922\ttotal: 14.2s\tremaining: 41.7s\n",
      "475:\tlearn: 0.0041686\ttotal: 14.2s\tremaining: 41.7s\n",
      "476:\tlearn: 0.0041637\ttotal: 14.2s\tremaining: 41.7s\n",
      "477:\tlearn: 0.0041607\ttotal: 14.3s\tremaining: 41.7s\n",
      "478:\tlearn: 0.0041464\ttotal: 14.3s\tremaining: 41.6s\n",
      "479:\tlearn: 0.0041302\ttotal: 14.3s\tremaining: 41.6s\n",
      "480:\tlearn: 0.0041184\ttotal: 14.3s\tremaining: 41.6s\n",
      "481:\tlearn: 0.0041084\ttotal: 14.4s\tremaining: 41.5s\n",
      "482:\tlearn: 0.0041014\ttotal: 14.4s\tremaining: 41.5s\n",
      "483:\tlearn: 0.0040840\ttotal: 14.4s\tremaining: 41.5s\n",
      "484:\tlearn: 0.0040672\ttotal: 14.5s\tremaining: 41.5s\n",
      "485:\tlearn: 0.0040567\ttotal: 14.5s\tremaining: 41.4s\n",
      "486:\tlearn: 0.0040382\ttotal: 14.5s\tremaining: 41.4s\n",
      "487:\tlearn: 0.0040283\ttotal: 14.6s\tremaining: 41.4s\n",
      "488:\tlearn: 0.0040166\ttotal: 14.6s\tremaining: 41.3s\n",
      "489:\tlearn: 0.0040043\ttotal: 14.6s\tremaining: 41.3s\n",
      "490:\tlearn: 0.0040016\ttotal: 14.6s\tremaining: 41.3s\n",
      "491:\tlearn: 0.0039953\ttotal: 14.7s\tremaining: 41.2s\n",
      "492:\tlearn: 0.0039851\ttotal: 14.7s\tremaining: 41.2s\n",
      "493:\tlearn: 0.0039851\ttotal: 14.7s\tremaining: 41.2s\n",
      "494:\tlearn: 0.0039740\ttotal: 14.8s\tremaining: 41.2s\n",
      "495:\tlearn: 0.0039694\ttotal: 14.8s\tremaining: 41.1s\n",
      "496:\tlearn: 0.0039694\ttotal: 14.8s\tremaining: 41.1s\n",
      "497:\tlearn: 0.0039557\ttotal: 14.8s\tremaining: 41.1s\n",
      "498:\tlearn: 0.0039420\ttotal: 14.9s\tremaining: 41s\n",
      "499:\tlearn: 0.0039420\ttotal: 14.9s\tremaining: 41s\n",
      "500:\tlearn: 0.0039228\ttotal: 14.9s\tremaining: 41s\n",
      "501:\tlearn: 0.0039157\ttotal: 15s\tremaining: 40.9s\n",
      "502:\tlearn: 0.0039069\ttotal: 15s\tremaining: 40.9s\n",
      "503:\tlearn: 0.0038905\ttotal: 15s\tremaining: 40.9s\n",
      "504:\tlearn: 0.0038863\ttotal: 15.1s\tremaining: 40.8s\n",
      "505:\tlearn: 0.0038632\ttotal: 15.1s\tremaining: 40.8s\n",
      "506:\tlearn: 0.0038531\ttotal: 15.1s\tremaining: 40.8s\n",
      "507:\tlearn: 0.0038426\ttotal: 15.1s\tremaining: 40.8s\n",
      "508:\tlearn: 0.0038389\ttotal: 15.2s\tremaining: 40.7s\n",
      "509:\tlearn: 0.0038189\ttotal: 15.2s\tremaining: 40.7s\n",
      "510:\tlearn: 0.0037992\ttotal: 15.2s\tremaining: 40.7s\n",
      "511:\tlearn: 0.0037828\ttotal: 15.3s\tremaining: 40.6s\n",
      "512:\tlearn: 0.0037808\ttotal: 15.3s\tremaining: 40.6s\n",
      "513:\tlearn: 0.0037725\ttotal: 15.3s\tremaining: 40.6s\n",
      "514:\tlearn: 0.0037676\ttotal: 15.4s\tremaining: 40.5s\n",
      "515:\tlearn: 0.0037489\ttotal: 15.4s\tremaining: 40.5s\n",
      "516:\tlearn: 0.0037338\ttotal: 15.4s\tremaining: 40.5s\n",
      "517:\tlearn: 0.0037218\ttotal: 15.4s\tremaining: 40.5s\n",
      "518:\tlearn: 0.0037082\ttotal: 15.5s\tremaining: 40.4s\n",
      "519:\tlearn: 0.0037003\ttotal: 15.5s\tremaining: 40.4s\n",
      "520:\tlearn: 0.0036885\ttotal: 15.5s\tremaining: 40.4s\n",
      "521:\tlearn: 0.0036831\ttotal: 15.6s\tremaining: 40.3s\n",
      "522:\tlearn: 0.0036686\ttotal: 15.6s\tremaining: 40.3s\n",
      "523:\tlearn: 0.0036512\ttotal: 15.6s\tremaining: 40.3s\n",
      "524:\tlearn: 0.0036378\ttotal: 15.7s\tremaining: 40.2s\n",
      "525:\tlearn: 0.0036242\ttotal: 15.7s\tremaining: 40.2s\n",
      "526:\tlearn: 0.0036126\ttotal: 15.7s\tremaining: 40.2s\n",
      "527:\tlearn: 0.0035958\ttotal: 15.7s\tremaining: 40.2s\n",
      "528:\tlearn: 0.0035906\ttotal: 15.8s\tremaining: 40.1s\n",
      "529:\tlearn: 0.0035671\ttotal: 15.8s\tremaining: 40.1s\n",
      "530:\tlearn: 0.0035521\ttotal: 15.8s\tremaining: 40.1s\n",
      "531:\tlearn: 0.0035345\ttotal: 15.9s\tremaining: 40s\n",
      "532:\tlearn: 0.0035273\ttotal: 15.9s\tremaining: 40s\n",
      "533:\tlearn: 0.0035224\ttotal: 15.9s\tremaining: 40s\n",
      "534:\tlearn: 0.0035095\ttotal: 15.9s\tremaining: 39.9s\n",
      "535:\tlearn: 0.0035025\ttotal: 16s\tremaining: 39.9s\n",
      "536:\tlearn: 0.0034853\ttotal: 16s\tremaining: 39.9s\n",
      "537:\tlearn: 0.0034807\ttotal: 16s\tremaining: 39.9s\n",
      "538:\tlearn: 0.0034688\ttotal: 16.1s\tremaining: 39.8s\n",
      "539:\tlearn: 0.0034525\ttotal: 16.1s\tremaining: 39.8s\n",
      "540:\tlearn: 0.0034430\ttotal: 16.1s\tremaining: 39.8s\n",
      "541:\tlearn: 0.0034321\ttotal: 16.2s\tremaining: 39.7s\n",
      "542:\tlearn: 0.0034320\ttotal: 16.2s\tremaining: 39.7s\n",
      "543:\tlearn: 0.0034166\ttotal: 16.2s\tremaining: 39.7s\n",
      "544:\tlearn: 0.0034064\ttotal: 16.2s\tremaining: 39.6s\n",
      "545:\tlearn: 0.0033923\ttotal: 16.3s\tremaining: 39.6s\n",
      "546:\tlearn: 0.0033832\ttotal: 16.3s\tremaining: 39.6s\n",
      "547:\tlearn: 0.0033689\ttotal: 16.3s\tremaining: 39.6s\n",
      "548:\tlearn: 0.0033635\ttotal: 16.4s\tremaining: 39.5s\n",
      "549:\tlearn: 0.0033518\ttotal: 16.4s\tremaining: 39.5s\n",
      "550:\tlearn: 0.0033437\ttotal: 16.4s\tremaining: 39.5s\n",
      "551:\tlearn: 0.0033372\ttotal: 16.4s\tremaining: 39.4s\n",
      "552:\tlearn: 0.0033306\ttotal: 16.5s\tremaining: 39.4s\n",
      "553:\tlearn: 0.0033226\ttotal: 16.5s\tremaining: 39.4s\n",
      "554:\tlearn: 0.0033115\ttotal: 16.5s\tremaining: 39.3s\n",
      "555:\tlearn: 0.0033115\ttotal: 16.6s\tremaining: 39.3s\n",
      "556:\tlearn: 0.0033115\ttotal: 16.6s\tremaining: 39.3s\n",
      "557:\tlearn: 0.0033115\ttotal: 16.6s\tremaining: 39.3s\n",
      "558:\tlearn: 0.0033001\ttotal: 16.7s\tremaining: 39.2s\n",
      "559:\tlearn: 0.0032978\ttotal: 16.7s\tremaining: 39.2s\n",
      "560:\tlearn: 0.0032878\ttotal: 16.7s\tremaining: 39.2s\n",
      "561:\tlearn: 0.0032834\ttotal: 16.8s\tremaining: 39.1s\n",
      "562:\tlearn: 0.0032834\ttotal: 16.8s\tremaining: 39.1s\n",
      "563:\tlearn: 0.0032733\ttotal: 16.8s\tremaining: 39.1s\n",
      "564:\tlearn: 0.0032733\ttotal: 16.8s\tremaining: 39.1s\n",
      "565:\tlearn: 0.0032640\ttotal: 16.9s\tremaining: 39s\n",
      "566:\tlearn: 0.0032492\ttotal: 16.9s\tremaining: 39s\n",
      "567:\tlearn: 0.0032434\ttotal: 16.9s\tremaining: 39s\n",
      "568:\tlearn: 0.0032364\ttotal: 17s\tremaining: 38.9s\n",
      "569:\tlearn: 0.0032303\ttotal: 17s\tremaining: 38.9s\n",
      "570:\tlearn: 0.0032265\ttotal: 17s\tremaining: 38.9s\n",
      "571:\tlearn: 0.0032265\ttotal: 17.1s\tremaining: 38.8s\n",
      "572:\tlearn: 0.0032243\ttotal: 17.1s\tremaining: 38.8s\n",
      "573:\tlearn: 0.0032156\ttotal: 17.1s\tremaining: 38.8s\n",
      "574:\tlearn: 0.0032079\ttotal: 17.1s\tremaining: 38.8s\n",
      "575:\tlearn: 0.0031960\ttotal: 17.2s\tremaining: 38.7s\n",
      "576:\tlearn: 0.0031926\ttotal: 17.2s\tremaining: 38.7s\n",
      "577:\tlearn: 0.0031800\ttotal: 17.2s\tremaining: 38.7s\n",
      "578:\tlearn: 0.0031671\ttotal: 17.3s\tremaining: 38.6s\n",
      "579:\tlearn: 0.0031538\ttotal: 17.3s\tremaining: 38.6s\n",
      "580:\tlearn: 0.0031417\ttotal: 17.3s\tremaining: 38.6s\n",
      "581:\tlearn: 0.0031363\ttotal: 17.4s\tremaining: 38.5s\n",
      "582:\tlearn: 0.0031327\ttotal: 17.4s\tremaining: 38.5s\n",
      "583:\tlearn: 0.0031256\ttotal: 17.4s\tremaining: 38.5s\n",
      "584:\tlearn: 0.0031192\ttotal: 17.4s\tremaining: 38.5s\n",
      "585:\tlearn: 0.0031174\ttotal: 17.5s\tremaining: 38.4s\n",
      "586:\tlearn: 0.0031174\ttotal: 17.5s\tremaining: 38.4s\n",
      "587:\tlearn: 0.0031094\ttotal: 17.5s\tremaining: 38.4s\n",
      "588:\tlearn: 0.0031094\ttotal: 17.6s\tremaining: 38.3s\n",
      "589:\tlearn: 0.0031094\ttotal: 17.6s\tremaining: 38.3s\n",
      "590:\tlearn: 0.0031020\ttotal: 17.6s\tremaining: 38.3s\n",
      "591:\tlearn: 0.0030964\ttotal: 17.6s\tremaining: 38.2s\n",
      "592:\tlearn: 0.0030964\ttotal: 17.7s\tremaining: 38.2s\n",
      "593:\tlearn: 0.0030920\ttotal: 17.7s\tremaining: 38.2s\n",
      "594:\tlearn: 0.0030919\ttotal: 17.7s\tremaining: 38.2s\n",
      "595:\tlearn: 0.0030822\ttotal: 17.8s\tremaining: 38.1s\n",
      "596:\tlearn: 0.0030725\ttotal: 17.8s\tremaining: 38.1s\n",
      "597:\tlearn: 0.0030678\ttotal: 17.8s\tremaining: 38.1s\n",
      "598:\tlearn: 0.0030636\ttotal: 17.9s\tremaining: 38s\n",
      "599:\tlearn: 0.0030636\ttotal: 17.9s\tremaining: 38s\n",
      "600:\tlearn: 0.0030606\ttotal: 17.9s\tremaining: 38s\n",
      "601:\tlearn: 0.0030604\ttotal: 17.9s\tremaining: 37.9s\n",
      "602:\tlearn: 0.0030563\ttotal: 18s\tremaining: 37.9s\n",
      "603:\tlearn: 0.0030521\ttotal: 18s\tremaining: 37.9s\n",
      "604:\tlearn: 0.0030521\ttotal: 18s\tremaining: 37.8s\n",
      "605:\tlearn: 0.0030489\ttotal: 18.1s\tremaining: 37.8s\n",
      "606:\tlearn: 0.0030457\ttotal: 18.1s\tremaining: 37.8s\n",
      "607:\tlearn: 0.0030405\ttotal: 18.1s\tremaining: 37.8s\n",
      "608:\tlearn: 0.0030362\ttotal: 18.1s\tremaining: 37.7s\n",
      "609:\tlearn: 0.0030362\ttotal: 18.2s\tremaining: 37.7s\n",
      "610:\tlearn: 0.0030324\ttotal: 18.2s\tremaining: 37.7s\n",
      "611:\tlearn: 0.0030217\ttotal: 18.2s\tremaining: 37.7s\n",
      "612:\tlearn: 0.0030121\ttotal: 18.3s\tremaining: 37.6s\n",
      "613:\tlearn: 0.0030121\ttotal: 18.3s\tremaining: 37.6s\n",
      "614:\tlearn: 0.0030120\ttotal: 18.3s\tremaining: 37.6s\n",
      "615:\tlearn: 0.0030025\ttotal: 18.4s\tremaining: 37.5s\n",
      "616:\tlearn: 0.0029949\ttotal: 18.4s\tremaining: 37.5s\n",
      "617:\tlearn: 0.0029909\ttotal: 18.4s\tremaining: 37.5s\n",
      "618:\tlearn: 0.0029748\ttotal: 18.5s\tremaining: 37.4s\n",
      "619:\tlearn: 0.0029631\ttotal: 18.5s\tremaining: 37.4s\n",
      "620:\tlearn: 0.0029575\ttotal: 18.5s\tremaining: 37.4s\n",
      "621:\tlearn: 0.0029486\ttotal: 18.5s\tremaining: 37.4s\n",
      "622:\tlearn: 0.0029381\ttotal: 18.6s\tremaining: 37.3s\n",
      "623:\tlearn: 0.0029380\ttotal: 18.6s\tremaining: 37.3s\n",
      "624:\tlearn: 0.0029285\ttotal: 18.6s\tremaining: 37.3s\n",
      "625:\tlearn: 0.0029166\ttotal: 18.7s\tremaining: 37.2s\n",
      "626:\tlearn: 0.0029069\ttotal: 18.7s\tremaining: 37.2s\n",
      "627:\tlearn: 0.0029006\ttotal: 18.7s\tremaining: 37.2s\n",
      "628:\tlearn: 0.0028918\ttotal: 18.8s\tremaining: 37.1s\n",
      "629:\tlearn: 0.0028836\ttotal: 18.8s\tremaining: 37.1s\n",
      "630:\tlearn: 0.0028804\ttotal: 18.8s\tremaining: 37.1s\n",
      "631:\tlearn: 0.0028748\ttotal: 18.8s\tremaining: 37.1s\n",
      "632:\tlearn: 0.0028698\ttotal: 18.9s\tremaining: 37s\n",
      "633:\tlearn: 0.0028591\ttotal: 18.9s\tremaining: 37s\n",
      "634:\tlearn: 0.0028536\ttotal: 18.9s\tremaining: 37s\n",
      "635:\tlearn: 0.0028485\ttotal: 19s\tremaining: 36.9s\n",
      "636:\tlearn: 0.0028365\ttotal: 19s\tremaining: 36.9s\n",
      "637:\tlearn: 0.0028205\ttotal: 19s\tremaining: 36.9s\n",
      "638:\tlearn: 0.0028158\ttotal: 19s\tremaining: 36.8s\n",
      "639:\tlearn: 0.0028080\ttotal: 19.1s\tremaining: 36.8s\n",
      "640:\tlearn: 0.0027995\ttotal: 19.1s\tremaining: 36.8s\n",
      "641:\tlearn: 0.0027918\ttotal: 19.1s\tremaining: 36.7s\n",
      "642:\tlearn: 0.0027871\ttotal: 19.2s\tremaining: 36.7s\n",
      "643:\tlearn: 0.0027792\ttotal: 19.2s\tremaining: 36.7s\n",
      "644:\tlearn: 0.0027792\ttotal: 19.2s\tremaining: 36.7s\n",
      "645:\tlearn: 0.0027756\ttotal: 19.3s\tremaining: 36.6s\n",
      "646:\tlearn: 0.0027702\ttotal: 19.3s\tremaining: 36.6s\n",
      "647:\tlearn: 0.0027654\ttotal: 19.3s\tremaining: 36.6s\n",
      "648:\tlearn: 0.0027590\ttotal: 19.3s\tremaining: 36.5s\n",
      "649:\tlearn: 0.0027531\ttotal: 19.4s\tremaining: 36.5s\n",
      "650:\tlearn: 0.0027450\ttotal: 19.4s\tremaining: 36.5s\n",
      "651:\tlearn: 0.0027407\ttotal: 19.4s\tremaining: 36.4s\n",
      "652:\tlearn: 0.0027287\ttotal: 19.5s\tremaining: 36.4s\n",
      "653:\tlearn: 0.0027247\ttotal: 19.5s\tremaining: 36.4s\n",
      "654:\tlearn: 0.0027173\ttotal: 19.5s\tremaining: 36.4s\n",
      "655:\tlearn: 0.0027140\ttotal: 19.6s\tremaining: 36.3s\n",
      "656:\tlearn: 0.0027067\ttotal: 19.6s\tremaining: 36.3s\n",
      "657:\tlearn: 0.0027067\ttotal: 19.6s\tremaining: 36.3s\n",
      "658:\tlearn: 0.0027014\ttotal: 19.6s\tremaining: 36.2s\n",
      "659:\tlearn: 0.0026944\ttotal: 19.7s\tremaining: 36.2s\n",
      "660:\tlearn: 0.0026877\ttotal: 19.7s\tremaining: 36.2s\n",
      "661:\tlearn: 0.0026743\ttotal: 19.7s\tremaining: 36.2s\n",
      "662:\tlearn: 0.0026676\ttotal: 19.8s\tremaining: 36.1s\n",
      "663:\tlearn: 0.0026676\ttotal: 19.8s\tremaining: 36.1s\n",
      "664:\tlearn: 0.0026676\ttotal: 19.8s\tremaining: 36.1s\n",
      "665:\tlearn: 0.0026577\ttotal: 19.8s\tremaining: 36s\n",
      "666:\tlearn: 0.0026499\ttotal: 19.9s\tremaining: 36s\n",
      "667:\tlearn: 0.0026499\ttotal: 19.9s\tremaining: 36s\n",
      "668:\tlearn: 0.0026435\ttotal: 19.9s\tremaining: 35.9s\n",
      "669:\tlearn: 0.0026379\ttotal: 20s\tremaining: 35.9s\n",
      "670:\tlearn: 0.0026343\ttotal: 20s\tremaining: 35.9s\n",
      "671:\tlearn: 0.0026343\ttotal: 20s\tremaining: 35.9s\n",
      "672:\tlearn: 0.0026208\ttotal: 20.1s\tremaining: 35.8s\n",
      "673:\tlearn: 0.0026177\ttotal: 20.1s\tremaining: 35.8s\n",
      "674:\tlearn: 0.0026111\ttotal: 20.1s\tremaining: 35.8s\n",
      "675:\tlearn: 0.0026064\ttotal: 20.1s\tremaining: 35.7s\n",
      "676:\tlearn: 0.0026029\ttotal: 20.2s\tremaining: 35.7s\n",
      "677:\tlearn: 0.0025928\ttotal: 20.2s\tremaining: 35.7s\n",
      "678:\tlearn: 0.0025888\ttotal: 20.2s\tremaining: 35.6s\n",
      "679:\tlearn: 0.0025834\ttotal: 20.3s\tremaining: 35.6s\n",
      "680:\tlearn: 0.0025751\ttotal: 20.3s\tremaining: 35.6s\n",
      "681:\tlearn: 0.0025751\ttotal: 20.3s\tremaining: 35.6s\n",
      "682:\tlearn: 0.0025649\ttotal: 20.4s\tremaining: 35.5s\n",
      "683:\tlearn: 0.0025537\ttotal: 20.4s\tremaining: 35.5s\n",
      "684:\tlearn: 0.0025498\ttotal: 20.4s\tremaining: 35.5s\n",
      "685:\tlearn: 0.0025441\ttotal: 20.4s\tremaining: 35.4s\n",
      "686:\tlearn: 0.0025383\ttotal: 20.5s\tremaining: 35.4s\n",
      "687:\tlearn: 0.0025357\ttotal: 20.5s\tremaining: 35.4s\n",
      "688:\tlearn: 0.0025357\ttotal: 20.5s\tremaining: 35.3s\n",
      "689:\tlearn: 0.0025356\ttotal: 20.6s\tremaining: 35.3s\n",
      "690:\tlearn: 0.0025319\ttotal: 20.6s\tremaining: 35.3s\n",
      "691:\tlearn: 0.0025319\ttotal: 20.6s\tremaining: 35.3s\n",
      "692:\tlearn: 0.0025201\ttotal: 20.7s\tremaining: 35.2s\n",
      "693:\tlearn: 0.0025201\ttotal: 20.7s\tremaining: 35.2s\n",
      "694:\tlearn: 0.0025165\ttotal: 20.7s\tremaining: 35.2s\n",
      "695:\tlearn: 0.0025115\ttotal: 20.7s\tremaining: 35.1s\n",
      "696:\tlearn: 0.0025055\ttotal: 20.8s\tremaining: 35.1s\n",
      "697:\tlearn: 0.0025055\ttotal: 20.8s\tremaining: 35.1s\n",
      "698:\tlearn: 0.0025002\ttotal: 20.8s\tremaining: 35s\n",
      "699:\tlearn: 0.0024913\ttotal: 20.9s\tremaining: 35s\n",
      "700:\tlearn: 0.0024871\ttotal: 20.9s\tremaining: 35s\n",
      "701:\tlearn: 0.0024852\ttotal: 20.9s\tremaining: 35s\n",
      "702:\tlearn: 0.0024820\ttotal: 20.9s\tremaining: 34.9s\n",
      "703:\tlearn: 0.0024781\ttotal: 21s\tremaining: 34.9s\n",
      "704:\tlearn: 0.0024720\ttotal: 21s\tremaining: 34.9s\n",
      "705:\tlearn: 0.0024688\ttotal: 21s\tremaining: 34.8s\n",
      "706:\tlearn: 0.0024639\ttotal: 21.1s\tremaining: 34.8s\n",
      "707:\tlearn: 0.0024561\ttotal: 21.1s\tremaining: 34.8s\n",
      "708:\tlearn: 0.0024468\ttotal: 21.1s\tremaining: 34.7s\n",
      "709:\tlearn: 0.0024408\ttotal: 21.2s\tremaining: 34.7s\n",
      "710:\tlearn: 0.0024347\ttotal: 21.2s\tremaining: 34.7s\n",
      "711:\tlearn: 0.0024313\ttotal: 21.2s\tremaining: 34.7s\n",
      "712:\tlearn: 0.0024243\ttotal: 21.2s\tremaining: 34.6s\n",
      "713:\tlearn: 0.0024209\ttotal: 21.3s\tremaining: 34.6s\n",
      "714:\tlearn: 0.0024180\ttotal: 21.3s\tremaining: 34.6s\n",
      "715:\tlearn: 0.0024144\ttotal: 21.3s\tremaining: 34.5s\n",
      "716:\tlearn: 0.0024100\ttotal: 21.4s\tremaining: 34.5s\n",
      "717:\tlearn: 0.0024030\ttotal: 21.4s\tremaining: 34.5s\n",
      "718:\tlearn: 0.0023995\ttotal: 21.4s\tremaining: 34.4s\n",
      "719:\tlearn: 0.0023984\ttotal: 21.5s\tremaining: 34.4s\n",
      "720:\tlearn: 0.0023956\ttotal: 21.5s\tremaining: 34.4s\n",
      "721:\tlearn: 0.0023915\ttotal: 21.5s\tremaining: 34.4s\n",
      "722:\tlearn: 0.0023883\ttotal: 21.5s\tremaining: 34.3s\n",
      "723:\tlearn: 0.0023826\ttotal: 21.6s\tremaining: 34.3s\n",
      "724:\tlearn: 0.0023786\ttotal: 21.6s\tremaining: 34.3s\n",
      "725:\tlearn: 0.0023721\ttotal: 21.6s\tremaining: 34.2s\n",
      "726:\tlearn: 0.0023699\ttotal: 21.7s\tremaining: 34.2s\n",
      "727:\tlearn: 0.0023646\ttotal: 21.7s\tremaining: 34.2s\n",
      "728:\tlearn: 0.0023645\ttotal: 21.7s\tremaining: 34.1s\n",
      "729:\tlearn: 0.0023601\ttotal: 21.8s\tremaining: 34.1s\n",
      "730:\tlearn: 0.0023601\ttotal: 21.8s\tremaining: 34.1s\n",
      "731:\tlearn: 0.0023541\ttotal: 21.8s\tremaining: 34.1s\n",
      "732:\tlearn: 0.0023505\ttotal: 21.8s\tremaining: 34s\n",
      "733:\tlearn: 0.0023505\ttotal: 21.9s\tremaining: 34s\n",
      "734:\tlearn: 0.0023505\ttotal: 21.9s\tremaining: 34s\n",
      "735:\tlearn: 0.0023480\ttotal: 21.9s\tremaining: 33.9s\n",
      "736:\tlearn: 0.0023431\ttotal: 22s\tremaining: 33.9s\n",
      "737:\tlearn: 0.0023389\ttotal: 22s\tremaining: 33.9s\n",
      "738:\tlearn: 0.0023342\ttotal: 22.1s\tremaining: 33.9s\n",
      "739:\tlearn: 0.0023342\ttotal: 22.1s\tremaining: 33.9s\n",
      "740:\tlearn: 0.0023300\ttotal: 22.1s\tremaining: 33.8s\n",
      "741:\tlearn: 0.0023203\ttotal: 22.1s\tremaining: 33.8s\n",
      "742:\tlearn: 0.0023152\ttotal: 22.2s\tremaining: 33.8s\n",
      "743:\tlearn: 0.0023152\ttotal: 22.2s\tremaining: 33.8s\n",
      "744:\tlearn: 0.0023152\ttotal: 22.2s\tremaining: 33.7s\n",
      "745:\tlearn: 0.0023080\ttotal: 22.3s\tremaining: 33.7s\n",
      "746:\tlearn: 0.0023080\ttotal: 22.3s\tremaining: 33.7s\n",
      "747:\tlearn: 0.0023036\ttotal: 22.3s\tremaining: 33.6s\n",
      "748:\tlearn: 0.0023010\ttotal: 22.4s\tremaining: 33.6s\n",
      "749:\tlearn: 0.0022970\ttotal: 22.4s\tremaining: 33.6s\n",
      "750:\tlearn: 0.0022940\ttotal: 22.4s\tremaining: 33.5s\n",
      "751:\tlearn: 0.0022899\ttotal: 22.4s\tremaining: 33.5s\n",
      "752:\tlearn: 0.0022899\ttotal: 22.5s\tremaining: 33.5s\n",
      "753:\tlearn: 0.0022899\ttotal: 22.5s\tremaining: 33.5s\n",
      "754:\tlearn: 0.0022849\ttotal: 22.5s\tremaining: 33.4s\n",
      "755:\tlearn: 0.0022831\ttotal: 22.6s\tremaining: 33.4s\n",
      "756:\tlearn: 0.0022831\ttotal: 22.6s\tremaining: 33.4s\n",
      "757:\tlearn: 0.0022831\ttotal: 22.6s\tremaining: 33.3s\n",
      "758:\tlearn: 0.0022762\ttotal: 22.6s\tremaining: 33.3s\n",
      "759:\tlearn: 0.0022762\ttotal: 22.7s\tremaining: 33.3s\n",
      "760:\tlearn: 0.0022724\ttotal: 22.7s\tremaining: 33.2s\n",
      "761:\tlearn: 0.0022724\ttotal: 22.7s\tremaining: 33.2s\n",
      "762:\tlearn: 0.0022724\ttotal: 22.8s\tremaining: 33.2s\n",
      "763:\tlearn: 0.0022683\ttotal: 22.8s\tremaining: 33.1s\n",
      "764:\tlearn: 0.0022645\ttotal: 22.8s\tremaining: 33.1s\n",
      "765:\tlearn: 0.0022645\ttotal: 22.9s\tremaining: 33.1s\n",
      "766:\tlearn: 0.0022612\ttotal: 22.9s\tremaining: 33.1s\n",
      "767:\tlearn: 0.0022611\ttotal: 22.9s\tremaining: 33s\n",
      "768:\tlearn: 0.0022552\ttotal: 22.9s\tremaining: 33s\n",
      "769:\tlearn: 0.0022523\ttotal: 23s\tremaining: 33s\n",
      "770:\tlearn: 0.0022523\ttotal: 23s\tremaining: 32.9s\n",
      "771:\tlearn: 0.0022522\ttotal: 23s\tremaining: 32.9s\n",
      "772:\tlearn: 0.0022522\ttotal: 23.1s\tremaining: 32.9s\n",
      "773:\tlearn: 0.0022479\ttotal: 23.1s\tremaining: 32.9s\n",
      "774:\tlearn: 0.0022479\ttotal: 23.1s\tremaining: 32.8s\n",
      "775:\tlearn: 0.0022479\ttotal: 23.2s\tremaining: 32.8s\n",
      "776:\tlearn: 0.0022431\ttotal: 23.2s\tremaining: 32.8s\n",
      "777:\tlearn: 0.0022407\ttotal: 23.2s\tremaining: 32.7s\n",
      "778:\tlearn: 0.0022371\ttotal: 23.2s\tremaining: 32.7s\n",
      "779:\tlearn: 0.0022364\ttotal: 23.3s\tremaining: 32.7s\n",
      "780:\tlearn: 0.0022364\ttotal: 23.3s\tremaining: 32.6s\n",
      "781:\tlearn: 0.0022364\ttotal: 23.3s\tremaining: 32.6s\n",
      "782:\tlearn: 0.0022332\ttotal: 23.4s\tremaining: 32.6s\n",
      "783:\tlearn: 0.0022293\ttotal: 23.4s\tremaining: 32.6s\n",
      "784:\tlearn: 0.0022293\ttotal: 23.4s\tremaining: 32.5s\n",
      "785:\tlearn: 0.0022261\ttotal: 23.5s\tremaining: 32.5s\n",
      "786:\tlearn: 0.0022261\ttotal: 23.5s\tremaining: 32.5s\n",
      "787:\tlearn: 0.0022261\ttotal: 23.5s\tremaining: 32.4s\n",
      "788:\tlearn: 0.0022261\ttotal: 23.5s\tremaining: 32.4s\n",
      "789:\tlearn: 0.0022222\ttotal: 23.6s\tremaining: 32.4s\n",
      "790:\tlearn: 0.0022176\ttotal: 23.6s\tremaining: 32.3s\n",
      "791:\tlearn: 0.0022083\ttotal: 23.6s\tremaining: 32.3s\n",
      "792:\tlearn: 0.0022042\ttotal: 23.7s\tremaining: 32.3s\n",
      "793:\tlearn: 0.0022042\ttotal: 23.7s\tremaining: 32.3s\n",
      "794:\tlearn: 0.0021976\ttotal: 23.7s\tremaining: 32.2s\n",
      "795:\tlearn: 0.0021941\ttotal: 23.8s\tremaining: 32.2s\n",
      "796:\tlearn: 0.0021898\ttotal: 23.8s\tremaining: 32.2s\n",
      "797:\tlearn: 0.0021856\ttotal: 23.8s\tremaining: 32.1s\n",
      "798:\tlearn: 0.0021827\ttotal: 23.8s\tremaining: 32.1s\n",
      "799:\tlearn: 0.0021792\ttotal: 23.9s\tremaining: 32.1s\n",
      "800:\tlearn: 0.0021715\ttotal: 23.9s\tremaining: 32s\n",
      "801:\tlearn: 0.0021715\ttotal: 23.9s\tremaining: 32s\n",
      "802:\tlearn: 0.0021604\ttotal: 24s\tremaining: 32s\n",
      "803:\tlearn: 0.0021548\ttotal: 24s\tremaining: 32s\n",
      "804:\tlearn: 0.0021548\ttotal: 24s\tremaining: 31.9s\n",
      "805:\tlearn: 0.0021548\ttotal: 24.1s\tremaining: 31.9s\n",
      "806:\tlearn: 0.0021487\ttotal: 24.1s\tremaining: 31.9s\n",
      "807:\tlearn: 0.0021416\ttotal: 24.1s\tremaining: 31.8s\n",
      "808:\tlearn: 0.0021402\ttotal: 24.1s\tremaining: 31.8s\n",
      "809:\tlearn: 0.0021402\ttotal: 24.2s\tremaining: 31.8s\n",
      "810:\tlearn: 0.0021363\ttotal: 24.2s\tremaining: 31.8s\n",
      "811:\tlearn: 0.0021288\ttotal: 24.2s\tremaining: 31.7s\n",
      "812:\tlearn: 0.0021230\ttotal: 24.3s\tremaining: 31.7s\n",
      "813:\tlearn: 0.0021188\ttotal: 24.3s\tremaining: 31.7s\n",
      "814:\tlearn: 0.0021188\ttotal: 24.3s\tremaining: 31.6s\n",
      "815:\tlearn: 0.0021188\ttotal: 24.3s\tremaining: 31.6s\n",
      "816:\tlearn: 0.0021188\ttotal: 24.4s\tremaining: 31.6s\n",
      "817:\tlearn: 0.0021120\ttotal: 24.4s\tremaining: 31.5s\n",
      "818:\tlearn: 0.0021120\ttotal: 24.4s\tremaining: 31.5s\n",
      "819:\tlearn: 0.0021120\ttotal: 24.5s\tremaining: 31.5s\n",
      "820:\tlearn: 0.0021057\ttotal: 24.5s\tremaining: 31.4s\n",
      "821:\tlearn: 0.0021057\ttotal: 24.5s\tremaining: 31.4s\n",
      "822:\tlearn: 0.0021018\ttotal: 24.6s\tremaining: 31.4s\n",
      "823:\tlearn: 0.0021018\ttotal: 24.6s\tremaining: 31.4s\n",
      "824:\tlearn: 0.0020978\ttotal: 24.6s\tremaining: 31.3s\n",
      "825:\tlearn: 0.0020928\ttotal: 24.6s\tremaining: 31.3s\n",
      "826:\tlearn: 0.0020928\ttotal: 24.7s\tremaining: 31.3s\n",
      "827:\tlearn: 0.0020898\ttotal: 24.7s\tremaining: 31.2s\n",
      "828:\tlearn: 0.0020810\ttotal: 24.7s\tremaining: 31.2s\n",
      "829:\tlearn: 0.0020771\ttotal: 24.8s\tremaining: 31.2s\n",
      "830:\tlearn: 0.0020720\ttotal: 24.8s\tremaining: 31.1s\n",
      "831:\tlearn: 0.0020686\ttotal: 24.8s\tremaining: 31.1s\n",
      "832:\tlearn: 0.0020623\ttotal: 24.9s\tremaining: 31.1s\n",
      "833:\tlearn: 0.0020589\ttotal: 24.9s\tremaining: 31.1s\n",
      "834:\tlearn: 0.0020589\ttotal: 24.9s\tremaining: 31s\n",
      "835:\tlearn: 0.0020524\ttotal: 24.9s\tremaining: 31s\n",
      "836:\tlearn: 0.0020476\ttotal: 25s\tremaining: 31s\n",
      "837:\tlearn: 0.0020453\ttotal: 25s\tremaining: 30.9s\n",
      "838:\tlearn: 0.0020453\ttotal: 25s\tremaining: 30.9s\n",
      "839:\tlearn: 0.0020407\ttotal: 25.1s\tremaining: 30.9s\n",
      "840:\tlearn: 0.0020407\ttotal: 25.1s\tremaining: 30.8s\n",
      "841:\tlearn: 0.0020385\ttotal: 25.1s\tremaining: 30.8s\n",
      "842:\tlearn: 0.0020338\ttotal: 25.1s\tremaining: 30.8s\n",
      "843:\tlearn: 0.0020292\ttotal: 25.2s\tremaining: 30.8s\n",
      "844:\tlearn: 0.0020246\ttotal: 25.2s\tremaining: 30.7s\n",
      "845:\tlearn: 0.0020215\ttotal: 25.2s\tremaining: 30.7s\n",
      "846:\tlearn: 0.0020215\ttotal: 25.3s\tremaining: 30.7s\n",
      "847:\tlearn: 0.0020215\ttotal: 25.3s\tremaining: 30.6s\n",
      "848:\tlearn: 0.0020195\ttotal: 25.3s\tremaining: 30.6s\n",
      "849:\tlearn: 0.0020131\ttotal: 25.3s\tremaining: 30.6s\n",
      "850:\tlearn: 0.0020079\ttotal: 25.4s\tremaining: 30.5s\n",
      "851:\tlearn: 0.0020043\ttotal: 25.4s\tremaining: 30.5s\n",
      "852:\tlearn: 0.0019991\ttotal: 25.4s\tremaining: 30.5s\n",
      "853:\tlearn: 0.0019957\ttotal: 25.5s\tremaining: 30.4s\n",
      "854:\tlearn: 0.0019918\ttotal: 25.5s\tremaining: 30.4s\n",
      "855:\tlearn: 0.0019884\ttotal: 25.5s\tremaining: 30.4s\n",
      "856:\tlearn: 0.0019814\ttotal: 25.6s\tremaining: 30.4s\n",
      "857:\tlearn: 0.0019814\ttotal: 25.6s\tremaining: 30.3s\n",
      "858:\tlearn: 0.0019779\ttotal: 25.6s\tremaining: 30.3s\n",
      "859:\tlearn: 0.0019726\ttotal: 25.6s\tremaining: 30.3s\n",
      "860:\tlearn: 0.0019706\ttotal: 25.7s\tremaining: 30.2s\n",
      "861:\tlearn: 0.0019674\ttotal: 25.7s\tremaining: 30.2s\n",
      "862:\tlearn: 0.0019674\ttotal: 25.7s\tremaining: 30.2s\n",
      "863:\tlearn: 0.0019674\ttotal: 25.8s\tremaining: 30.1s\n",
      "864:\tlearn: 0.0019674\ttotal: 25.8s\tremaining: 30.1s\n",
      "865:\tlearn: 0.0019642\ttotal: 25.8s\tremaining: 30.1s\n",
      "866:\tlearn: 0.0019618\ttotal: 25.8s\tremaining: 30.1s\n",
      "867:\tlearn: 0.0019582\ttotal: 25.9s\tremaining: 30s\n",
      "868:\tlearn: 0.0019539\ttotal: 25.9s\tremaining: 30s\n",
      "869:\tlearn: 0.0019539\ttotal: 25.9s\tremaining: 30s\n",
      "870:\tlearn: 0.0019539\ttotal: 26s\tremaining: 29.9s\n",
      "871:\tlearn: 0.0019483\ttotal: 26s\tremaining: 29.9s\n",
      "872:\tlearn: 0.0019444\ttotal: 26s\tremaining: 29.9s\n",
      "873:\tlearn: 0.0019418\ttotal: 26.1s\tremaining: 29.8s\n",
      "874:\tlearn: 0.0019383\ttotal: 26.1s\tremaining: 29.8s\n",
      "875:\tlearn: 0.0019383\ttotal: 26.1s\tremaining: 29.8s\n",
      "876:\tlearn: 0.0019383\ttotal: 26.1s\tremaining: 29.8s\n",
      "877:\tlearn: 0.0019371\ttotal: 26.2s\tremaining: 29.7s\n",
      "878:\tlearn: 0.0019371\ttotal: 26.2s\tremaining: 29.7s\n",
      "879:\tlearn: 0.0019371\ttotal: 26.2s\tremaining: 29.7s\n",
      "880:\tlearn: 0.0019371\ttotal: 26.3s\tremaining: 29.6s\n",
      "881:\tlearn: 0.0019371\ttotal: 26.3s\tremaining: 29.6s\n",
      "882:\tlearn: 0.0019320\ttotal: 26.3s\tremaining: 29.6s\n",
      "883:\tlearn: 0.0019291\ttotal: 26.3s\tremaining: 29.5s\n",
      "884:\tlearn: 0.0019285\ttotal: 26.4s\tremaining: 29.5s\n",
      "885:\tlearn: 0.0019285\ttotal: 26.4s\tremaining: 29.5s\n",
      "886:\tlearn: 0.0019285\ttotal: 26.4s\tremaining: 29.4s\n",
      "887:\tlearn: 0.0019259\ttotal: 26.5s\tremaining: 29.4s\n",
      "888:\tlearn: 0.0019259\ttotal: 26.5s\tremaining: 29.4s\n",
      "889:\tlearn: 0.0019259\ttotal: 26.5s\tremaining: 29.4s\n",
      "890:\tlearn: 0.0019232\ttotal: 26.6s\tremaining: 29.3s\n",
      "891:\tlearn: 0.0019232\ttotal: 26.6s\tremaining: 29.3s\n",
      "892:\tlearn: 0.0019189\ttotal: 26.6s\tremaining: 29.3s\n",
      "893:\tlearn: 0.0019189\ttotal: 26.7s\tremaining: 29.2s\n",
      "894:\tlearn: 0.0019147\ttotal: 26.7s\tremaining: 29.2s\n",
      "895:\tlearn: 0.0019140\ttotal: 26.7s\tremaining: 29.2s\n",
      "896:\tlearn: 0.0019140\ttotal: 26.7s\tremaining: 29.2s\n",
      "897:\tlearn: 0.0019082\ttotal: 26.8s\tremaining: 29.1s\n",
      "898:\tlearn: 0.0019082\ttotal: 26.8s\tremaining: 29.1s\n",
      "899:\tlearn: 0.0019056\ttotal: 26.8s\tremaining: 29.1s\n",
      "900:\tlearn: 0.0019016\ttotal: 26.9s\tremaining: 29s\n",
      "901:\tlearn: 0.0019016\ttotal: 26.9s\tremaining: 29s\n",
      "902:\tlearn: 0.0018964\ttotal: 26.9s\tremaining: 29s\n",
      "903:\tlearn: 0.0018896\ttotal: 26.9s\tremaining: 28.9s\n",
      "904:\tlearn: 0.0018859\ttotal: 27s\tremaining: 28.9s\n",
      "905:\tlearn: 0.0018859\ttotal: 27s\tremaining: 28.9s\n",
      "906:\tlearn: 0.0018859\ttotal: 27s\tremaining: 28.9s\n",
      "907:\tlearn: 0.0018854\ttotal: 27.1s\tremaining: 28.8s\n",
      "908:\tlearn: 0.0018814\ttotal: 27.1s\tremaining: 28.8s\n",
      "909:\tlearn: 0.0018814\ttotal: 27.1s\tremaining: 28.8s\n",
      "910:\tlearn: 0.0018792\ttotal: 27.2s\tremaining: 28.7s\n",
      "911:\tlearn: 0.0018775\ttotal: 27.2s\tremaining: 28.7s\n",
      "912:\tlearn: 0.0018775\ttotal: 27.2s\tremaining: 28.7s\n",
      "913:\tlearn: 0.0018775\ttotal: 27.3s\tremaining: 28.7s\n",
      "914:\tlearn: 0.0018763\ttotal: 27.3s\tremaining: 28.6s\n",
      "915:\tlearn: 0.0018755\ttotal: 27.3s\tremaining: 28.6s\n",
      "916:\tlearn: 0.0018754\ttotal: 27.3s\tremaining: 28.6s\n",
      "917:\tlearn: 0.0018719\ttotal: 27.4s\tremaining: 28.5s\n",
      "918:\tlearn: 0.0018689\ttotal: 27.4s\tremaining: 28.5s\n",
      "919:\tlearn: 0.0018653\ttotal: 27.4s\tremaining: 28.5s\n",
      "920:\tlearn: 0.0018593\ttotal: 27.5s\tremaining: 28.4s\n",
      "921:\tlearn: 0.0018593\ttotal: 27.5s\tremaining: 28.4s\n",
      "922:\tlearn: 0.0018593\ttotal: 27.5s\tremaining: 28.4s\n",
      "923:\tlearn: 0.0018593\ttotal: 27.5s\tremaining: 28.3s\n",
      "924:\tlearn: 0.0018593\ttotal: 27.6s\tremaining: 28.3s\n",
      "925:\tlearn: 0.0018593\ttotal: 27.6s\tremaining: 28.3s\n",
      "926:\tlearn: 0.0018577\ttotal: 27.6s\tremaining: 28.3s\n",
      "927:\tlearn: 0.0018577\ttotal: 27.7s\tremaining: 28.2s\n",
      "928:\tlearn: 0.0018577\ttotal: 27.7s\tremaining: 28.2s\n",
      "929:\tlearn: 0.0018577\ttotal: 27.7s\tremaining: 28.2s\n",
      "930:\tlearn: 0.0018577\ttotal: 27.7s\tremaining: 28.1s\n",
      "931:\tlearn: 0.0018577\ttotal: 27.8s\tremaining: 28.1s\n",
      "932:\tlearn: 0.0018577\ttotal: 27.8s\tremaining: 28.1s\n",
      "933:\tlearn: 0.0018577\ttotal: 27.8s\tremaining: 28s\n",
      "934:\tlearn: 0.0018577\ttotal: 27.9s\tremaining: 28s\n",
      "935:\tlearn: 0.0018577\ttotal: 27.9s\tremaining: 28s\n",
      "936:\tlearn: 0.0018577\ttotal: 27.9s\tremaining: 28s\n",
      "937:\tlearn: 0.0018577\ttotal: 28s\tremaining: 27.9s\n",
      "938:\tlearn: 0.0018548\ttotal: 28s\tremaining: 27.9s\n",
      "939:\tlearn: 0.0018548\ttotal: 28s\tremaining: 27.9s\n",
      "940:\tlearn: 0.0018548\ttotal: 28s\tremaining: 27.8s\n",
      "941:\tlearn: 0.0018548\ttotal: 28.1s\tremaining: 27.8s\n",
      "942:\tlearn: 0.0018529\ttotal: 28.1s\tremaining: 27.8s\n",
      "943:\tlearn: 0.0018529\ttotal: 28.1s\tremaining: 27.7s\n",
      "944:\tlearn: 0.0018476\ttotal: 28.2s\tremaining: 27.7s\n",
      "945:\tlearn: 0.0018476\ttotal: 28.2s\tremaining: 27.7s\n",
      "946:\tlearn: 0.0018476\ttotal: 28.2s\tremaining: 27.7s\n",
      "947:\tlearn: 0.0018430\ttotal: 28.2s\tremaining: 27.6s\n",
      "948:\tlearn: 0.0018369\ttotal: 28.3s\tremaining: 27.6s\n",
      "949:\tlearn: 0.0018369\ttotal: 28.3s\tremaining: 27.6s\n",
      "950:\tlearn: 0.0018323\ttotal: 28.3s\tremaining: 27.5s\n",
      "951:\tlearn: 0.0018274\ttotal: 28.4s\tremaining: 27.5s\n",
      "952:\tlearn: 0.0018274\ttotal: 28.4s\tremaining: 27.5s\n",
      "953:\tlearn: 0.0018274\ttotal: 28.4s\tremaining: 27.4s\n",
      "954:\tlearn: 0.0018274\ttotal: 28.5s\tremaining: 27.4s\n",
      "955:\tlearn: 0.0018274\ttotal: 28.5s\tremaining: 27.4s\n",
      "956:\tlearn: 0.0018257\ttotal: 28.5s\tremaining: 27.3s\n",
      "957:\tlearn: 0.0018257\ttotal: 28.5s\tremaining: 27.3s\n",
      "958:\tlearn: 0.0018217\ttotal: 28.6s\tremaining: 27.3s\n",
      "959:\tlearn: 0.0018208\ttotal: 28.6s\tremaining: 27.3s\n",
      "960:\tlearn: 0.0018167\ttotal: 28.6s\tremaining: 27.2s\n",
      "961:\tlearn: 0.0018167\ttotal: 28.7s\tremaining: 27.2s\n",
      "962:\tlearn: 0.0018126\ttotal: 28.7s\tremaining: 27.2s\n",
      "963:\tlearn: 0.0018074\ttotal: 28.7s\tremaining: 27.1s\n",
      "964:\tlearn: 0.0018074\ttotal: 28.7s\tremaining: 27.1s\n",
      "965:\tlearn: 0.0018043\ttotal: 28.8s\tremaining: 27.1s\n",
      "966:\tlearn: 0.0018006\ttotal: 28.8s\tremaining: 27s\n",
      "967:\tlearn: 0.0018006\ttotal: 28.8s\tremaining: 27s\n",
      "968:\tlearn: 0.0018006\ttotal: 28.9s\tremaining: 27s\n",
      "969:\tlearn: 0.0018006\ttotal: 28.9s\tremaining: 27s\n",
      "970:\tlearn: 0.0018006\ttotal: 28.9s\tremaining: 26.9s\n",
      "971:\tlearn: 0.0018006\ttotal: 28.9s\tremaining: 26.9s\n",
      "972:\tlearn: 0.0018000\ttotal: 29s\tremaining: 26.9s\n",
      "973:\tlearn: 0.0017999\ttotal: 29s\tremaining: 26.8s\n",
      "974:\tlearn: 0.0017999\ttotal: 29s\tremaining: 26.8s\n",
      "975:\tlearn: 0.0017999\ttotal: 29.1s\tremaining: 26.8s\n",
      "976:\tlearn: 0.0017999\ttotal: 29.1s\tremaining: 26.7s\n",
      "977:\tlearn: 0.0017999\ttotal: 29.1s\tremaining: 26.7s\n",
      "978:\tlearn: 0.0017956\ttotal: 29.2s\tremaining: 26.7s\n",
      "979:\tlearn: 0.0017929\ttotal: 29.2s\tremaining: 26.7s\n",
      "980:\tlearn: 0.0017872\ttotal: 29.2s\tremaining: 26.6s\n",
      "981:\tlearn: 0.0017872\ttotal: 29.2s\tremaining: 26.6s\n",
      "982:\tlearn: 0.0017806\ttotal: 29.3s\tremaining: 26.6s\n",
      "983:\tlearn: 0.0017806\ttotal: 29.3s\tremaining: 26.5s\n",
      "984:\tlearn: 0.0017767\ttotal: 29.3s\tremaining: 26.5s\n",
      "985:\tlearn: 0.0017715\ttotal: 29.4s\tremaining: 26.5s\n",
      "986:\tlearn: 0.0017715\ttotal: 29.4s\tremaining: 26.4s\n",
      "987:\tlearn: 0.0017715\ttotal: 29.4s\tremaining: 26.4s\n",
      "988:\tlearn: 0.0017695\ttotal: 29.4s\tremaining: 26.4s\n",
      "989:\tlearn: 0.0017656\ttotal: 29.5s\tremaining: 26.3s\n",
      "990:\tlearn: 0.0017602\ttotal: 29.5s\tremaining: 26.3s\n",
      "991:\tlearn: 0.0017568\ttotal: 29.5s\tremaining: 26.3s\n",
      "992:\tlearn: 0.0017568\ttotal: 29.6s\tremaining: 26.3s\n",
      "993:\tlearn: 0.0017565\ttotal: 29.6s\tremaining: 26.2s\n",
      "994:\tlearn: 0.0017565\ttotal: 29.6s\tremaining: 26.2s\n",
      "995:\tlearn: 0.0017565\ttotal: 29.6s\tremaining: 26.2s\n",
      "996:\tlearn: 0.0017509\ttotal: 29.7s\tremaining: 26.1s\n",
      "997:\tlearn: 0.0017480\ttotal: 29.7s\tremaining: 26.1s\n",
      "998:\tlearn: 0.0017427\ttotal: 29.7s\tremaining: 26.1s\n",
      "999:\tlearn: 0.0017396\ttotal: 29.8s\tremaining: 26s\n",
      "1000:\tlearn: 0.0017396\ttotal: 29.8s\tremaining: 26s\n",
      "1001:\tlearn: 0.0017396\ttotal: 29.8s\tremaining: 26s\n",
      "1002:\tlearn: 0.0017396\ttotal: 29.9s\tremaining: 26s\n",
      "1003:\tlearn: 0.0017370\ttotal: 29.9s\tremaining: 25.9s\n",
      "1004:\tlearn: 0.0017370\ttotal: 29.9s\tremaining: 25.9s\n",
      "1005:\tlearn: 0.0017349\ttotal: 29.9s\tremaining: 25.9s\n",
      "1006:\tlearn: 0.0017346\ttotal: 30s\tremaining: 25.8s\n",
      "1007:\tlearn: 0.0017346\ttotal: 30s\tremaining: 25.8s\n",
      "1008:\tlearn: 0.0017346\ttotal: 30s\tremaining: 25.8s\n",
      "1009:\tlearn: 0.0017346\ttotal: 30.1s\tremaining: 25.7s\n",
      "1010:\tlearn: 0.0017324\ttotal: 30.1s\tremaining: 25.7s\n",
      "1011:\tlearn: 0.0017324\ttotal: 30.1s\tremaining: 25.7s\n",
      "1012:\tlearn: 0.0017324\ttotal: 30.1s\tremaining: 25.6s\n",
      "1013:\tlearn: 0.0017323\ttotal: 30.2s\tremaining: 25.6s\n",
      "1014:\tlearn: 0.0017289\ttotal: 30.2s\tremaining: 25.6s\n",
      "1015:\tlearn: 0.0017289\ttotal: 30.2s\tremaining: 25.6s\n",
      "1016:\tlearn: 0.0017289\ttotal: 30.3s\tremaining: 25.5s\n",
      "1017:\tlearn: 0.0017289\ttotal: 30.3s\tremaining: 25.5s\n",
      "1018:\tlearn: 0.0017289\ttotal: 30.3s\tremaining: 25.5s\n",
      "1019:\tlearn: 0.0017251\ttotal: 30.3s\tremaining: 25.4s\n",
      "1020:\tlearn: 0.0017251\ttotal: 30.4s\tremaining: 25.4s\n",
      "1021:\tlearn: 0.0017214\ttotal: 30.4s\tremaining: 25.4s\n",
      "1022:\tlearn: 0.0017214\ttotal: 30.4s\tremaining: 25.3s\n",
      "1023:\tlearn: 0.0017214\ttotal: 30.5s\tremaining: 25.3s\n",
      "1024:\tlearn: 0.0017214\ttotal: 30.5s\tremaining: 25.3s\n",
      "1025:\tlearn: 0.0017214\ttotal: 30.5s\tremaining: 25.3s\n",
      "1026:\tlearn: 0.0017214\ttotal: 30.5s\tremaining: 25.2s\n",
      "1027:\tlearn: 0.0017214\ttotal: 30.6s\tremaining: 25.2s\n",
      "1028:\tlearn: 0.0017214\ttotal: 30.6s\tremaining: 25.2s\n",
      "1029:\tlearn: 0.0017198\ttotal: 30.6s\tremaining: 25.1s\n",
      "1030:\tlearn: 0.0017162\ttotal: 30.7s\tremaining: 25.1s\n",
      "1031:\tlearn: 0.0017162\ttotal: 30.7s\tremaining: 25.1s\n",
      "1032:\tlearn: 0.0017158\ttotal: 30.7s\tremaining: 25s\n",
      "1033:\tlearn: 0.0017140\ttotal: 30.8s\tremaining: 25s\n",
      "1034:\tlearn: 0.0017140\ttotal: 30.8s\tremaining: 25s\n",
      "1035:\tlearn: 0.0017140\ttotal: 30.8s\tremaining: 25s\n",
      "1036:\tlearn: 0.0017140\ttotal: 30.8s\tremaining: 24.9s\n",
      "1037:\tlearn: 0.0017140\ttotal: 30.9s\tremaining: 24.9s\n",
      "1038:\tlearn: 0.0017140\ttotal: 30.9s\tremaining: 24.9s\n",
      "1039:\tlearn: 0.0017140\ttotal: 30.9s\tremaining: 24.8s\n",
      "1040:\tlearn: 0.0017139\ttotal: 31s\tremaining: 24.8s\n",
      "1041:\tlearn: 0.0017139\ttotal: 31s\tremaining: 24.8s\n",
      "1042:\tlearn: 0.0017139\ttotal: 31s\tremaining: 24.7s\n",
      "1043:\tlearn: 0.0017139\ttotal: 31s\tremaining: 24.7s\n",
      "1044:\tlearn: 0.0017111\ttotal: 31.1s\tremaining: 24.7s\n",
      "1045:\tlearn: 0.0017083\ttotal: 31.1s\tremaining: 24.6s\n",
      "1046:\tlearn: 0.0017083\ttotal: 31.1s\tremaining: 24.6s\n",
      "1047:\tlearn: 0.0017083\ttotal: 31.2s\tremaining: 24.6s\n",
      "1048:\tlearn: 0.0017083\ttotal: 31.2s\tremaining: 24.6s\n",
      "1049:\tlearn: 0.0017083\ttotal: 31.2s\tremaining: 24.5s\n",
      "1050:\tlearn: 0.0017083\ttotal: 31.2s\tremaining: 24.5s\n",
      "1051:\tlearn: 0.0017082\ttotal: 31.3s\tremaining: 24.5s\n",
      "1052:\tlearn: 0.0017080\ttotal: 31.3s\tremaining: 24.4s\n",
      "1053:\tlearn: 0.0017080\ttotal: 31.3s\tremaining: 24.4s\n",
      "1054:\tlearn: 0.0017053\ttotal: 31.4s\tremaining: 24.4s\n",
      "1055:\tlearn: 0.0017018\ttotal: 31.4s\tremaining: 24.3s\n",
      "1056:\tlearn: 0.0017018\ttotal: 31.4s\tremaining: 24.3s\n",
      "1057:\tlearn: 0.0016982\ttotal: 31.5s\tremaining: 24.3s\n",
      "1058:\tlearn: 0.0016982\ttotal: 31.5s\tremaining: 24.3s\n",
      "1059:\tlearn: 0.0016933\ttotal: 31.5s\tremaining: 24.2s\n",
      "1060:\tlearn: 0.0016932\ttotal: 31.5s\tremaining: 24.2s\n",
      "1061:\tlearn: 0.0016903\ttotal: 31.6s\tremaining: 24.2s\n",
      "1062:\tlearn: 0.0016903\ttotal: 31.6s\tremaining: 24.1s\n",
      "1063:\tlearn: 0.0016903\ttotal: 31.6s\tremaining: 24.1s\n",
      "1064:\tlearn: 0.0016875\ttotal: 31.7s\tremaining: 24.1s\n",
      "1065:\tlearn: 0.0016875\ttotal: 31.7s\tremaining: 24.1s\n",
      "1066:\tlearn: 0.0016875\ttotal: 31.7s\tremaining: 24s\n",
      "1067:\tlearn: 0.0016875\ttotal: 31.8s\tremaining: 24s\n",
      "1068:\tlearn: 0.0016875\ttotal: 31.8s\tremaining: 24s\n",
      "1069:\tlearn: 0.0016875\ttotal: 31.8s\tremaining: 23.9s\n",
      "1070:\tlearn: 0.0016875\ttotal: 31.8s\tremaining: 23.9s\n",
      "1071:\tlearn: 0.0016875\ttotal: 31.9s\tremaining: 23.9s\n",
      "1072:\tlearn: 0.0016875\ttotal: 31.9s\tremaining: 23.8s\n",
      "1073:\tlearn: 0.0016851\ttotal: 31.9s\tremaining: 23.8s\n",
      "1074:\tlearn: 0.0016851\ttotal: 32s\tremaining: 23.8s\n",
      "1075:\tlearn: 0.0016851\ttotal: 32s\tremaining: 23.8s\n",
      "1076:\tlearn: 0.0016851\ttotal: 32s\tremaining: 23.7s\n",
      "1077:\tlearn: 0.0016851\ttotal: 32s\tremaining: 23.7s\n",
      "1078:\tlearn: 0.0016850\ttotal: 32.1s\tremaining: 23.7s\n",
      "1079:\tlearn: 0.0016850\ttotal: 32.1s\tremaining: 23.6s\n",
      "1080:\tlearn: 0.0016850\ttotal: 32.1s\tremaining: 23.6s\n",
      "1081:\tlearn: 0.0016850\ttotal: 32.2s\tremaining: 23.6s\n",
      "1082:\tlearn: 0.0016850\ttotal: 32.2s\tremaining: 23.5s\n",
      "1083:\tlearn: 0.0016849\ttotal: 32.2s\tremaining: 23.5s\n",
      "1084:\tlearn: 0.0016849\ttotal: 32.3s\tremaining: 23.5s\n",
      "1085:\tlearn: 0.0016849\ttotal: 32.3s\tremaining: 23.5s\n",
      "1086:\tlearn: 0.0016847\ttotal: 32.3s\tremaining: 23.4s\n",
      "1087:\tlearn: 0.0016847\ttotal: 32.3s\tremaining: 23.4s\n",
      "1088:\tlearn: 0.0016847\ttotal: 32.4s\tremaining: 23.4s\n",
      "1089:\tlearn: 0.0016838\ttotal: 32.4s\tremaining: 23.3s\n",
      "1090:\tlearn: 0.0016838\ttotal: 32.4s\tremaining: 23.3s\n",
      "1091:\tlearn: 0.0016816\ttotal: 32.5s\tremaining: 23.3s\n",
      "1092:\tlearn: 0.0016816\ttotal: 32.5s\tremaining: 23.2s\n",
      "1093:\tlearn: 0.0016782\ttotal: 32.5s\tremaining: 23.2s\n",
      "1094:\tlearn: 0.0016782\ttotal: 32.5s\tremaining: 23.2s\n",
      "1095:\tlearn: 0.0016782\ttotal: 32.6s\tremaining: 23.2s\n",
      "1096:\tlearn: 0.0016782\ttotal: 32.6s\tremaining: 23.1s\n",
      "1097:\tlearn: 0.0016782\ttotal: 32.6s\tremaining: 23.1s\n",
      "1098:\tlearn: 0.0016782\ttotal: 32.7s\tremaining: 23.1s\n",
      "1099:\tlearn: 0.0016782\ttotal: 32.7s\tremaining: 23s\n",
      "1100:\tlearn: 0.0016746\ttotal: 32.7s\tremaining: 23s\n",
      "1101:\tlearn: 0.0016715\ttotal: 32.7s\tremaining: 23s\n",
      "1102:\tlearn: 0.0016715\ttotal: 32.8s\tremaining: 22.9s\n",
      "1103:\tlearn: 0.0016715\ttotal: 32.8s\tremaining: 22.9s\n",
      "1104:\tlearn: 0.0016715\ttotal: 32.8s\tremaining: 22.9s\n",
      "1105:\tlearn: 0.0016715\ttotal: 32.9s\tremaining: 22.9s\n",
      "1106:\tlearn: 0.0016715\ttotal: 32.9s\tremaining: 22.8s\n",
      "1107:\tlearn: 0.0016715\ttotal: 32.9s\tremaining: 22.8s\n",
      "1108:\tlearn: 0.0016715\ttotal: 33s\tremaining: 22.8s\n",
      "1109:\tlearn: 0.0016694\ttotal: 33s\tremaining: 22.7s\n",
      "1110:\tlearn: 0.0016694\ttotal: 33s\tremaining: 22.7s\n",
      "1111:\tlearn: 0.0016694\ttotal: 33s\tremaining: 22.7s\n",
      "1112:\tlearn: 0.0016650\ttotal: 33.1s\tremaining: 22.6s\n",
      "1113:\tlearn: 0.0016650\ttotal: 33.1s\tremaining: 22.6s\n",
      "1114:\tlearn: 0.0016650\ttotal: 33.1s\tremaining: 22.6s\n",
      "1115:\tlearn: 0.0016623\ttotal: 33.2s\tremaining: 22.6s\n",
      "1116:\tlearn: 0.0016567\ttotal: 33.2s\tremaining: 22.5s\n",
      "1117:\tlearn: 0.0016567\ttotal: 33.2s\tremaining: 22.5s\n",
      "1118:\tlearn: 0.0016567\ttotal: 33.3s\tremaining: 22.5s\n",
      "1119:\tlearn: 0.0016567\ttotal: 33.3s\tremaining: 22.4s\n",
      "1120:\tlearn: 0.0016567\ttotal: 33.3s\tremaining: 22.4s\n",
      "1121:\tlearn: 0.0016567\ttotal: 33.3s\tremaining: 22.4s\n",
      "1122:\tlearn: 0.0016567\ttotal: 33.4s\tremaining: 22.3s\n",
      "1123:\tlearn: 0.0016566\ttotal: 33.4s\tremaining: 22.3s\n",
      "1124:\tlearn: 0.0016530\ttotal: 33.4s\tremaining: 22.3s\n",
      "1125:\tlearn: 0.0016530\ttotal: 33.5s\tremaining: 22.3s\n",
      "1126:\tlearn: 0.0016530\ttotal: 33.5s\tremaining: 22.2s\n",
      "1127:\tlearn: 0.0016504\ttotal: 33.5s\tremaining: 22.2s\n",
      "1128:\tlearn: 0.0016504\ttotal: 33.5s\tremaining: 22.2s\n",
      "1129:\tlearn: 0.0016462\ttotal: 33.6s\tremaining: 22.1s\n",
      "1130:\tlearn: 0.0016462\ttotal: 33.6s\tremaining: 22.1s\n",
      "1131:\tlearn: 0.0016459\ttotal: 33.6s\tremaining: 22.1s\n",
      "1132:\tlearn: 0.0016410\ttotal: 33.7s\tremaining: 22s\n",
      "1133:\tlearn: 0.0016384\ttotal: 33.7s\tremaining: 22s\n",
      "1134:\tlearn: 0.0016358\ttotal: 33.7s\tremaining: 22s\n",
      "1135:\tlearn: 0.0016357\ttotal: 33.8s\tremaining: 22s\n",
      "1136:\tlearn: 0.0016357\ttotal: 33.8s\tremaining: 21.9s\n",
      "1137:\tlearn: 0.0016357\ttotal: 33.8s\tremaining: 21.9s\n",
      "1138:\tlearn: 0.0016357\ttotal: 33.8s\tremaining: 21.9s\n",
      "1139:\tlearn: 0.0016357\ttotal: 33.9s\tremaining: 21.8s\n",
      "1140:\tlearn: 0.0016357\ttotal: 33.9s\tremaining: 21.8s\n",
      "1141:\tlearn: 0.0016308\ttotal: 33.9s\tremaining: 21.8s\n",
      "1142:\tlearn: 0.0016308\ttotal: 34s\tremaining: 21.7s\n",
      "1143:\tlearn: 0.0016308\ttotal: 34s\tremaining: 21.7s\n",
      "1144:\tlearn: 0.0016308\ttotal: 34s\tremaining: 21.7s\n",
      "1145:\tlearn: 0.0016308\ttotal: 34s\tremaining: 21.7s\n",
      "1146:\tlearn: 0.0016307\ttotal: 34.1s\tremaining: 21.6s\n",
      "1147:\tlearn: 0.0016294\ttotal: 34.1s\tremaining: 21.6s\n",
      "1148:\tlearn: 0.0016294\ttotal: 34.1s\tremaining: 21.6s\n",
      "1149:\tlearn: 0.0016294\ttotal: 34.2s\tremaining: 21.5s\n",
      "1150:\tlearn: 0.0016274\ttotal: 34.2s\tremaining: 21.5s\n",
      "1151:\tlearn: 0.0016235\ttotal: 34.2s\tremaining: 21.5s\n",
      "1152:\tlearn: 0.0016235\ttotal: 34.3s\tremaining: 21.4s\n",
      "1153:\tlearn: 0.0016235\ttotal: 34.3s\tremaining: 21.4s\n",
      "1154:\tlearn: 0.0016235\ttotal: 34.3s\tremaining: 21.4s\n",
      "1155:\tlearn: 0.0016235\ttotal: 34.3s\tremaining: 21.4s\n",
      "1156:\tlearn: 0.0016235\ttotal: 34.4s\tremaining: 21.3s\n",
      "1157:\tlearn: 0.0016235\ttotal: 34.4s\tremaining: 21.3s\n",
      "1158:\tlearn: 0.0016218\ttotal: 34.4s\tremaining: 21.3s\n",
      "1159:\tlearn: 0.0016218\ttotal: 34.5s\tremaining: 21.2s\n",
      "1160:\tlearn: 0.0016217\ttotal: 34.5s\tremaining: 21.2s\n",
      "1161:\tlearn: 0.0016217\ttotal: 34.5s\tremaining: 21.2s\n",
      "1162:\tlearn: 0.0016217\ttotal: 34.5s\tremaining: 21.1s\n",
      "1163:\tlearn: 0.0016180\ttotal: 34.6s\tremaining: 21.1s\n",
      "1164:\tlearn: 0.0016180\ttotal: 34.6s\tremaining: 21.1s\n",
      "1165:\tlearn: 0.0016139\ttotal: 34.6s\tremaining: 21.1s\n",
      "1166:\tlearn: 0.0016139\ttotal: 34.7s\tremaining: 21s\n",
      "1167:\tlearn: 0.0016138\ttotal: 34.7s\tremaining: 21s\n",
      "1168:\tlearn: 0.0016138\ttotal: 34.7s\tremaining: 21s\n",
      "1169:\tlearn: 0.0016138\ttotal: 34.8s\tremaining: 20.9s\n",
      "1170:\tlearn: 0.0016134\ttotal: 34.8s\tremaining: 20.9s\n",
      "1171:\tlearn: 0.0016116\ttotal: 34.8s\tremaining: 20.9s\n",
      "1172:\tlearn: 0.0016087\ttotal: 34.8s\tremaining: 20.8s\n",
      "1173:\tlearn: 0.0016087\ttotal: 34.9s\tremaining: 20.8s\n",
      "1174:\tlearn: 0.0016087\ttotal: 34.9s\tremaining: 20.8s\n",
      "1175:\tlearn: 0.0016087\ttotal: 34.9s\tremaining: 20.8s\n",
      "1176:\tlearn: 0.0016087\ttotal: 35s\tremaining: 20.7s\n",
      "1177:\tlearn: 0.0016087\ttotal: 35s\tremaining: 20.7s\n",
      "1178:\tlearn: 0.0016087\ttotal: 35s\tremaining: 20.7s\n",
      "1179:\tlearn: 0.0016067\ttotal: 35s\tremaining: 20.6s\n",
      "1180:\tlearn: 0.0016067\ttotal: 35.1s\tremaining: 20.6s\n",
      "1181:\tlearn: 0.0016067\ttotal: 35.1s\tremaining: 20.6s\n",
      "1182:\tlearn: 0.0016067\ttotal: 35.1s\tremaining: 20.6s\n",
      "1183:\tlearn: 0.0016067\ttotal: 35.2s\tremaining: 20.5s\n",
      "1184:\tlearn: 0.0016067\ttotal: 35.2s\tremaining: 20.5s\n",
      "1185:\tlearn: 0.0016067\ttotal: 35.2s\tremaining: 20.5s\n",
      "1186:\tlearn: 0.0016066\ttotal: 35.3s\tremaining: 20.4s\n",
      "1187:\tlearn: 0.0016059\ttotal: 35.3s\tremaining: 20.4s\n",
      "1188:\tlearn: 0.0016059\ttotal: 35.3s\tremaining: 20.4s\n",
      "1189:\tlearn: 0.0016056\ttotal: 35.3s\tremaining: 20.3s\n",
      "1190:\tlearn: 0.0016056\ttotal: 35.4s\tremaining: 20.3s\n",
      "1191:\tlearn: 0.0016056\ttotal: 35.4s\tremaining: 20.3s\n",
      "1192:\tlearn: 0.0016049\ttotal: 35.4s\tremaining: 20.3s\n",
      "1193:\tlearn: 0.0016015\ttotal: 35.5s\tremaining: 20.2s\n",
      "1194:\tlearn: 0.0016015\ttotal: 35.5s\tremaining: 20.2s\n",
      "1195:\tlearn: 0.0016015\ttotal: 35.6s\tremaining: 20.2s\n",
      "1196:\tlearn: 0.0016015\ttotal: 35.6s\tremaining: 20.2s\n",
      "1197:\tlearn: 0.0016015\ttotal: 35.6s\tremaining: 20.1s\n",
      "1198:\tlearn: 0.0016015\ttotal: 35.6s\tremaining: 20.1s\n",
      "1199:\tlearn: 0.0016015\ttotal: 35.7s\tremaining: 20.1s\n",
      "1200:\tlearn: 0.0016015\ttotal: 35.7s\tremaining: 20s\n",
      "1201:\tlearn: 0.0016015\ttotal: 35.7s\tremaining: 20s\n",
      "1202:\tlearn: 0.0016014\ttotal: 35.8s\tremaining: 20s\n",
      "1203:\tlearn: 0.0016014\ttotal: 35.8s\tremaining: 19.9s\n",
      "1204:\tlearn: 0.0016011\ttotal: 35.8s\tremaining: 19.9s\n",
      "1205:\tlearn: 0.0015983\ttotal: 35.9s\tremaining: 19.9s\n",
      "1206:\tlearn: 0.0015982\ttotal: 35.9s\tremaining: 19.9s\n",
      "1207:\tlearn: 0.0015929\ttotal: 35.9s\tremaining: 19.8s\n",
      "1208:\tlearn: 0.0015928\ttotal: 35.9s\tremaining: 19.8s\n",
      "1209:\tlearn: 0.0015903\ttotal: 36s\tremaining: 19.8s\n",
      "1210:\tlearn: 0.0015903\ttotal: 36s\tremaining: 19.7s\n",
      "1211:\tlearn: 0.0015903\ttotal: 36s\tremaining: 19.7s\n",
      "1212:\tlearn: 0.0015903\ttotal: 36.1s\tremaining: 19.7s\n",
      "1213:\tlearn: 0.0015903\ttotal: 36.1s\tremaining: 19.6s\n",
      "1214:\tlearn: 0.0015902\ttotal: 36.1s\tremaining: 19.6s\n",
      "1215:\tlearn: 0.0015902\ttotal: 36.1s\tremaining: 19.6s\n",
      "1216:\tlearn: 0.0015902\ttotal: 36.2s\tremaining: 19.6s\n",
      "1217:\tlearn: 0.0015902\ttotal: 36.2s\tremaining: 19.5s\n",
      "1218:\tlearn: 0.0015902\ttotal: 36.2s\tremaining: 19.5s\n",
      "1219:\tlearn: 0.0015862\ttotal: 36.3s\tremaining: 19.5s\n",
      "1220:\tlearn: 0.0015862\ttotal: 36.3s\tremaining: 19.4s\n",
      "1221:\tlearn: 0.0015862\ttotal: 36.3s\tremaining: 19.4s\n",
      "1222:\tlearn: 0.0015862\ttotal: 36.3s\tremaining: 19.4s\n",
      "1223:\tlearn: 0.0015845\ttotal: 36.4s\tremaining: 19.3s\n",
      "1224:\tlearn: 0.0015845\ttotal: 36.4s\tremaining: 19.3s\n",
      "1225:\tlearn: 0.0015845\ttotal: 36.4s\tremaining: 19.3s\n",
      "1226:\tlearn: 0.0015845\ttotal: 36.5s\tremaining: 19.3s\n",
      "1227:\tlearn: 0.0015845\ttotal: 36.5s\tremaining: 19.2s\n",
      "1228:\tlearn: 0.0015845\ttotal: 36.5s\tremaining: 19.2s\n",
      "1229:\tlearn: 0.0015845\ttotal: 36.6s\tremaining: 19.2s\n",
      "1230:\tlearn: 0.0015845\ttotal: 36.6s\tremaining: 19.1s\n",
      "1231:\tlearn: 0.0015845\ttotal: 36.6s\tremaining: 19.1s\n",
      "1232:\tlearn: 0.0015844\ttotal: 36.6s\tremaining: 19.1s\n",
      "1233:\tlearn: 0.0015844\ttotal: 36.7s\tremaining: 19s\n",
      "1234:\tlearn: 0.0015809\ttotal: 36.7s\tremaining: 19s\n",
      "1235:\tlearn: 0.0015809\ttotal: 36.7s\tremaining: 19s\n",
      "1236:\tlearn: 0.0015809\ttotal: 36.8s\tremaining: 19s\n",
      "1237:\tlearn: 0.0015809\ttotal: 36.8s\tremaining: 18.9s\n",
      "1238:\tlearn: 0.0015809\ttotal: 36.8s\tremaining: 18.9s\n",
      "1239:\tlearn: 0.0015809\ttotal: 36.8s\tremaining: 18.9s\n",
      "1240:\tlearn: 0.0015809\ttotal: 36.9s\tremaining: 18.8s\n",
      "1241:\tlearn: 0.0015809\ttotal: 36.9s\tremaining: 18.8s\n",
      "1242:\tlearn: 0.0015776\ttotal: 36.9s\tremaining: 18.8s\n",
      "1243:\tlearn: 0.0015776\ttotal: 37s\tremaining: 18.8s\n",
      "1244:\tlearn: 0.0015776\ttotal: 37s\tremaining: 18.7s\n",
      "1245:\tlearn: 0.0015776\ttotal: 37s\tremaining: 18.7s\n",
      "1246:\tlearn: 0.0015740\ttotal: 37.1s\tremaining: 18.7s\n",
      "1247:\tlearn: 0.0015706\ttotal: 37.1s\tremaining: 18.6s\n",
      "1248:\tlearn: 0.0015706\ttotal: 37.1s\tremaining: 18.6s\n",
      "1249:\tlearn: 0.0015706\ttotal: 37.1s\tremaining: 18.6s\n",
      "1250:\tlearn: 0.0015706\ttotal: 37.2s\tremaining: 18.5s\n",
      "1251:\tlearn: 0.0015706\ttotal: 37.2s\tremaining: 18.5s\n",
      "1252:\tlearn: 0.0015706\ttotal: 37.2s\tremaining: 18.5s\n",
      "1253:\tlearn: 0.0015648\ttotal: 37.3s\tremaining: 18.5s\n",
      "1254:\tlearn: 0.0015648\ttotal: 37.3s\tremaining: 18.4s\n",
      "1255:\tlearn: 0.0015648\ttotal: 37.3s\tremaining: 18.4s\n",
      "1256:\tlearn: 0.0015641\ttotal: 37.4s\tremaining: 18.4s\n",
      "1257:\tlearn: 0.0015641\ttotal: 37.4s\tremaining: 18.3s\n",
      "1258:\tlearn: 0.0015641\ttotal: 37.4s\tremaining: 18.3s\n",
      "1259:\tlearn: 0.0015641\ttotal: 37.4s\tremaining: 18.3s\n",
      "1260:\tlearn: 0.0015641\ttotal: 37.5s\tremaining: 18.2s\n",
      "1261:\tlearn: 0.0015609\ttotal: 37.5s\tremaining: 18.2s\n",
      "1262:\tlearn: 0.0015609\ttotal: 37.5s\tremaining: 18.2s\n",
      "1263:\tlearn: 0.0015609\ttotal: 37.6s\tremaining: 18.2s\n",
      "1264:\tlearn: 0.0015609\ttotal: 37.6s\tremaining: 18.1s\n",
      "1265:\tlearn: 0.0015576\ttotal: 37.6s\tremaining: 18.1s\n",
      "1266:\tlearn: 0.0015576\ttotal: 37.6s\tremaining: 18.1s\n",
      "1267:\tlearn: 0.0015518\ttotal: 37.7s\tremaining: 18s\n",
      "1268:\tlearn: 0.0015518\ttotal: 37.7s\tremaining: 18s\n",
      "1269:\tlearn: 0.0015518\ttotal: 37.7s\tremaining: 18s\n",
      "1270:\tlearn: 0.0015517\ttotal: 37.8s\tremaining: 17.9s\n",
      "1271:\tlearn: 0.0015517\ttotal: 37.8s\tremaining: 17.9s\n",
      "1272:\tlearn: 0.0015517\ttotal: 37.8s\tremaining: 17.9s\n",
      "1273:\tlearn: 0.0015517\ttotal: 37.9s\tremaining: 17.9s\n",
      "1274:\tlearn: 0.0015517\ttotal: 37.9s\tremaining: 17.8s\n",
      "1275:\tlearn: 0.0015517\ttotal: 37.9s\tremaining: 17.8s\n",
      "1276:\tlearn: 0.0015517\ttotal: 37.9s\tremaining: 17.8s\n",
      "1277:\tlearn: 0.0015517\ttotal: 38s\tremaining: 17.7s\n",
      "1278:\tlearn: 0.0015517\ttotal: 38s\tremaining: 17.7s\n",
      "1279:\tlearn: 0.0015488\ttotal: 38s\tremaining: 17.7s\n",
      "1280:\tlearn: 0.0015488\ttotal: 38.1s\tremaining: 17.6s\n",
      "1281:\tlearn: 0.0015488\ttotal: 38.1s\tremaining: 17.6s\n",
      "1282:\tlearn: 0.0015488\ttotal: 38.1s\tremaining: 17.6s\n",
      "1283:\tlearn: 0.0015488\ttotal: 38.1s\tremaining: 17.6s\n",
      "1284:\tlearn: 0.0015488\ttotal: 38.2s\tremaining: 17.5s\n",
      "1285:\tlearn: 0.0015488\ttotal: 38.2s\tremaining: 17.5s\n",
      "1286:\tlearn: 0.0015488\ttotal: 38.2s\tremaining: 17.5s\n",
      "1287:\tlearn: 0.0015488\ttotal: 38.3s\tremaining: 17.4s\n",
      "1288:\tlearn: 0.0015488\ttotal: 38.3s\tremaining: 17.4s\n",
      "1289:\tlearn: 0.0015488\ttotal: 38.3s\tremaining: 17.4s\n",
      "1290:\tlearn: 0.0015488\ttotal: 38.3s\tremaining: 17.3s\n",
      "1291:\tlearn: 0.0015488\ttotal: 38.4s\tremaining: 17.3s\n",
      "1292:\tlearn: 0.0015488\ttotal: 38.4s\tremaining: 17.3s\n",
      "1293:\tlearn: 0.0015488\ttotal: 38.4s\tremaining: 17.3s\n",
      "1294:\tlearn: 0.0015488\ttotal: 38.5s\tremaining: 17.2s\n",
      "1295:\tlearn: 0.0015488\ttotal: 38.5s\tremaining: 17.2s\n",
      "1296:\tlearn: 0.0015487\ttotal: 38.5s\tremaining: 17.2s\n",
      "1297:\tlearn: 0.0015487\ttotal: 38.5s\tremaining: 17.1s\n",
      "1298:\tlearn: 0.0015487\ttotal: 38.6s\tremaining: 17.1s\n",
      "1299:\tlearn: 0.0015487\ttotal: 38.6s\tremaining: 17.1s\n",
      "1300:\tlearn: 0.0015453\ttotal: 38.6s\tremaining: 17s\n",
      "1301:\tlearn: 0.0015453\ttotal: 38.7s\tremaining: 17s\n",
      "1302:\tlearn: 0.0015453\ttotal: 38.7s\tremaining: 17s\n",
      "1303:\tlearn: 0.0015452\ttotal: 38.7s\tremaining: 17s\n",
      "1304:\tlearn: 0.0015452\ttotal: 38.8s\tremaining: 16.9s\n",
      "1305:\tlearn: 0.0015433\ttotal: 38.8s\tremaining: 16.9s\n",
      "1306:\tlearn: 0.0015433\ttotal: 38.8s\tremaining: 16.9s\n",
      "1307:\tlearn: 0.0015433\ttotal: 38.8s\tremaining: 16.8s\n",
      "1308:\tlearn: 0.0015433\ttotal: 38.9s\tremaining: 16.8s\n",
      "1309:\tlearn: 0.0015433\ttotal: 38.9s\tremaining: 16.8s\n",
      "1310:\tlearn: 0.0015433\ttotal: 38.9s\tremaining: 16.7s\n",
      "1311:\tlearn: 0.0015433\ttotal: 39s\tremaining: 16.7s\n",
      "1312:\tlearn: 0.0015433\ttotal: 39s\tremaining: 16.7s\n",
      "1313:\tlearn: 0.0015433\ttotal: 39s\tremaining: 16.7s\n",
      "1314:\tlearn: 0.0015421\ttotal: 39s\tremaining: 16.6s\n",
      "1315:\tlearn: 0.0015421\ttotal: 39.1s\tremaining: 16.6s\n",
      "1316:\tlearn: 0.0015421\ttotal: 39.1s\tremaining: 16.6s\n",
      "1317:\tlearn: 0.0015421\ttotal: 39.1s\tremaining: 16.5s\n",
      "1318:\tlearn: 0.0015421\ttotal: 39.2s\tremaining: 16.5s\n",
      "1319:\tlearn: 0.0015421\ttotal: 39.2s\tremaining: 16.5s\n",
      "1320:\tlearn: 0.0015421\ttotal: 39.2s\tremaining: 16.4s\n",
      "1321:\tlearn: 0.0015421\ttotal: 39.3s\tremaining: 16.4s\n",
      "1322:\tlearn: 0.0015421\ttotal: 39.3s\tremaining: 16.4s\n",
      "1323:\tlearn: 0.0015393\ttotal: 39.3s\tremaining: 16.4s\n",
      "1324:\tlearn: 0.0015393\ttotal: 39.3s\tremaining: 16.3s\n",
      "1325:\tlearn: 0.0015392\ttotal: 39.4s\tremaining: 16.3s\n",
      "1326:\tlearn: 0.0015392\ttotal: 39.4s\tremaining: 16.3s\n",
      "1327:\tlearn: 0.0015370\ttotal: 39.4s\tremaining: 16.2s\n",
      "1328:\tlearn: 0.0015370\ttotal: 39.5s\tremaining: 16.2s\n",
      "1329:\tlearn: 0.0015370\ttotal: 39.5s\tremaining: 16.2s\n",
      "1330:\tlearn: 0.0015370\ttotal: 39.5s\tremaining: 16.1s\n",
      "1331:\tlearn: 0.0015370\ttotal: 39.5s\tremaining: 16.1s\n",
      "1332:\tlearn: 0.0015370\ttotal: 39.6s\tremaining: 16.1s\n",
      "1333:\tlearn: 0.0015370\ttotal: 39.6s\tremaining: 16.1s\n",
      "1334:\tlearn: 0.0015370\ttotal: 39.6s\tremaining: 16s\n",
      "1335:\tlearn: 0.0015369\ttotal: 39.7s\tremaining: 16s\n",
      "1336:\tlearn: 0.0015322\ttotal: 39.7s\tremaining: 16s\n",
      "1337:\tlearn: 0.0015322\ttotal: 39.7s\tremaining: 15.9s\n",
      "1338:\tlearn: 0.0015322\ttotal: 39.7s\tremaining: 15.9s\n",
      "1339:\tlearn: 0.0015322\ttotal: 39.8s\tremaining: 15.9s\n",
      "1340:\tlearn: 0.0015322\ttotal: 39.8s\tremaining: 15.9s\n",
      "1341:\tlearn: 0.0015322\ttotal: 39.8s\tremaining: 15.8s\n",
      "1342:\tlearn: 0.0015322\ttotal: 39.9s\tremaining: 15.8s\n",
      "1343:\tlearn: 0.0015322\ttotal: 39.9s\tremaining: 15.8s\n",
      "1344:\tlearn: 0.0015303\ttotal: 39.9s\tremaining: 15.7s\n",
      "1345:\tlearn: 0.0015303\ttotal: 40s\tremaining: 15.7s\n",
      "1346:\tlearn: 0.0015303\ttotal: 40s\tremaining: 15.7s\n",
      "1347:\tlearn: 0.0015298\ttotal: 40s\tremaining: 15.6s\n",
      "1348:\tlearn: 0.0015298\ttotal: 40.1s\tremaining: 15.6s\n",
      "1349:\tlearn: 0.0015298\ttotal: 40.1s\tremaining: 15.6s\n",
      "1350:\tlearn: 0.0015298\ttotal: 40.1s\tremaining: 15.6s\n",
      "1351:\tlearn: 0.0015298\ttotal: 40.1s\tremaining: 15.5s\n",
      "1352:\tlearn: 0.0015298\ttotal: 40.2s\tremaining: 15.5s\n",
      "1353:\tlearn: 0.0015298\ttotal: 40.2s\tremaining: 15.5s\n",
      "1354:\tlearn: 0.0015298\ttotal: 40.2s\tremaining: 15.4s\n",
      "1355:\tlearn: 0.0015268\ttotal: 40.3s\tremaining: 15.4s\n",
      "1356:\tlearn: 0.0015268\ttotal: 40.3s\tremaining: 15.4s\n",
      "1357:\tlearn: 0.0015268\ttotal: 40.3s\tremaining: 15.3s\n",
      "1358:\tlearn: 0.0015268\ttotal: 40.3s\tremaining: 15.3s\n",
      "1359:\tlearn: 0.0015268\ttotal: 40.4s\tremaining: 15.3s\n",
      "1360:\tlearn: 0.0015268\ttotal: 40.4s\tremaining: 15.3s\n",
      "1361:\tlearn: 0.0015268\ttotal: 40.4s\tremaining: 15.2s\n",
      "1362:\tlearn: 0.0015264\ttotal: 40.5s\tremaining: 15.2s\n",
      "1363:\tlearn: 0.0015264\ttotal: 40.5s\tremaining: 15.2s\n",
      "1364:\tlearn: 0.0015264\ttotal: 40.5s\tremaining: 15.1s\n",
      "1365:\tlearn: 0.0015264\ttotal: 40.5s\tremaining: 15.1s\n",
      "1366:\tlearn: 0.0015264\ttotal: 40.6s\tremaining: 15.1s\n",
      "1367:\tlearn: 0.0015264\ttotal: 40.6s\tremaining: 15.1s\n",
      "1368:\tlearn: 0.0015264\ttotal: 40.6s\tremaining: 15s\n",
      "1369:\tlearn: 0.0015264\ttotal: 40.7s\tremaining: 15s\n",
      "1370:\tlearn: 0.0015264\ttotal: 40.7s\tremaining: 15s\n",
      "1371:\tlearn: 0.0015264\ttotal: 40.7s\tremaining: 14.9s\n",
      "1372:\tlearn: 0.0015264\ttotal: 40.8s\tremaining: 14.9s\n",
      "1373:\tlearn: 0.0015264\ttotal: 40.8s\tremaining: 14.9s\n",
      "1374:\tlearn: 0.0015263\ttotal: 40.8s\tremaining: 14.8s\n",
      "1375:\tlearn: 0.0015259\ttotal: 40.8s\tremaining: 14.8s\n",
      "1376:\tlearn: 0.0015259\ttotal: 40.9s\tremaining: 14.8s\n",
      "1377:\tlearn: 0.0015244\ttotal: 40.9s\tremaining: 14.8s\n",
      "1378:\tlearn: 0.0015244\ttotal: 40.9s\tremaining: 14.7s\n",
      "1379:\tlearn: 0.0015244\ttotal: 41s\tremaining: 14.7s\n",
      "1380:\tlearn: 0.0015244\ttotal: 41s\tremaining: 14.7s\n",
      "1381:\tlearn: 0.0015244\ttotal: 41s\tremaining: 14.6s\n",
      "1382:\tlearn: 0.0015244\ttotal: 41.1s\tremaining: 14.6s\n",
      "1383:\tlearn: 0.0015244\ttotal: 41.1s\tremaining: 14.6s\n",
      "1384:\tlearn: 0.0015244\ttotal: 41.1s\tremaining: 14.5s\n",
      "1385:\tlearn: 0.0015244\ttotal: 41.1s\tremaining: 14.5s\n",
      "1386:\tlearn: 0.0015243\ttotal: 41.2s\tremaining: 14.5s\n",
      "1387:\tlearn: 0.0015243\ttotal: 41.2s\tremaining: 14.5s\n",
      "1388:\tlearn: 0.0015243\ttotal: 41.2s\tremaining: 14.4s\n",
      "1389:\tlearn: 0.0015243\ttotal: 41.3s\tremaining: 14.4s\n",
      "1390:\tlearn: 0.0015243\ttotal: 41.3s\tremaining: 14.4s\n",
      "1391:\tlearn: 0.0015243\ttotal: 41.3s\tremaining: 14.3s\n",
      "1392:\tlearn: 0.0015243\ttotal: 41.4s\tremaining: 14.3s\n",
      "1393:\tlearn: 0.0015243\ttotal: 41.4s\tremaining: 14.3s\n",
      "1394:\tlearn: 0.0015243\ttotal: 41.4s\tremaining: 14.2s\n",
      "1395:\tlearn: 0.0015243\ttotal: 41.4s\tremaining: 14.2s\n",
      "1396:\tlearn: 0.0015243\ttotal: 41.5s\tremaining: 14.2s\n",
      "1397:\tlearn: 0.0015243\ttotal: 41.5s\tremaining: 14.2s\n",
      "1398:\tlearn: 0.0015243\ttotal: 41.5s\tremaining: 14.1s\n",
      "1399:\tlearn: 0.0015243\ttotal: 41.6s\tremaining: 14.1s\n",
      "1400:\tlearn: 0.0015222\ttotal: 41.6s\tremaining: 14.1s\n",
      "1401:\tlearn: 0.0015180\ttotal: 41.6s\tremaining: 14s\n",
      "1402:\tlearn: 0.0015180\ttotal: 41.6s\tremaining: 14s\n",
      "1403:\tlearn: 0.0015180\ttotal: 41.7s\tremaining: 14s\n",
      "1404:\tlearn: 0.0015180\ttotal: 41.7s\tremaining: 13.9s\n",
      "1405:\tlearn: 0.0015180\ttotal: 41.7s\tremaining: 13.9s\n",
      "1406:\tlearn: 0.0015180\ttotal: 41.8s\tremaining: 13.9s\n",
      "1407:\tlearn: 0.0015141\ttotal: 41.8s\tremaining: 13.9s\n",
      "1408:\tlearn: 0.0015104\ttotal: 41.8s\tremaining: 13.8s\n",
      "1409:\tlearn: 0.0015104\ttotal: 41.9s\tremaining: 13.8s\n",
      "1410:\tlearn: 0.0015104\ttotal: 41.9s\tremaining: 13.8s\n",
      "1411:\tlearn: 0.0015104\ttotal: 41.9s\tremaining: 13.7s\n",
      "1412:\tlearn: 0.0015101\ttotal: 41.9s\tremaining: 13.7s\n",
      "1413:\tlearn: 0.0015101\ttotal: 42s\tremaining: 13.7s\n",
      "1414:\tlearn: 0.0015101\ttotal: 42s\tremaining: 13.7s\n",
      "1415:\tlearn: 0.0015088\ttotal: 42s\tremaining: 13.6s\n",
      "1416:\tlearn: 0.0015088\ttotal: 42.1s\tremaining: 13.6s\n",
      "1417:\tlearn: 0.0015088\ttotal: 42.1s\tremaining: 13.6s\n",
      "1418:\tlearn: 0.0015088\ttotal: 42.1s\tremaining: 13.5s\n",
      "1419:\tlearn: 0.0015088\ttotal: 42.1s\tremaining: 13.5s\n",
      "1420:\tlearn: 0.0015060\ttotal: 42.2s\tremaining: 13.5s\n",
      "1421:\tlearn: 0.0015023\ttotal: 42.2s\tremaining: 13.4s\n",
      "1422:\tlearn: 0.0015023\ttotal: 42.2s\tremaining: 13.4s\n",
      "1423:\tlearn: 0.0015023\ttotal: 42.3s\tremaining: 13.4s\n",
      "1424:\tlearn: 0.0015023\ttotal: 42.3s\tremaining: 13.4s\n",
      "1425:\tlearn: 0.0015023\ttotal: 42.3s\tremaining: 13.3s\n",
      "1426:\tlearn: 0.0015023\ttotal: 42.3s\tremaining: 13.3s\n",
      "1427:\tlearn: 0.0015023\ttotal: 42.4s\tremaining: 13.3s\n",
      "1428:\tlearn: 0.0015023\ttotal: 42.4s\tremaining: 13.2s\n",
      "1429:\tlearn: 0.0015023\ttotal: 42.4s\tremaining: 13.2s\n",
      "1430:\tlearn: 0.0015023\ttotal: 42.5s\tremaining: 13.2s\n",
      "1431:\tlearn: 0.0015023\ttotal: 42.5s\tremaining: 13.1s\n",
      "1432:\tlearn: 0.0014995\ttotal: 42.5s\tremaining: 13.1s\n",
      "1433:\tlearn: 0.0014995\ttotal: 42.6s\tremaining: 13.1s\n",
      "1434:\tlearn: 0.0014995\ttotal: 42.6s\tremaining: 13.1s\n",
      "1435:\tlearn: 0.0014995\ttotal: 42.6s\tremaining: 13s\n",
      "1436:\tlearn: 0.0014995\ttotal: 42.6s\tremaining: 13s\n",
      "1437:\tlearn: 0.0014995\ttotal: 42.7s\tremaining: 13s\n",
      "1438:\tlearn: 0.0014995\ttotal: 42.7s\tremaining: 12.9s\n",
      "1439:\tlearn: 0.0014995\ttotal: 42.7s\tremaining: 12.9s\n",
      "1440:\tlearn: 0.0014995\ttotal: 42.8s\tremaining: 12.9s\n",
      "1441:\tlearn: 0.0014995\ttotal: 42.8s\tremaining: 12.8s\n",
      "1442:\tlearn: 0.0014995\ttotal: 42.8s\tremaining: 12.8s\n",
      "1443:\tlearn: 0.0014995\ttotal: 42.8s\tremaining: 12.8s\n",
      "1444:\tlearn: 0.0014995\ttotal: 42.9s\tremaining: 12.8s\n",
      "1445:\tlearn: 0.0014995\ttotal: 42.9s\tremaining: 12.7s\n",
      "1446:\tlearn: 0.0014995\ttotal: 42.9s\tremaining: 12.7s\n",
      "1447:\tlearn: 0.0014995\ttotal: 43s\tremaining: 12.7s\n",
      "1448:\tlearn: 0.0014995\ttotal: 43s\tremaining: 12.6s\n",
      "1449:\tlearn: 0.0014958\ttotal: 43s\tremaining: 12.6s\n",
      "1450:\tlearn: 0.0014958\ttotal: 43s\tremaining: 12.6s\n",
      "1451:\tlearn: 0.0014958\ttotal: 43.1s\tremaining: 12.6s\n",
      "1452:\tlearn: 0.0014958\ttotal: 43.1s\tremaining: 12.5s\n",
      "1453:\tlearn: 0.0014958\ttotal: 43.1s\tremaining: 12.5s\n",
      "1454:\tlearn: 0.0014958\ttotal: 43.2s\tremaining: 12.5s\n",
      "1455:\tlearn: 0.0014956\ttotal: 43.2s\tremaining: 12.4s\n",
      "1456:\tlearn: 0.0014956\ttotal: 43.2s\tremaining: 12.4s\n",
      "1457:\tlearn: 0.0014956\ttotal: 43.3s\tremaining: 12.4s\n",
      "1458:\tlearn: 0.0014956\ttotal: 43.3s\tremaining: 12.3s\n",
      "1459:\tlearn: 0.0014956\ttotal: 43.3s\tremaining: 12.3s\n",
      "1460:\tlearn: 0.0014908\ttotal: 43.3s\tremaining: 12.3s\n",
      "1461:\tlearn: 0.0014908\ttotal: 43.4s\tremaining: 12.3s\n",
      "1462:\tlearn: 0.0014908\ttotal: 43.4s\tremaining: 12.2s\n",
      "1463:\tlearn: 0.0014908\ttotal: 43.4s\tremaining: 12.2s\n",
      "1464:\tlearn: 0.0014908\ttotal: 43.5s\tremaining: 12.2s\n",
      "1465:\tlearn: 0.0014908\ttotal: 43.5s\tremaining: 12.1s\n",
      "1466:\tlearn: 0.0014908\ttotal: 43.5s\tremaining: 12.1s\n",
      "1467:\tlearn: 0.0014908\ttotal: 43.5s\tremaining: 12.1s\n",
      "1468:\tlearn: 0.0014908\ttotal: 43.6s\tremaining: 12s\n",
      "1469:\tlearn: 0.0014908\ttotal: 43.6s\tremaining: 12s\n",
      "1470:\tlearn: 0.0014908\ttotal: 43.6s\tremaining: 12s\n",
      "1471:\tlearn: 0.0014908\ttotal: 43.7s\tremaining: 12s\n",
      "1472:\tlearn: 0.0014894\ttotal: 43.7s\tremaining: 11.9s\n",
      "1473:\tlearn: 0.0014894\ttotal: 43.7s\tremaining: 11.9s\n",
      "1474:\tlearn: 0.0014894\ttotal: 43.8s\tremaining: 11.9s\n",
      "1475:\tlearn: 0.0014868\ttotal: 43.8s\tremaining: 11.8s\n",
      "1476:\tlearn: 0.0014842\ttotal: 43.8s\tremaining: 11.8s\n",
      "1477:\tlearn: 0.0014842\ttotal: 43.8s\tremaining: 11.8s\n",
      "1478:\tlearn: 0.0014842\ttotal: 43.9s\tremaining: 11.7s\n",
      "1479:\tlearn: 0.0014842\ttotal: 43.9s\tremaining: 11.7s\n",
      "1480:\tlearn: 0.0014842\ttotal: 43.9s\tremaining: 11.7s\n",
      "1481:\tlearn: 0.0014821\ttotal: 44s\tremaining: 11.7s\n",
      "1482:\tlearn: 0.0014821\ttotal: 44s\tremaining: 11.6s\n",
      "1483:\tlearn: 0.0014821\ttotal: 44s\tremaining: 11.6s\n",
      "1484:\tlearn: 0.0014821\ttotal: 44s\tremaining: 11.6s\n",
      "1485:\tlearn: 0.0014821\ttotal: 44.1s\tremaining: 11.5s\n",
      "1486:\tlearn: 0.0014821\ttotal: 44.1s\tremaining: 11.5s\n",
      "1487:\tlearn: 0.0014788\ttotal: 44.1s\tremaining: 11.5s\n",
      "1488:\tlearn: 0.0014788\ttotal: 44.2s\tremaining: 11.4s\n",
      "1489:\tlearn: 0.0014788\ttotal: 44.2s\tremaining: 11.4s\n",
      "1490:\tlearn: 0.0014788\ttotal: 44.2s\tremaining: 11.4s\n",
      "1491:\tlearn: 0.0014763\ttotal: 44.3s\tremaining: 11.4s\n",
      "1492:\tlearn: 0.0014727\ttotal: 44.3s\tremaining: 11.3s\n",
      "1493:\tlearn: 0.0014727\ttotal: 44.3s\tremaining: 11.3s\n",
      "1494:\tlearn: 0.0014727\ttotal: 44.4s\tremaining: 11.3s\n",
      "1495:\tlearn: 0.0014701\ttotal: 44.4s\tremaining: 11.2s\n",
      "1496:\tlearn: 0.0014688\ttotal: 44.4s\tremaining: 11.2s\n",
      "1497:\tlearn: 0.0014688\ttotal: 44.4s\tremaining: 11.2s\n",
      "1498:\tlearn: 0.0014688\ttotal: 44.5s\tremaining: 11.2s\n",
      "1499:\tlearn: 0.0014688\ttotal: 44.5s\tremaining: 11.1s\n",
      "1500:\tlearn: 0.0014688\ttotal: 44.5s\tremaining: 11.1s\n",
      "1501:\tlearn: 0.0014688\ttotal: 44.6s\tremaining: 11.1s\n",
      "1502:\tlearn: 0.0014688\ttotal: 44.6s\tremaining: 11s\n",
      "1503:\tlearn: 0.0014688\ttotal: 44.6s\tremaining: 11s\n",
      "1504:\tlearn: 0.0014688\ttotal: 44.7s\tremaining: 11s\n",
      "1505:\tlearn: 0.0014688\ttotal: 44.7s\tremaining: 10.9s\n",
      "1506:\tlearn: 0.0014687\ttotal: 44.7s\tremaining: 10.9s\n",
      "1507:\tlearn: 0.0014687\ttotal: 44.7s\tremaining: 10.9s\n",
      "1508:\tlearn: 0.0014687\ttotal: 44.8s\tremaining: 10.9s\n",
      "1509:\tlearn: 0.0014687\ttotal: 44.8s\tremaining: 10.8s\n",
      "1510:\tlearn: 0.0014687\ttotal: 44.8s\tremaining: 10.8s\n",
      "1511:\tlearn: 0.0014687\ttotal: 44.9s\tremaining: 10.8s\n",
      "1512:\tlearn: 0.0014687\ttotal: 44.9s\tremaining: 10.7s\n",
      "1513:\tlearn: 0.0014687\ttotal: 44.9s\tremaining: 10.7s\n",
      "1514:\tlearn: 0.0014687\ttotal: 44.9s\tremaining: 10.7s\n",
      "1515:\tlearn: 0.0014687\ttotal: 45s\tremaining: 10.6s\n",
      "1516:\tlearn: 0.0014687\ttotal: 45s\tremaining: 10.6s\n",
      "1517:\tlearn: 0.0014687\ttotal: 45s\tremaining: 10.6s\n",
      "1518:\tlearn: 0.0014671\ttotal: 45.1s\tremaining: 10.6s\n",
      "1519:\tlearn: 0.0014671\ttotal: 45.1s\tremaining: 10.5s\n",
      "1520:\tlearn: 0.0014637\ttotal: 45.1s\tremaining: 10.5s\n",
      "1521:\tlearn: 0.0014629\ttotal: 45.1s\tremaining: 10.5s\n",
      "1522:\tlearn: 0.0014629\ttotal: 45.2s\tremaining: 10.4s\n",
      "1523:\tlearn: 0.0014629\ttotal: 45.2s\tremaining: 10.4s\n",
      "1524:\tlearn: 0.0014629\ttotal: 45.2s\tremaining: 10.4s\n",
      "1525:\tlearn: 0.0014628\ttotal: 45.3s\tremaining: 10.4s\n",
      "1526:\tlearn: 0.0014628\ttotal: 45.3s\tremaining: 10.3s\n",
      "1527:\tlearn: 0.0014628\ttotal: 45.3s\tremaining: 10.3s\n",
      "1528:\tlearn: 0.0014628\ttotal: 45.4s\tremaining: 10.3s\n",
      "1529:\tlearn: 0.0014628\ttotal: 45.4s\tremaining: 10.2s\n",
      "1530:\tlearn: 0.0014589\ttotal: 45.4s\tremaining: 10.2s\n",
      "1531:\tlearn: 0.0014589\ttotal: 45.4s\tremaining: 10.2s\n",
      "1532:\tlearn: 0.0014589\ttotal: 45.5s\tremaining: 10.1s\n",
      "1533:\tlearn: 0.0014551\ttotal: 45.5s\tremaining: 10.1s\n",
      "1534:\tlearn: 0.0014551\ttotal: 45.5s\tremaining: 10.1s\n",
      "1535:\tlearn: 0.0014551\ttotal: 45.6s\tremaining: 10.1s\n",
      "1536:\tlearn: 0.0014516\ttotal: 45.6s\tremaining: 10s\n",
      "1537:\tlearn: 0.0014516\ttotal: 45.6s\tremaining: 9.99s\n",
      "1538:\tlearn: 0.0014516\ttotal: 45.6s\tremaining: 9.96s\n",
      "1539:\tlearn: 0.0014483\ttotal: 45.7s\tremaining: 9.94s\n",
      "1540:\tlearn: 0.0014483\ttotal: 45.7s\tremaining: 9.9s\n",
      "1541:\tlearn: 0.0014483\ttotal: 45.7s\tremaining: 9.88s\n",
      "1542:\tlearn: 0.0014483\ttotal: 45.8s\tremaining: 9.85s\n",
      "1543:\tlearn: 0.0014483\ttotal: 45.8s\tremaining: 9.82s\n",
      "1544:\tlearn: 0.0014483\ttotal: 45.8s\tremaining: 9.79s\n",
      "1545:\tlearn: 0.0014483\ttotal: 45.8s\tremaining: 9.76s\n",
      "1546:\tlearn: 0.0014463\ttotal: 45.9s\tremaining: 9.73s\n",
      "1547:\tlearn: 0.0014463\ttotal: 45.9s\tremaining: 9.7s\n",
      "1548:\tlearn: 0.0014463\ttotal: 45.9s\tremaining: 9.67s\n",
      "1549:\tlearn: 0.0014463\ttotal: 46s\tremaining: 9.64s\n",
      "1550:\tlearn: 0.0014463\ttotal: 46s\tremaining: 9.61s\n",
      "1551:\tlearn: 0.0014463\ttotal: 46s\tremaining: 9.58s\n",
      "1552:\tlearn: 0.0014449\ttotal: 46s\tremaining: 9.55s\n",
      "1553:\tlearn: 0.0014449\ttotal: 46.1s\tremaining: 9.52s\n",
      "1554:\tlearn: 0.0014448\ttotal: 46.1s\tremaining: 9.49s\n",
      "1555:\tlearn: 0.0014448\ttotal: 46.1s\tremaining: 9.46s\n",
      "1556:\tlearn: 0.0014448\ttotal: 46.2s\tremaining: 9.43s\n",
      "1557:\tlearn: 0.0014448\ttotal: 46.2s\tremaining: 9.4s\n",
      "1558:\tlearn: 0.0014448\ttotal: 46.2s\tremaining: 9.37s\n",
      "1559:\tlearn: 0.0014448\ttotal: 46.3s\tremaining: 9.34s\n",
      "1560:\tlearn: 0.0014448\ttotal: 46.3s\tremaining: 9.31s\n",
      "1561:\tlearn: 0.0014448\ttotal: 46.3s\tremaining: 9.28s\n",
      "1562:\tlearn: 0.0014448\ttotal: 46.3s\tremaining: 9.25s\n",
      "1563:\tlearn: 0.0014447\ttotal: 46.4s\tremaining: 9.22s\n",
      "1564:\tlearn: 0.0014447\ttotal: 46.4s\tremaining: 9.19s\n",
      "1565:\tlearn: 0.0014447\ttotal: 46.4s\tremaining: 9.16s\n",
      "1566:\tlearn: 0.0014447\ttotal: 46.5s\tremaining: 9.13s\n",
      "1567:\tlearn: 0.0014427\ttotal: 46.5s\tremaining: 9.1s\n",
      "1568:\tlearn: 0.0014427\ttotal: 46.5s\tremaining: 9.07s\n",
      "1569:\tlearn: 0.0014427\ttotal: 46.5s\tremaining: 9.04s\n",
      "1570:\tlearn: 0.0014426\ttotal: 46.6s\tremaining: 9.01s\n",
      "1571:\tlearn: 0.0014426\ttotal: 46.6s\tremaining: 8.98s\n",
      "1572:\tlearn: 0.0014426\ttotal: 46.6s\tremaining: 8.95s\n",
      "1573:\tlearn: 0.0014378\ttotal: 46.7s\tremaining: 8.92s\n",
      "1574:\tlearn: 0.0014378\ttotal: 46.7s\tremaining: 8.89s\n",
      "1575:\tlearn: 0.0014378\ttotal: 46.7s\tremaining: 8.86s\n",
      "1576:\tlearn: 0.0014378\ttotal: 46.8s\tremaining: 8.83s\n",
      "1577:\tlearn: 0.0014378\ttotal: 46.8s\tremaining: 8.8s\n",
      "1578:\tlearn: 0.0014378\ttotal: 46.8s\tremaining: 8.78s\n",
      "1579:\tlearn: 0.0014374\ttotal: 46.8s\tremaining: 8.74s\n",
      "1580:\tlearn: 0.0014374\ttotal: 46.9s\tremaining: 8.71s\n",
      "1581:\tlearn: 0.0014374\ttotal: 46.9s\tremaining: 8.69s\n",
      "1582:\tlearn: 0.0014373\ttotal: 46.9s\tremaining: 8.66s\n",
      "1583:\tlearn: 0.0014373\ttotal: 47s\tremaining: 8.63s\n",
      "1584:\tlearn: 0.0014357\ttotal: 47s\tremaining: 8.6s\n",
      "1585:\tlearn: 0.0014357\ttotal: 47s\tremaining: 8.57s\n",
      "1586:\tlearn: 0.0014357\ttotal: 47s\tremaining: 8.54s\n",
      "1587:\tlearn: 0.0014357\ttotal: 47.1s\tremaining: 8.51s\n",
      "1588:\tlearn: 0.0014357\ttotal: 47.1s\tremaining: 8.48s\n",
      "1589:\tlearn: 0.0014357\ttotal: 47.1s\tremaining: 8.45s\n",
      "1590:\tlearn: 0.0014357\ttotal: 47.2s\tremaining: 8.42s\n",
      "1591:\tlearn: 0.0014357\ttotal: 47.2s\tremaining: 8.39s\n",
      "1592:\tlearn: 0.0014357\ttotal: 47.2s\tremaining: 8.36s\n",
      "1593:\tlearn: 0.0014357\ttotal: 47.2s\tremaining: 8.33s\n",
      "1594:\tlearn: 0.0014357\ttotal: 47.3s\tremaining: 8.3s\n",
      "1595:\tlearn: 0.0014357\ttotal: 47.3s\tremaining: 8.27s\n",
      "1596:\tlearn: 0.0014357\ttotal: 47.3s\tremaining: 8.24s\n",
      "1597:\tlearn: 0.0014356\ttotal: 47.4s\tremaining: 8.21s\n",
      "1598:\tlearn: 0.0014356\ttotal: 47.4s\tremaining: 8.18s\n",
      "1599:\tlearn: 0.0014356\ttotal: 47.4s\tremaining: 8.15s\n",
      "1600:\tlearn: 0.0014356\ttotal: 47.5s\tremaining: 8.12s\n",
      "1601:\tlearn: 0.0014356\ttotal: 47.5s\tremaining: 8.09s\n",
      "1602:\tlearn: 0.0014341\ttotal: 47.5s\tremaining: 8.06s\n",
      "1603:\tlearn: 0.0014341\ttotal: 47.5s\tremaining: 8.03s\n",
      "1604:\tlearn: 0.0014341\ttotal: 47.6s\tremaining: 8s\n",
      "1605:\tlearn: 0.0014341\ttotal: 47.6s\tremaining: 7.97s\n",
      "1606:\tlearn: 0.0014341\ttotal: 47.6s\tremaining: 7.94s\n",
      "1607:\tlearn: 0.0014341\ttotal: 47.7s\tremaining: 7.91s\n",
      "1608:\tlearn: 0.0014341\ttotal: 47.7s\tremaining: 7.88s\n",
      "1609:\tlearn: 0.0014341\ttotal: 47.7s\tremaining: 7.85s\n",
      "1610:\tlearn: 0.0014341\ttotal: 47.7s\tremaining: 7.82s\n",
      "1611:\tlearn: 0.0014341\ttotal: 47.8s\tremaining: 7.79s\n",
      "1612:\tlearn: 0.0014341\ttotal: 47.8s\tremaining: 7.76s\n",
      "1613:\tlearn: 0.0014341\ttotal: 47.8s\tremaining: 7.74s\n",
      "1614:\tlearn: 0.0014341\ttotal: 47.9s\tremaining: 7.71s\n",
      "1615:\tlearn: 0.0014341\ttotal: 47.9s\tremaining: 7.68s\n",
      "1616:\tlearn: 0.0014341\ttotal: 47.9s\tremaining: 7.65s\n",
      "1617:\tlearn: 0.0014341\ttotal: 48s\tremaining: 7.62s\n",
      "1618:\tlearn: 0.0014341\ttotal: 48s\tremaining: 7.59s\n",
      "1619:\tlearn: 0.0014341\ttotal: 48s\tremaining: 7.56s\n",
      "1620:\tlearn: 0.0014307\ttotal: 48s\tremaining: 7.53s\n",
      "1621:\tlearn: 0.0014307\ttotal: 48.1s\tremaining: 7.5s\n",
      "1622:\tlearn: 0.0014303\ttotal: 48.1s\tremaining: 7.47s\n",
      "1623:\tlearn: 0.0014293\ttotal: 48.1s\tremaining: 7.44s\n",
      "1624:\tlearn: 0.0014293\ttotal: 48.2s\tremaining: 7.41s\n",
      "1625:\tlearn: 0.0014293\ttotal: 48.2s\tremaining: 7.38s\n",
      "1626:\tlearn: 0.0014263\ttotal: 48.2s\tremaining: 7.35s\n",
      "1627:\tlearn: 0.0014263\ttotal: 48.2s\tremaining: 7.32s\n",
      "1628:\tlearn: 0.0014263\ttotal: 48.3s\tremaining: 7.29s\n",
      "1629:\tlearn: 0.0014263\ttotal: 48.3s\tremaining: 7.26s\n",
      "1630:\tlearn: 0.0014263\ttotal: 48.3s\tremaining: 7.23s\n",
      "1631:\tlearn: 0.0014263\ttotal: 48.4s\tremaining: 7.2s\n",
      "1632:\tlearn: 0.0014263\ttotal: 48.4s\tremaining: 7.17s\n",
      "1633:\tlearn: 0.0014263\ttotal: 48.4s\tremaining: 7.14s\n",
      "1634:\tlearn: 0.0014263\ttotal: 48.5s\tremaining: 7.11s\n",
      "1635:\tlearn: 0.0014263\ttotal: 48.5s\tremaining: 7.08s\n",
      "1636:\tlearn: 0.0014263\ttotal: 48.5s\tremaining: 7.05s\n",
      "1637:\tlearn: 0.0014263\ttotal: 48.5s\tremaining: 7.02s\n",
      "1638:\tlearn: 0.0014263\ttotal: 48.6s\tremaining: 6.99s\n",
      "1639:\tlearn: 0.0014263\ttotal: 48.6s\tremaining: 6.96s\n",
      "1640:\tlearn: 0.0014263\ttotal: 48.6s\tremaining: 6.93s\n",
      "1641:\tlearn: 0.0014263\ttotal: 48.7s\tremaining: 6.9s\n",
      "1642:\tlearn: 0.0014262\ttotal: 48.7s\tremaining: 6.87s\n",
      "1643:\tlearn: 0.0014262\ttotal: 48.7s\tremaining: 6.84s\n",
      "1644:\tlearn: 0.0014262\ttotal: 48.7s\tremaining: 6.82s\n",
      "1645:\tlearn: 0.0014262\ttotal: 48.8s\tremaining: 6.79s\n",
      "1646:\tlearn: 0.0014262\ttotal: 48.8s\tremaining: 6.76s\n",
      "1647:\tlearn: 0.0014262\ttotal: 48.8s\tremaining: 6.73s\n",
      "1648:\tlearn: 0.0014262\ttotal: 48.9s\tremaining: 6.7s\n",
      "1649:\tlearn: 0.0014262\ttotal: 48.9s\tremaining: 6.67s\n",
      "1650:\tlearn: 0.0014262\ttotal: 48.9s\tremaining: 6.64s\n",
      "1651:\tlearn: 0.0014250\ttotal: 49s\tremaining: 6.61s\n",
      "1652:\tlearn: 0.0014250\ttotal: 49s\tremaining: 6.58s\n",
      "1653:\tlearn: 0.0014249\ttotal: 49s\tremaining: 6.55s\n",
      "1654:\tlearn: 0.0014235\ttotal: 49s\tremaining: 6.52s\n",
      "1655:\tlearn: 0.0014235\ttotal: 49.1s\tremaining: 6.49s\n",
      "1656:\tlearn: 0.0014222\ttotal: 49.1s\tremaining: 6.46s\n",
      "1657:\tlearn: 0.0014222\ttotal: 49.1s\tremaining: 6.43s\n",
      "1658:\tlearn: 0.0014222\ttotal: 49.2s\tremaining: 6.4s\n",
      "1659:\tlearn: 0.0014222\ttotal: 49.2s\tremaining: 6.37s\n",
      "1660:\tlearn: 0.0014222\ttotal: 49.2s\tremaining: 6.34s\n",
      "1661:\tlearn: 0.0014222\ttotal: 49.2s\tremaining: 6.31s\n",
      "1662:\tlearn: 0.0014222\ttotal: 49.3s\tremaining: 6.28s\n",
      "1663:\tlearn: 0.0014222\ttotal: 49.3s\tremaining: 6.25s\n",
      "1664:\tlearn: 0.0014207\ttotal: 49.3s\tremaining: 6.22s\n",
      "1665:\tlearn: 0.0014177\ttotal: 49.4s\tremaining: 6.19s\n",
      "1666:\tlearn: 0.0014177\ttotal: 49.4s\tremaining: 6.16s\n",
      "1667:\tlearn: 0.0014177\ttotal: 49.4s\tremaining: 6.13s\n",
      "1668:\tlearn: 0.0014177\ttotal: 49.5s\tremaining: 6.11s\n",
      "1669:\tlearn: 0.0014177\ttotal: 49.5s\tremaining: 6.08s\n",
      "1670:\tlearn: 0.0014177\ttotal: 49.5s\tremaining: 6.04s\n",
      "1671:\tlearn: 0.0014173\ttotal: 49.6s\tremaining: 6.02s\n",
      "1672:\tlearn: 0.0014173\ttotal: 49.6s\tremaining: 5.99s\n",
      "1673:\tlearn: 0.0014172\ttotal: 49.6s\tremaining: 5.96s\n",
      "1674:\tlearn: 0.0014166\ttotal: 49.6s\tremaining: 5.93s\n",
      "1675:\tlearn: 0.0014166\ttotal: 49.7s\tremaining: 5.9s\n",
      "1676:\tlearn: 0.0014166\ttotal: 49.7s\tremaining: 5.87s\n",
      "1677:\tlearn: 0.0014166\ttotal: 49.7s\tremaining: 5.84s\n",
      "1678:\tlearn: 0.0014166\ttotal: 49.8s\tremaining: 5.81s\n",
      "1679:\tlearn: 0.0014166\ttotal: 49.8s\tremaining: 5.78s\n",
      "1680:\tlearn: 0.0014166\ttotal: 49.8s\tremaining: 5.75s\n",
      "1681:\tlearn: 0.0014166\ttotal: 49.8s\tremaining: 5.72s\n",
      "1682:\tlearn: 0.0014165\ttotal: 49.9s\tremaining: 5.69s\n",
      "1683:\tlearn: 0.0014165\ttotal: 49.9s\tremaining: 5.66s\n",
      "1684:\tlearn: 0.0014165\ttotal: 49.9s\tremaining: 5.63s\n",
      "1685:\tlearn: 0.0014165\ttotal: 50s\tremaining: 5.6s\n",
      "1686:\tlearn: 0.0014165\ttotal: 50s\tremaining: 5.57s\n",
      "1687:\tlearn: 0.0014165\ttotal: 50s\tremaining: 5.54s\n",
      "1688:\tlearn: 0.0014165\ttotal: 50s\tremaining: 5.51s\n",
      "1689:\tlearn: 0.0014165\ttotal: 50.1s\tremaining: 5.48s\n",
      "1690:\tlearn: 0.0014165\ttotal: 50.1s\tremaining: 5.45s\n",
      "1691:\tlearn: 0.0014165\ttotal: 50.1s\tremaining: 5.42s\n",
      "1692:\tlearn: 0.0014165\ttotal: 50.2s\tremaining: 5.39s\n",
      "1693:\tlearn: 0.0014165\ttotal: 50.2s\tremaining: 5.36s\n",
      "1694:\tlearn: 0.0014164\ttotal: 50.2s\tremaining: 5.33s\n",
      "1695:\tlearn: 0.0014164\ttotal: 50.3s\tremaining: 5.3s\n",
      "1696:\tlearn: 0.0014164\ttotal: 50.3s\tremaining: 5.27s\n",
      "1697:\tlearn: 0.0014164\ttotal: 50.3s\tremaining: 5.24s\n",
      "1698:\tlearn: 0.0014164\ttotal: 50.3s\tremaining: 5.21s\n",
      "1699:\tlearn: 0.0014164\ttotal: 50.4s\tremaining: 5.18s\n",
      "1700:\tlearn: 0.0014164\ttotal: 50.4s\tremaining: 5.16s\n",
      "1701:\tlearn: 0.0014162\ttotal: 50.4s\tremaining: 5.13s\n",
      "1702:\tlearn: 0.0014141\ttotal: 50.5s\tremaining: 5.1s\n",
      "1703:\tlearn: 0.0014140\ttotal: 50.5s\tremaining: 5.07s\n",
      "1704:\tlearn: 0.0014140\ttotal: 50.5s\tremaining: 5.04s\n",
      "1705:\tlearn: 0.0014140\ttotal: 50.5s\tremaining: 5.01s\n",
      "1706:\tlearn: 0.0014140\ttotal: 50.6s\tremaining: 4.98s\n",
      "1707:\tlearn: 0.0014140\ttotal: 50.6s\tremaining: 4.95s\n",
      "1708:\tlearn: 0.0014140\ttotal: 50.6s\tremaining: 4.92s\n",
      "1709:\tlearn: 0.0014140\ttotal: 50.7s\tremaining: 4.89s\n",
      "1710:\tlearn: 0.0014140\ttotal: 50.7s\tremaining: 4.86s\n",
      "1711:\tlearn: 0.0014133\ttotal: 50.7s\tremaining: 4.83s\n",
      "1712:\tlearn: 0.0014133\ttotal: 50.8s\tremaining: 4.8s\n",
      "1713:\tlearn: 0.0014122\ttotal: 50.8s\tremaining: 4.77s\n",
      "1714:\tlearn: 0.0014122\ttotal: 50.8s\tremaining: 4.74s\n",
      "1715:\tlearn: 0.0014122\ttotal: 50.8s\tremaining: 4.71s\n",
      "1716:\tlearn: 0.0014122\ttotal: 50.9s\tremaining: 4.68s\n",
      "1717:\tlearn: 0.0014122\ttotal: 50.9s\tremaining: 4.65s\n",
      "1718:\tlearn: 0.0014122\ttotal: 50.9s\tremaining: 4.62s\n",
      "1719:\tlearn: 0.0014122\ttotal: 51s\tremaining: 4.59s\n",
      "1720:\tlearn: 0.0014122\ttotal: 51s\tremaining: 4.56s\n",
      "1721:\tlearn: 0.0014121\ttotal: 51s\tremaining: 4.53s\n",
      "1722:\tlearn: 0.0014121\ttotal: 51.1s\tremaining: 4.5s\n",
      "1723:\tlearn: 0.0014121\ttotal: 51.1s\tremaining: 4.47s\n",
      "1724:\tlearn: 0.0014121\ttotal: 51.1s\tremaining: 4.45s\n",
      "1725:\tlearn: 0.0014121\ttotal: 51.2s\tremaining: 4.42s\n",
      "1726:\tlearn: 0.0014121\ttotal: 51.2s\tremaining: 4.39s\n",
      "1727:\tlearn: 0.0014121\ttotal: 51.2s\tremaining: 4.36s\n",
      "1728:\tlearn: 0.0014121\ttotal: 51.2s\tremaining: 4.33s\n",
      "1729:\tlearn: 0.0014121\ttotal: 51.3s\tremaining: 4.3s\n",
      "1730:\tlearn: 0.0014121\ttotal: 51.3s\tremaining: 4.27s\n",
      "1731:\tlearn: 0.0014121\ttotal: 51.3s\tremaining: 4.24s\n",
      "1732:\tlearn: 0.0014121\ttotal: 51.4s\tremaining: 4.21s\n",
      "1733:\tlearn: 0.0014120\ttotal: 51.4s\tremaining: 4.18s\n",
      "1734:\tlearn: 0.0014120\ttotal: 51.4s\tremaining: 4.15s\n",
      "1735:\tlearn: 0.0014120\ttotal: 51.5s\tremaining: 4.12s\n",
      "1736:\tlearn: 0.0014120\ttotal: 51.5s\tremaining: 4.09s\n",
      "1737:\tlearn: 0.0014120\ttotal: 51.5s\tremaining: 4.06s\n",
      "1738:\tlearn: 0.0014120\ttotal: 51.5s\tremaining: 4.03s\n",
      "1739:\tlearn: 0.0014120\ttotal: 51.6s\tremaining: 4s\n",
      "1740:\tlearn: 0.0014120\ttotal: 51.6s\tremaining: 3.97s\n",
      "1741:\tlearn: 0.0014120\ttotal: 51.6s\tremaining: 3.94s\n",
      "1742:\tlearn: 0.0014120\ttotal: 51.7s\tremaining: 3.91s\n",
      "1743:\tlearn: 0.0014097\ttotal: 51.7s\tremaining: 3.88s\n",
      "1744:\tlearn: 0.0014088\ttotal: 51.7s\tremaining: 3.85s\n",
      "1745:\tlearn: 0.0014088\ttotal: 51.7s\tremaining: 3.82s\n",
      "1746:\tlearn: 0.0014051\ttotal: 51.8s\tremaining: 3.79s\n",
      "1747:\tlearn: 0.0014033\ttotal: 51.8s\tremaining: 3.76s\n",
      "1748:\tlearn: 0.0014033\ttotal: 51.8s\tremaining: 3.73s\n",
      "1749:\tlearn: 0.0014033\ttotal: 51.9s\tremaining: 3.7s\n",
      "1750:\tlearn: 0.0014033\ttotal: 51.9s\tremaining: 3.67s\n",
      "1751:\tlearn: 0.0014019\ttotal: 51.9s\tremaining: 3.65s\n",
      "1752:\tlearn: 0.0014002\ttotal: 52s\tremaining: 3.62s\n",
      "1753:\tlearn: 0.0014002\ttotal: 52s\tremaining: 3.59s\n",
      "1754:\tlearn: 0.0014002\ttotal: 52s\tremaining: 3.56s\n",
      "1755:\tlearn: 0.0014002\ttotal: 52.1s\tremaining: 3.53s\n",
      "1756:\tlearn: 0.0014002\ttotal: 52.1s\tremaining: 3.5s\n",
      "1757:\tlearn: 0.0014002\ttotal: 52.1s\tremaining: 3.47s\n",
      "1758:\tlearn: 0.0014002\ttotal: 52.2s\tremaining: 3.44s\n",
      "1759:\tlearn: 0.0014001\ttotal: 52.2s\tremaining: 3.41s\n",
      "1760:\tlearn: 0.0014001\ttotal: 52.2s\tremaining: 3.38s\n",
      "1761:\tlearn: 0.0014001\ttotal: 52.2s\tremaining: 3.35s\n",
      "1762:\tlearn: 0.0014001\ttotal: 52.3s\tremaining: 3.32s\n",
      "1763:\tlearn: 0.0014001\ttotal: 52.3s\tremaining: 3.29s\n",
      "1764:\tlearn: 0.0014001\ttotal: 52.3s\tremaining: 3.26s\n",
      "1765:\tlearn: 0.0014000\ttotal: 52.4s\tremaining: 3.23s\n",
      "1766:\tlearn: 0.0014000\ttotal: 52.4s\tremaining: 3.2s\n",
      "1767:\tlearn: 0.0014000\ttotal: 52.4s\tremaining: 3.17s\n",
      "1768:\tlearn: 0.0014000\ttotal: 52.5s\tremaining: 3.14s\n",
      "1769:\tlearn: 0.0014000\ttotal: 52.5s\tremaining: 3.11s\n",
      "1770:\tlearn: 0.0014000\ttotal: 52.5s\tremaining: 3.08s\n",
      "1771:\tlearn: 0.0014000\ttotal: 52.5s\tremaining: 3.05s\n",
      "1772:\tlearn: 0.0014000\ttotal: 52.6s\tremaining: 3.02s\n",
      "1773:\tlearn: 0.0014000\ttotal: 52.6s\tremaining: 2.99s\n",
      "1774:\tlearn: 0.0014000\ttotal: 52.6s\tremaining: 2.96s\n",
      "1775:\tlearn: 0.0014000\ttotal: 52.7s\tremaining: 2.94s\n",
      "1776:\tlearn: 0.0014000\ttotal: 52.7s\tremaining: 2.9s\n",
      "1777:\tlearn: 0.0014000\ttotal: 52.7s\tremaining: 2.88s\n",
      "1778:\tlearn: 0.0014000\ttotal: 52.8s\tremaining: 2.85s\n",
      "1779:\tlearn: 0.0014000\ttotal: 52.8s\tremaining: 2.82s\n",
      "1780:\tlearn: 0.0014000\ttotal: 52.8s\tremaining: 2.79s\n",
      "1781:\tlearn: 0.0014000\ttotal: 52.8s\tremaining: 2.76s\n",
      "1782:\tlearn: 0.0014000\ttotal: 52.9s\tremaining: 2.73s\n",
      "1783:\tlearn: 0.0014000\ttotal: 52.9s\tremaining: 2.7s\n",
      "1784:\tlearn: 0.0014000\ttotal: 52.9s\tremaining: 2.67s\n",
      "1785:\tlearn: 0.0014000\ttotal: 53s\tremaining: 2.64s\n",
      "1786:\tlearn: 0.0014000\ttotal: 53s\tremaining: 2.61s\n",
      "1787:\tlearn: 0.0014000\ttotal: 53s\tremaining: 2.58s\n",
      "1788:\tlearn: 0.0014000\ttotal: 53s\tremaining: 2.55s\n",
      "1789:\tlearn: 0.0014000\ttotal: 53.1s\tremaining: 2.52s\n",
      "1790:\tlearn: 0.0014000\ttotal: 53.1s\tremaining: 2.49s\n",
      "1791:\tlearn: 0.0014000\ttotal: 53.1s\tremaining: 2.46s\n",
      "1792:\tlearn: 0.0014000\ttotal: 53.2s\tremaining: 2.43s\n",
      "1793:\tlearn: 0.0014000\ttotal: 53.2s\tremaining: 2.4s\n",
      "1794:\tlearn: 0.0014000\ttotal: 53.2s\tremaining: 2.37s\n",
      "1795:\tlearn: 0.0013999\ttotal: 53.3s\tremaining: 2.34s\n",
      "1796:\tlearn: 0.0013990\ttotal: 53.3s\tremaining: 2.31s\n",
      "1797:\tlearn: 0.0013990\ttotal: 53.3s\tremaining: 2.28s\n",
      "1798:\tlearn: 0.0013989\ttotal: 53.3s\tremaining: 2.25s\n",
      "1799:\tlearn: 0.0013989\ttotal: 53.4s\tremaining: 2.22s\n",
      "1800:\tlearn: 0.0013968\ttotal: 53.4s\tremaining: 2.19s\n",
      "1801:\tlearn: 0.0013968\ttotal: 53.4s\tremaining: 2.16s\n",
      "1802:\tlearn: 0.0013968\ttotal: 53.5s\tremaining: 2.13s\n",
      "1803:\tlearn: 0.0013967\ttotal: 53.5s\tremaining: 2.1s\n",
      "1804:\tlearn: 0.0013967\ttotal: 53.5s\tremaining: 2.08s\n",
      "1805:\tlearn: 0.0013967\ttotal: 53.5s\tremaining: 2.04s\n",
      "1806:\tlearn: 0.0013967\ttotal: 53.6s\tremaining: 2.02s\n",
      "1807:\tlearn: 0.0013967\ttotal: 53.6s\tremaining: 1.99s\n",
      "1808:\tlearn: 0.0013967\ttotal: 53.6s\tremaining: 1.96s\n",
      "1809:\tlearn: 0.0013967\ttotal: 53.7s\tremaining: 1.93s\n",
      "1810:\tlearn: 0.0013967\ttotal: 53.7s\tremaining: 1.9s\n",
      "1811:\tlearn: 0.0013967\ttotal: 53.7s\tremaining: 1.87s\n",
      "1812:\tlearn: 0.0013967\ttotal: 53.7s\tremaining: 1.84s\n",
      "1813:\tlearn: 0.0013967\ttotal: 53.8s\tremaining: 1.81s\n",
      "1814:\tlearn: 0.0013967\ttotal: 53.8s\tremaining: 1.78s\n",
      "1815:\tlearn: 0.0013967\ttotal: 53.8s\tremaining: 1.75s\n",
      "1816:\tlearn: 0.0013967\ttotal: 53.9s\tremaining: 1.72s\n",
      "1817:\tlearn: 0.0013967\ttotal: 53.9s\tremaining: 1.69s\n",
      "1818:\tlearn: 0.0013967\ttotal: 53.9s\tremaining: 1.66s\n",
      "1819:\tlearn: 0.0013967\ttotal: 54s\tremaining: 1.63s\n",
      "1820:\tlearn: 0.0013967\ttotal: 54s\tremaining: 1.6s\n",
      "1821:\tlearn: 0.0013967\ttotal: 54s\tremaining: 1.57s\n",
      "1822:\tlearn: 0.0013967\ttotal: 54s\tremaining: 1.54s\n",
      "1823:\tlearn: 0.0013967\ttotal: 54.1s\tremaining: 1.51s\n",
      "1824:\tlearn: 0.0013967\ttotal: 54.1s\tremaining: 1.48s\n",
      "1825:\tlearn: 0.0013967\ttotal: 54.1s\tremaining: 1.45s\n",
      "1826:\tlearn: 0.0013966\ttotal: 54.2s\tremaining: 1.42s\n",
      "1827:\tlearn: 0.0013966\ttotal: 54.2s\tremaining: 1.39s\n",
      "1828:\tlearn: 0.0013966\ttotal: 54.2s\tremaining: 1.36s\n",
      "1829:\tlearn: 0.0013966\ttotal: 54.2s\tremaining: 1.33s\n",
      "1830:\tlearn: 0.0013966\ttotal: 54.3s\tremaining: 1.3s\n",
      "1831:\tlearn: 0.0013966\ttotal: 54.3s\tremaining: 1.27s\n",
      "1832:\tlearn: 0.0013966\ttotal: 54.3s\tremaining: 1.25s\n",
      "1833:\tlearn: 0.0013966\ttotal: 54.4s\tremaining: 1.22s\n",
      "1834:\tlearn: 0.0013966\ttotal: 54.4s\tremaining: 1.19s\n",
      "1835:\tlearn: 0.0013966\ttotal: 54.4s\tremaining: 1.16s\n",
      "1836:\tlearn: 0.0013965\ttotal: 54.5s\tremaining: 1.13s\n",
      "1837:\tlearn: 0.0013965\ttotal: 54.5s\tremaining: 1.1s\n",
      "1838:\tlearn: 0.0013965\ttotal: 54.5s\tremaining: 1.07s\n",
      "1839:\tlearn: 0.0013965\ttotal: 54.5s\tremaining: 1.04s\n",
      "1840:\tlearn: 0.0013965\ttotal: 54.6s\tremaining: 1.01s\n",
      "1841:\tlearn: 0.0013965\ttotal: 54.6s\tremaining: 978ms\n",
      "1842:\tlearn: 0.0013965\ttotal: 54.6s\tremaining: 949ms\n",
      "1843:\tlearn: 0.0013965\ttotal: 54.7s\tremaining: 919ms\n",
      "1844:\tlearn: 0.0013965\ttotal: 54.7s\tremaining: 889ms\n",
      "1845:\tlearn: 0.0013965\ttotal: 54.7s\tremaining: 860ms\n",
      "1846:\tlearn: 0.0013965\ttotal: 54.7s\tremaining: 830ms\n",
      "1847:\tlearn: 0.0013965\ttotal: 54.8s\tremaining: 800ms\n",
      "1848:\tlearn: 0.0013965\ttotal: 54.8s\tremaining: 771ms\n",
      "1849:\tlearn: 0.0013965\ttotal: 54.8s\tremaining: 741ms\n",
      "1850:\tlearn: 0.0013965\ttotal: 54.9s\tremaining: 711ms\n",
      "1851:\tlearn: 0.0013965\ttotal: 54.9s\tremaining: 682ms\n",
      "1852:\tlearn: 0.0013965\ttotal: 54.9s\tremaining: 652ms\n",
      "1853:\tlearn: 0.0013965\ttotal: 55s\tremaining: 623ms\n",
      "1854:\tlearn: 0.0013964\ttotal: 55s\tremaining: 593ms\n",
      "1855:\tlearn: 0.0013964\ttotal: 55s\tremaining: 563ms\n",
      "1856:\tlearn: 0.0013964\ttotal: 55.1s\tremaining: 534ms\n",
      "1857:\tlearn: 0.0013964\ttotal: 55.1s\tremaining: 504ms\n",
      "1858:\tlearn: 0.0013964\ttotal: 55.1s\tremaining: 474ms\n",
      "1859:\tlearn: 0.0013964\ttotal: 55.1s\tremaining: 445ms\n",
      "1860:\tlearn: 0.0013964\ttotal: 55.2s\tremaining: 415ms\n",
      "1861:\tlearn: 0.0013964\ttotal: 55.2s\tremaining: 385ms\n",
      "1862:\tlearn: 0.0013955\ttotal: 55.2s\tremaining: 356ms\n",
      "1863:\tlearn: 0.0013955\ttotal: 55.3s\tremaining: 326ms\n",
      "1864:\tlearn: 0.0013955\ttotal: 55.3s\tremaining: 296ms\n",
      "1865:\tlearn: 0.0013955\ttotal: 55.3s\tremaining: 267ms\n",
      "1866:\tlearn: 0.0013955\ttotal: 55.4s\tremaining: 237ms\n",
      "1867:\tlearn: 0.0013955\ttotal: 55.4s\tremaining: 208ms\n",
      "1868:\tlearn: 0.0013955\ttotal: 55.4s\tremaining: 178ms\n",
      "1869:\tlearn: 0.0013955\ttotal: 55.5s\tremaining: 148ms\n",
      "1870:\tlearn: 0.0013955\ttotal: 55.5s\tremaining: 119ms\n",
      "1871:\tlearn: 0.0013955\ttotal: 55.6s\tremaining: 89.1ms\n",
      "1872:\tlearn: 0.0013954\ttotal: 55.6s\tremaining: 59.4ms\n",
      "1873:\tlearn: 0.0013954\ttotal: 55.6s\tremaining: 29.7ms\n",
      "1874:\tlearn: 0.0013954\ttotal: 55.7s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1f1f8c17a50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cb.fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfab900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cb.save_model('catboost_best.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cb = time.perf_counter()\n",
    "pred_cb = model_cb.predict(X_test)\n",
    "end_cb = time.perf_counter()\n",
    "pred_proba_cb=model_cb.predict_proba(X_test)\n",
    "precision_cb = np.round(precision_score(y_test,pred_cb),4)\n",
    "recall_cb = np.round(recall_score(y_test,pred_cb),4)\n",
    "f1_cb = np.round(f1_score(y_test,pred_cb),4)\n",
    "roc_auc_cb = np.round(roc_auc_score(y_test,pred_proba_cb[:,1]),4)\n",
    "time_inference_ms_cb = round((end_cb-start_cb)/X_test.shape[0] * 1000,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f8f4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>time_inferense(ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.0114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Precision  Recall     F1  ROC_AUC  time_inferense(ms)\n",
       "0  Catboost     0.9714  0.9315  0.951   0.9971              0.0114"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model':['Catboost'],\n",
    "    'Precision':[precision_cb],\n",
    "    'Recall':[recall_cb],\n",
    "    'F1':[f1_cb],\n",
    "    'ROC_AUC':[roc_auc_cb],\n",
    "    'time_inferense(ms)':[time_inference_ms_cb]\n",
    "})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441d545",
   "metadata": {},
   "source": [
    "Важность признаков. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2d852e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature':model_cb.feature_names_,'importance':model_cb.feature_importances_}).sort_values('importance',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f5479b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='importance', ylabel='feature'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(feature_importance,x='importance',y='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23766d2",
   "metadata": {},
   "source": [
    "Видно, что самый важный признак это Tenure - сколько клиент находится в организации. Это логично, старые клиенты более лояльны и они не уходят, а новые клиенты могут прийти за конкретным товаром или купить по акции товар и уйти.\n",
    "\n",
    "WarehouseToHome - то же важно, вероятно из - за того, что удаленность от склада влияет на время доставки товаров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad96f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a159a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29a183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
